{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Курсовой проект для курса \"Python для Data Science\" - \"Библиотеки Python для Data Science: Numpy, Matplotlib, Scikit-learn\"\n",
    "\n",
    "Кузнецов ВВ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"project_task/train.csv\", sep=\",\")\n",
    "test = pd.read_csv(\"project_task/test.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведение колонок к числовым значениям, декомпозиция значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureImputer:\n",
    "    def colnum(self, X):\n",
    "        list_column_features = ['Ecology_2', 'Ecology_3', 'Shops_2']\n",
    "        for c in X.columns[X.dtypes == 'object']:\n",
    "            X[c] = X[c].factorize()[0]\n",
    "        year = datetime.date.today().year  \n",
    "        X['HouseYear'] = year - X['HouseYear']\n",
    "        X.loc[(X['LifeSquare'].isnull()), 'LifeSquare'] = X['Square']\n",
    "        X.loc[X['Ecology_2'] == 1, 'Ecology_2'] = 3\n",
    "        X.loc[X['Ecology_2'] == 0, 'Ecology_2'] = 2\n",
    "        X.loc[X['Ecology_3'] == 1, 'Ecology_3'] = 3\n",
    "        X.loc[X['Ecology_3'] == 0, 'Ecology_3'] = 2\n",
    "        X.loc[X['Helthcare_2'] != -1, 'Helthcare_2'] = (X['Helthcare_2'] + 1) * 10\n",
    "        X.loc[X['Shops_2'] == 1, 'Shops_2'] = 3\n",
    "        X.loc[X['Shops_2'] == 0, 'Shops_2'] = 2\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def transform(self, X, median):\n",
    "        X['Rooms_outlier'] = 0\n",
    "        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1        \n",
    "        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n",
    "        X.loc[X['Rooms'] >= 6, 'Rooms'] = median\n",
    "        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n",
    "        X.loc[X['KitchenSquare'] > 1000, 'KitchenSquare'] = X.loc[X['KitchenSquare'] > 1000, 'KitchenSquare'] / 10        \n",
    "        X['HouseFloor_outlier'] = 0\n",
    "        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n",
    "        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n",
    "        \n",
    "        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = X['HouseFloor'].median()\n",
    "        X.loc[X['Floor'] > X['HouseFloor'], 'Floor'] = X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor']\n",
    "        \n",
    "        current_year = now = datetime.datetime.now().year        \n",
    "        X['HouseYear_outlier'] = 0\n",
    "        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n",
    "        \n",
    "        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year                \n",
    "        X.loc[(X['LifeSquare'] > 300) & (X['Square'] > 300), 'LifeSquare']  = X['LifeSquare'] / 10\n",
    "        X.loc[(X['Square'] > 300), 'Square'] = X['Square']/ 10\n",
    "        X.loc[(X['LifeSquare'] > 300), 'LifeSquare'] = X['Square']\n",
    "        X.loc[X['Id'] == 15215, 'Square'] = X['LifeSquare']\n",
    "        X.loc[X['Ecology_1'] == 0, 'Ecology_1'] = X['Ecology_1'].mean()\n",
    "        X['Floor'] = X['HouseFloor']\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['HouseYear'] < 0, 'HouseYear'] = train['HouseYear'].median()\n",
    "di = train.groupby(['DistrictId']).mean()['HouseYear']\n",
    "\n",
    "train['HouseYear_mean'] = train['DistrictId'].map(di)\n",
    "test['HouseYear_mean'] = test['DistrictId'].map(di)\n",
    "test.loc[test['HouseYear_mean'].isnull(), 'HouseYear_mean'] = test['HouseYear_mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FeatureImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = f.colnum(train)\n",
    "test = f.colnum(test)\n",
    "median = train['Rooms'].median()\n",
    "train = f.transform(train, median)\n",
    "test = f.transform(test, median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на совпаденире колонки DistrictId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "203\n",
      "204\n",
      "206\n",
      "210\n",
      "211\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "for i in test.groupby(['DistrictId']).mean().index.values:\n",
    "    if(True != (i in train.groupby(['DistrictId']).mean().index.values)):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SqM3'] = train['Price'] / train['Square']\n",
    "di = train.groupby(['DistrictId']).mean()['SqM3']\n",
    "train['SqM3_mean'] = train['DistrictId'].map(di)\n",
    "test['SqM3_mean'] = test['DistrictId'].map(di)\n",
    "test.loc[test['SqM3_mean'].isnull(), 'SqM3_mean'] = test['SqM3_mean'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['SqM3'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на заполнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square</th>\n",
       "      <th>LifeSquare</th>\n",
       "      <th>KitchenSquare</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HouseFloor</th>\n",
       "      <th>HouseYear</th>\n",
       "      <th>Ecology_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Healthcare_1</th>\n",
       "      <th>Helthcare_2</th>\n",
       "      <th>Shops_1</th>\n",
       "      <th>Shops_2</th>\n",
       "      <th>Price</th>\n",
       "      <th>HouseYear_mean</th>\n",
       "      <th>Rooms_outlier</th>\n",
       "      <th>HouseFloor_outlier</th>\n",
       "      <th>HouseYear_outlier</th>\n",
       "      <th>SqM3_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>5202.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8383.40770</td>\n",
       "      <td>50.400800</td>\n",
       "      <td>1.887600</td>\n",
       "      <td>56.162732</td>\n",
       "      <td>41.164828</td>\n",
       "      <td>6.616240</td>\n",
       "      <td>12.95910</td>\n",
       "      <td>12.95910</td>\n",
       "      <td>-1.970166e+03</td>\n",
       "      <td>1.252402e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1142.904460</td>\n",
       "      <td>23.195000</td>\n",
       "      <td>4.231300</td>\n",
       "      <td>2.082500</td>\n",
       "      <td>214138.857399</td>\n",
       "      <td>3990.166300</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3992.167920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4859.01902</td>\n",
       "      <td>43.587592</td>\n",
       "      <td>0.811438</td>\n",
       "      <td>19.156723</td>\n",
       "      <td>20.806081</td>\n",
       "      <td>5.296383</td>\n",
       "      <td>6.44346</td>\n",
       "      <td>6.44346</td>\n",
       "      <td>2.005003e+05</td>\n",
       "      <td>1.156182e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1021.517264</td>\n",
       "      <td>14.936006</td>\n",
       "      <td>4.806341</td>\n",
       "      <td>0.275139</td>\n",
       "      <td>92872.293865</td>\n",
       "      <td>31250.218894</td>\n",
       "      <td>0.034622</td>\n",
       "      <td>0.386275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1016.847383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.136859</td>\n",
       "      <td>0.370619</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-2.004999e+07</td>\n",
       "      <td>1.800000e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>59174.778028</td>\n",
       "      <td>1924.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2284.108677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4169.50000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.771580</td>\n",
       "      <td>25.506959</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>3.465608e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153872.633942</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3021.675025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8394.50000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.509275</td>\n",
       "      <td>37.562685</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>9.079910e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>192269.644879</td>\n",
       "      <td>1985.793814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4084.464328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12592.50000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>65.889736</td>\n",
       "      <td>50.082176</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>4.600000e+01</td>\n",
       "      <td>1.957811e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1548.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>249135.462171</td>\n",
       "      <td>1990.818004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4553.239744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16798.00000</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>275.645284</td>\n",
       "      <td>263.542020</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>117.00000</td>\n",
       "      <td>117.00000</td>\n",
       "      <td>1.100000e+02</td>\n",
       "      <td>5.218671e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4849.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>633233.466570</td>\n",
       "      <td>491010.682927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9452.113505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id    DistrictId         Rooms        Square    LifeSquare  \\\n",
       "count  10000.00000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean    8383.40770     50.400800      1.887600     56.162732     41.164828   \n",
       "std     4859.01902     43.587592      0.811438     19.156723     20.806081   \n",
       "min        0.00000      0.000000      1.000000      1.136859      0.370619   \n",
       "25%     4169.50000     20.000000      1.000000     41.771580     25.506959   \n",
       "50%     8394.50000     36.000000      2.000000     52.509275     37.562685   \n",
       "75%    12592.50000     75.000000      2.000000     65.889736     50.082176   \n",
       "max    16798.00000    209.000000      5.000000    275.645284    263.542020   \n",
       "\n",
       "       KitchenSquare        Floor   HouseFloor     HouseYear     Ecology_1  \\\n",
       "count   10000.000000  10000.00000  10000.00000  1.000000e+04  1.000000e+04   \n",
       "mean        6.616240     12.95910     12.95910 -1.970166e+03  1.252402e-01   \n",
       "std         5.296383      6.44346      6.44346  2.005003e+05  1.156182e-01   \n",
       "min         3.000000      1.00000      1.00000 -2.004999e+07  1.800000e-09   \n",
       "25%         3.000000      9.00000      9.00000  1.900000e+01  3.465608e-02   \n",
       "50%         6.000000     13.00000     13.00000  4.300000e+01  9.079910e-02   \n",
       "75%         9.000000     17.00000     17.00000  4.600000e+01  1.957811e-01   \n",
       "max       201.400000    117.00000    117.00000  1.100000e+02  5.218671e-01   \n",
       "\n",
       "       ...  Healthcare_1   Helthcare_2       Shops_1       Shops_2  \\\n",
       "count  ...   5202.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...   1142.904460     23.195000      4.231300      2.082500   \n",
       "std    ...   1021.517264     14.936006      4.806341      0.275139   \n",
       "min    ...      0.000000     10.000000      0.000000      2.000000   \n",
       "25%    ...    350.000000     10.000000      1.000000      2.000000   \n",
       "50%    ...    900.000000     20.000000      3.000000      2.000000   \n",
       "75%    ...   1548.000000     30.000000      6.000000      2.000000   \n",
       "max    ...   4849.000000     70.000000     23.000000      3.000000   \n",
       "\n",
       "               Price  HouseYear_mean  Rooms_outlier  HouseFloor_outlier  \\\n",
       "count   10000.000000    10000.000000   10000.000000        10000.000000   \n",
       "mean   214138.857399     3990.166300       0.001200            0.182500   \n",
       "std     92872.293865    31250.218894       0.034622            0.386275   \n",
       "min     59174.778028     1924.500000       0.000000            0.000000   \n",
       "25%    153872.633942     1979.000000       0.000000            0.000000   \n",
       "50%    192269.644879     1985.793814       0.000000            0.000000   \n",
       "75%    249135.462171     1990.818004       0.000000            0.000000   \n",
       "max    633233.466570   491010.682927       1.000000            1.000000   \n",
       "\n",
       "       HouseYear_outlier     SqM3_mean  \n",
       "count            10000.0  10000.000000  \n",
       "mean                 0.0   3992.167920  \n",
       "std                  0.0   1016.847383  \n",
       "min                  0.0   2284.108677  \n",
       "25%                  0.0   3021.675025  \n",
       "50%                  0.0   4084.464328  \n",
       "75%                  0.0   4553.239744  \n",
       "max                  0.0   9452.113505  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DistrictId</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Square</th>\n",
       "      <th>LifeSquare</th>\n",
       "      <th>KitchenSquare</th>\n",
       "      <th>Floor</th>\n",
       "      <th>HouseFloor</th>\n",
       "      <th>HouseYear</th>\n",
       "      <th>Ecology_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Social_3</th>\n",
       "      <th>Healthcare_1</th>\n",
       "      <th>Helthcare_2</th>\n",
       "      <th>Shops_1</th>\n",
       "      <th>Shops_2</th>\n",
       "      <th>HouseYear_mean</th>\n",
       "      <th>Rooms_outlier</th>\n",
       "      <th>HouseFloor_outlier</th>\n",
       "      <th>HouseYear_outlier</th>\n",
       "      <th>SqM3_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>2623.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8412.595400</td>\n",
       "      <td>51.279200</td>\n",
       "      <td>1.905800</td>\n",
       "      <td>56.449500</td>\n",
       "      <td>41.165054</td>\n",
       "      <td>6.655000</td>\n",
       "      <td>12.915400</td>\n",
       "      <td>12.915400</td>\n",
       "      <td>35.607400</td>\n",
       "      <td>1.265629e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>8.262600</td>\n",
       "      <td>1146.657263</td>\n",
       "      <td>23.194000</td>\n",
       "      <td>4.242800</td>\n",
       "      <td>2.082400</td>\n",
       "      <td>3843.289687</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.176800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4008.572896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4832.674037</td>\n",
       "      <td>44.179466</td>\n",
       "      <td>0.806137</td>\n",
       "      <td>19.092787</td>\n",
       "      <td>20.255970</td>\n",
       "      <td>9.640921</td>\n",
       "      <td>6.468617</td>\n",
       "      <td>6.468617</td>\n",
       "      <td>18.573149</td>\n",
       "      <td>1.164904e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>23.863762</td>\n",
       "      <td>1044.744231</td>\n",
       "      <td>14.799398</td>\n",
       "      <td>4.777365</td>\n",
       "      <td>0.275001</td>\n",
       "      <td>30091.248198</td>\n",
       "      <td>0.03161</td>\n",
       "      <td>0.381538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.899656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.378543</td>\n",
       "      <td>0.333490</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.800000e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1924.500000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2284.108677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4221.750000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>41.906231</td>\n",
       "      <td>25.850152</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.612229e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1979.269231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3089.185017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8320.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.921340</td>\n",
       "      <td>37.382816</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.079910e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1985.361963</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4089.011120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12598.250000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>66.285129</td>\n",
       "      <td>50.611287</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1.957811e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1548.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1990.818004</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4560.204511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16795.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>223.453689</td>\n",
       "      <td>169.901701</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>5.218671e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>4849.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>491010.682927</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9452.113505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Id   DistrictId        Rooms       Square   LifeSquare  \\\n",
       "count   5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean    8412.595400    51.279200     1.905800    56.449500    41.165054   \n",
       "std     4832.674037    44.179466     0.806137    19.092787    20.255970   \n",
       "min        1.000000     0.000000     1.000000     1.378543     0.333490   \n",
       "25%     4221.750000    21.000000     1.000000    41.906231    25.850152   \n",
       "50%     8320.500000    37.000000     2.000000    52.921340    37.382816   \n",
       "75%    12598.250000    77.000000     2.000000    66.285129    50.611287   \n",
       "max    16795.000000   212.000000     5.000000   223.453689   169.901701   \n",
       "\n",
       "       KitchenSquare        Floor   HouseFloor    HouseYear     Ecology_1  \\\n",
       "count    5000.000000  5000.000000  5000.000000  5000.000000  5.000000e+03   \n",
       "mean        6.655000    12.915400    12.915400    35.607400  1.265629e-01   \n",
       "std         9.640921     6.468617     6.468617    18.573149  1.164904e-01   \n",
       "min         3.000000     1.000000     1.000000     0.000000  1.800000e-09   \n",
       "25%         3.000000     9.000000     9.000000    20.000000  3.612229e-02   \n",
       "50%         6.000000    12.000000    12.000000    43.000000  9.079910e-02   \n",
       "75%         9.000000    17.000000    17.000000    47.000000  1.957811e-01   \n",
       "max       620.000000    99.000000    99.000000   112.000000  5.218671e-01   \n",
       "\n",
       "       ...     Social_3  Healthcare_1  Helthcare_2      Shops_1      Shops_2  \\\n",
       "count  ...  5000.000000   2623.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean   ...     8.262600   1146.657263    23.194000     4.242800     2.082400   \n",
       "std    ...    23.863762   1044.744231    14.799398     4.777365     0.275001   \n",
       "min    ...     0.000000      0.000000    10.000000     0.000000     2.000000   \n",
       "25%    ...     0.000000    325.000000    10.000000     1.000000     2.000000   \n",
       "50%    ...     2.000000    900.000000    20.000000     3.000000     2.000000   \n",
       "75%    ...     5.000000   1548.000000    30.000000     6.000000     2.000000   \n",
       "max    ...   141.000000   4849.000000    70.000000    23.000000     3.000000   \n",
       "\n",
       "       HouseYear_mean  Rooms_outlier  HouseFloor_outlier  HouseYear_outlier  \\\n",
       "count     5000.000000     5000.00000         5000.000000             5000.0   \n",
       "mean      3843.289687        0.00100            0.176800                0.0   \n",
       "std      30091.248198        0.03161            0.381538                0.0   \n",
       "min       1924.500000        0.00000            0.000000                0.0   \n",
       "25%       1979.269231        0.00000            0.000000                0.0   \n",
       "50%       1985.361963        0.00000            0.000000                0.0   \n",
       "75%       1990.818004        0.00000            0.000000                0.0   \n",
       "max     491010.682927        1.00000            1.000000                0.0   \n",
       "\n",
       "         SqM3_mean  \n",
       "count  5000.000000  \n",
       "mean   4008.572896  \n",
       "std    1003.899656  \n",
       "min    2284.108677  \n",
       "25%    3089.185017  \n",
       "50%    4089.011120  \n",
       "75%    4560.204511  \n",
       "max    9452.113505  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(['HouseYear_outlier'], axis=1, inplace=True)\n",
    "train.drop(['HouseYear_outlier'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Id                  5000 non-null   int64  \n",
      " 1   DistrictId          5000 non-null   int64  \n",
      " 2   Rooms               5000 non-null   float64\n",
      " 3   Square              5000 non-null   float64\n",
      " 4   LifeSquare          5000 non-null   float64\n",
      " 5   KitchenSquare       5000 non-null   float64\n",
      " 6   Floor               5000 non-null   float64\n",
      " 7   HouseFloor          5000 non-null   float64\n",
      " 8   HouseYear           5000 non-null   int64  \n",
      " 9   Ecology_1           5000 non-null   float64\n",
      " 10  Ecology_2           5000 non-null   int64  \n",
      " 11  Ecology_3           5000 non-null   int64  \n",
      " 12  Social_1            5000 non-null   int64  \n",
      " 13  Social_2            5000 non-null   int64  \n",
      " 14  Social_3            5000 non-null   int64  \n",
      " 15  Healthcare_1        2623 non-null   float64\n",
      " 16  Helthcare_2         5000 non-null   int64  \n",
      " 17  Shops_1             5000 non-null   int64  \n",
      " 18  Shops_2             5000 non-null   int64  \n",
      " 19  HouseYear_mean      5000 non-null   float64\n",
      " 20  Rooms_outlier       5000 non-null   int64  \n",
      " 21  HouseFloor_outlier  5000 non-null   int64  \n",
      " 22  SqM3_mean           5000 non-null   float64\n",
      "dtypes: float64(10), int64(13)\n",
      "memory usage: 898.6 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "        23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  36.,\n",
       "        37.,  38.,  39.,  40.,  44.,  45.,  47.,  48.,  99., 117.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['HouseFloor'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "        12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,\n",
       "        23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  36.,\n",
       "        37.,  38.,  39.,  40.,  44.,  45.,  47.,  48.,  99., 117.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Floor'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[(train['Id'] == 6782), 'LifeSquare'] = train.loc[(438000<train['Price']) & (train['Price'] < 440000) & (train['DistrictId'] == 45.0) & (train['Square'] > 5)].iloc[0]['LifeSquare']\n",
    "train.loc[(train['Id'] == 6782), 'Square'] = train.loc[(438000<train['Price']) & (train['Price'] < 440000) & (train['DistrictId'] == 45.0) & (train['Square'] > 5)].iloc[0]['Square']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "restruct_train = train.loc[(train['LifeSquare'].isnull() != True) & (train['Healthcare_1'].isnull() != True)].drop(['Price'], axis=1).drop(['DistrictId'], axis=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_r_train_ls = restruct_train.drop([\"LifeSquare\", \"Healthcare_1\"], axis = 1)\n",
    "y_r_train_ls = restruct_train[\"Healthcare_1\"]\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_r_train_ls)\n",
    "feature_names = list(X_r_train_ls)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_r_train_ls, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 оценка точности\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9962262715794393"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Healthcare_1 = RandomForestRegressor(max_depth=14, random_state=42, n_estimators=1000)\n",
    "\n",
    "model_Healthcare_1.fit(X_train, y_train)\n",
    "y_forest_pred = model_Healthcare_1.predict(X_test)\n",
    "\n",
    "print('R2 оценка точности')\n",
    "r2_score(y_test, y_forest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = train.loc[(train['Healthcare_1'].isnull())].drop([\"LifeSquare\", \"Healthcare_1\"], axis = 1).drop(['Price'], axis=1).drop(['DistrictId'], axis=1)\n",
    "train.loc[train['Healthcare_1'].isnull(), 'Healthcare_1'] = model_Healthcare_1.predict(sq)\n",
    "\n",
    "sq = train.loc[(train['Healthcare_1'] > 0)].drop([\"LifeSquare\", \"Healthcare_1\"], axis = 1).drop(['Price'], axis=1).drop(['DistrictId'], axis=1)\n",
    "train.loc[(train['Healthcare_1'] > 0), 'Healthcare_1'] = model_Healthcare_1.predict(sq)\n",
    "\n",
    "\n",
    "sq = test.loc[(test['Healthcare_1'].isnull())].drop([\"LifeSquare\", \"Healthcare_1\"], axis = 1).drop(['DistrictId'], axis=1)\n",
    "test.loc[test['Healthcare_1'].isnull(), 'Healthcare_1'] = model_Healthcare_1.predict(sq)\n",
    "\n",
    "sq = test.loc[(test['Healthcare_1'] > 0)].drop([\"LifeSquare\", \"Healthcare_1\"], axis = 1).drop(['DistrictId'], axis=1)\n",
    "test.loc[(test['Healthcare_1'] > 0), 'Healthcare_1'] = model_Healthcare_1.predict(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка модели для предсказания цены "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "X_test_ls = test.drop([\"Id\"], axis = 1).drop([\"Ecology_2\"], axis = 1).drop([\"Ecology_3\"], axis = 1)\n",
    "X_r_train_ls = train.loc[(train['KitchenSquare'] <= 2000)].drop([\"Price\"], axis = 1).drop([\"Id\"], axis = 1)\n",
    "y_r_train_ls = train.loc[(train['KitchenSquare'] <= 2000)][\"Price\"]\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_r_train_ls)\n",
    "feature_names = list(X_r_train_ls)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_num_features = train.select_dtypes(include='float64')\n",
    "num_features = pd.DataFrame(df_num_features)\n",
    "\n",
    "corr = num_features.corr()\n",
    "plt.figure(figsize = (8, 8))\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(num_features.corr(), mask=mask, annot=True, fmt='.1f', linewidths=.5, cmap='GnBu')\n",
    "plt.title('Correlation matrix')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренировка на модели данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 оценка точности\n",
      "0.7306535168226043\n",
      "Выбрана модель с точностью 0.7306535168226043\n"
     ]
    }
   ],
   "source": [
    "ac = 0\n",
    "model_ac = []\n",
    "\n",
    "for i in range(1):\n",
    "    model = RandomForestRegressor(max_depth=14, n_estimators=300, random_state=42)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_r_train_ls.drop([\"Ecology_2\"], axis = 1).drop([\"Ecology_3\"], axis = 1), y_r_train_ls, test_size=0.20, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_forest_pred = model.predict(X_test)\n",
    "\n",
    "    print('R2 оценка точности')\n",
    "    r2 = r2_score(y_test, y_forest_pred)\n",
    "    \n",
    "    if ac < r2:\n",
    "        model_ac = model\n",
    "        ac = r2\n",
    "    print(r2)\n",
    "    \n",
    "print('Выбрана модель с точностью ' + str(ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7306535168226043"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_ac.feature_importances_)\n",
    "plt.xticks(np.arange(X_train.shape[1]), X_train.columns.tolist(), rotation=90);\n",
    "print(len(X_r_train_ls))\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X_test_ls)\n",
    "X_tarin_l = X_test_ls.copy(deep=True)\n",
    "X_tarin_l['Id'] = test['Id']\n",
    "X_tarin_l['Id'].values\n",
    "\n",
    "d = dict(zip(X_tarin_l['Id'].values, y))\n",
    "X_tarin_l['Price'] = test['Id'].map(d)\n",
    "X_tarin_l[['Id', 'Price']].to_csv(\"KuznetsovVV_predictions.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "plt.scatter(y_test, test_predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.xlim(plt.xlim())\n",
    "plt.ylim(plt.ylim())\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = test_predictions - y_test\n",
    "plt.hist(error, bins = 50)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_predictions = model.predict(X_train).flatten()\n",
    "\n",
    "plt.scatter(y_train, train_predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.xlim(plt.xlim())\n",
    "plt.ylim(plt.ylim())\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = train_predictions - y_train\n",
    "plt.hist(error, bins = 50)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['Price_pred'] = y_forest_pred.T\n",
    "#X_test['Price'] = y_test.values\n",
    "#proc = 0.05\n",
    "#X_test.loc[((X_test['Price_pred'] / X_test['Price']) <= 0.7) | ((X_test['Price_pred'] / X_test['Price']) >= 1.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.loc[(0.98 < (X_test['Price_pred'] / X_test['Price'])) & ((X_test['Price_pred'] / X_test['Price']) < 1.02)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Для примера проверим нейронную сеть\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF 2.3.0\n"
     ]
    }
   ],
   "source": [
    "#from future import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1 import keras as keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(\"We're using TF\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.24926888 -1.10037119 -1.26777632 -0.96770099 -0.29464088 -1.22755015\n",
      " -1.22755015  0.01127091 -0.74231612 -0.09858266 -0.16737193  0.01580894\n",
      " -0.47061679  0.13550813  0.2611156   1.11707916 -0.67412635 -0.29986373\n",
      " -0.06482552 -0.02959335 -0.4667348   0.66540875]\n"
     ]
    }
   ],
   "source": [
    "# Тестовые данные не используются при вычислении mean и std\n",
    "\n",
    "mean = X_train.values.mean(axis=0)\n",
    "std = X_train.values.std(axis=0)\n",
    "train_data = (X_train.values - mean) / std\n",
    "test_data = (X_test.values - mean) / std\n",
    "\n",
    "train_labels = y_train.values.T / 40000\n",
    "test_labels = y_test.values.T / 40000\n",
    "\n",
    "print(train_data[0])  # Первый тренировочный пример, нормализованный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 22)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 64)                1472      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 34,817\n",
      "Trainable params: 34,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_r_train_ls, test_size=0.2)\n",
    "    \n",
    "    model_nn = keras.Sequential([\n",
    "                keras.layers.Dense(64, activation='relu',\n",
    "                                   input_shape=(train_data.shape[1],)),\n",
    "                keras.layers.Dense(64, activation='sigmoid'),\n",
    "                keras.layers.Dense(64, activation='sigmoid'),\n",
    "                keras.layers.Dense(64, activation='sigmoid'),\n",
    "                keras.layers.Dense(64, activation='sigmoid'),\n",
    "                keras.layers.Dense(64, activation='sigmoid'),\n",
    "                keras.layers.Dense(64, activation='relu'),\n",
    "                keras.layers.Dense(64, activation='relu'),\n",
    "                keras.layers.Dense(64, activation='relu'),\n",
    "                keras.layers.Dense(1)\n",
    "              ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001, momentum=0.1)\n",
    "\n",
    "    model_nn.compile(loss='mse',\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['accuracy'])\n",
    "    return model_nn\n",
    "\n",
    "model_nn = build_model()\n",
    "model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загрузка модели\n",
    "#model_nn.load_weights(\"training_0/cp-2000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08903981,  0.13081336,  0.0459826 , ..., -0.02959335,\n",
       "        -0.4667348 ,  0.30753205],\n",
       "       [-0.99393813,  0.13081336, -0.84100002, ..., -0.02959335,\n",
       "        -0.4667348 ,  0.48771514],\n",
       "       [-1.016828  ,  0.13081336,  0.26749438, ..., -0.02959335,\n",
       "        -0.4667348 , -0.97719949],\n",
       "       ...,\n",
       "       [-0.37591171,  0.13081336,  0.2636501 , ..., -0.02959335,\n",
       "         2.14254432,  2.34696679],\n",
       "       [ 1.93596491,  0.13081336, -0.92663641, ..., -0.02959335,\n",
       "        -0.4667348 ,  1.57094299],\n",
       "       [-0.53614078,  0.13081336,  0.62421128, ..., -0.02959335,\n",
       "        -0.4667348 , -1.06743436]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   DistrictId          10000 non-null  float64\n",
      " 1   Rooms               10000 non-null  float64\n",
      " 2   Square              10000 non-null  float64\n",
      " 3   LifeSquare          10000 non-null  float64\n",
      " 4   KitchenSquare       10000 non-null  float64\n",
      " 5   Floor               10000 non-null  float64\n",
      " 6   HouseFloor          10000 non-null  float64\n",
      " 7   HouseYear           10000 non-null  float64\n",
      " 8   Ecology_1           10000 non-null  float64\n",
      " 9   Ecology_2           10000 non-null  float64\n",
      " 10  Ecology_3           10000 non-null  float64\n",
      " 11  Social_1            10000 non-null  float64\n",
      " 12  Social_2            10000 non-null  float64\n",
      " 13  Social_3            10000 non-null  float64\n",
      " 14  Healthcare_1        10000 non-null  float64\n",
      " 15  Helthcare_2         10000 non-null  float64\n",
      " 16  Shops_1             10000 non-null  float64\n",
      " 17  Shops_2             10000 non-null  float64\n",
      " 18  HouseYear_mean      10000 non-null  float64\n",
      " 19  Rooms_outlier       10000 non-null  float64\n",
      " 20  HouseFloor_outlier  10000 non-null  float64\n",
      " 21  SqM3_mean           10000 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#Если мало времени то лучше пропустить.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 30.3205 - accuracy: 0.0000e+00 - val_loss: 26.8239 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 23.1515 - accuracy: 0.0000e+00 - val_loss: 19.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/2000\n",
      "250/250 [==============================] - 0s 728us/step - loss: 16.2262 - accuracy: 0.0000e+00 - val_loss: 12.9775 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/2000\n",
      "250/250 [==============================] - 0s 715us/step - loss: 10.2642 - accuracy: 0.0000e+00 - val_loss: 7.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 6.4545 - accuracy: 0.0000e+00\n",
      "Epoch 00005: saving model to training_0_0/cp-0005.ckpt\n",
      "250/250 [==============================] - 0s 838us/step - loss: 6.3878 - accuracy: 0.0000e+00 - val_loss: 5.4599 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 5.4171 - accuracy: 0.0000e+00 - val_loss: 5.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 5.3993 - accuracy: 0.0000e+00 - val_loss: 5.3576 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/2000\n",
      "250/250 [==============================] - 0s 722us/step - loss: 5.4006 - accuracy: 0.0000e+00 - val_loss: 5.3567 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/2000\n",
      "250/250 [==============================] - 0s 741us/step - loss: 5.3964 - accuracy: 0.0000e+00 - val_loss: 5.3615 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/2000\n",
      "168/250 [===================>..........] - ETA: 0s - loss: 5.2143 - accuracy: 0.0000e+00\n",
      "Epoch 00010: saving model to training_0_0/cp-0010.ckpt\n",
      "250/250 [==============================] - 0s 758us/step - loss: 5.3981 - accuracy: 0.0000e+00 - val_loss: 5.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/2000\n",
      "250/250 [==============================] - 0s 725us/step - loss: 5.3989 - accuracy: 0.0000e+00 - val_loss: 5.3557 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 5.3986 - accuracy: 0.0000e+00 - val_loss: 5.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/2000\n",
      "250/250 [==============================] - 0s 717us/step - loss: 5.3968 - accuracy: 0.0000e+00 - val_loss: 5.3543 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 5.3975 - accuracy: 0.0000e+00 - val_loss: 5.3537 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 5.4158 - accuracy: 0.0000e+00\n",
      "Epoch 00015: saving model to training_0_0/cp-0015.ckpt\n",
      "250/250 [==============================] - 0s 791us/step - loss: 5.3954 - accuracy: 0.0000e+00 - val_loss: 5.3538 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 5.3956 - accuracy: 0.0000e+00 - val_loss: 5.3527 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/2000\n",
      "250/250 [==============================] - 0s 727us/step - loss: 5.3949 - accuracy: 0.0000e+00 - val_loss: 5.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 5.3942 - accuracy: 0.0000e+00 - val_loss: 5.3504 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 5.3937 - accuracy: 0.0000e+00 - val_loss: 5.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 5.4006 - accuracy: 0.0000e+00\n",
      "Epoch 00020: saving model to training_0_0/cp-0020.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 5.3914 - accuracy: 0.0000e+00 - val_loss: 5.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 5.3914 - accuracy: 0.0000e+00 - val_loss: 5.3474 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 5.3894 - accuracy: 0.0000e+00 - val_loss: 5.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 5.3881 - accuracy: 0.0000e+00 - val_loss: 5.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 5.3851 - accuracy: 0.0000e+00 - val_loss: 5.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 5.3996 - accuracy: 0.0000e+00\n",
      "Epoch 00025: saving model to training_0_0/cp-0025.ckpt\n",
      "250/250 [==============================] - 0s 822us/step - loss: 5.3841 - accuracy: 0.0000e+00 - val_loss: 5.3396 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 5.3807 - accuracy: 0.0000e+00 - val_loss: 5.3375 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 5.3787 - accuracy: 0.0000e+00 - val_loss: 5.3339 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/2000\n",
      "250/250 [==============================] - 0s 721us/step - loss: 5.3750 - accuracy: 0.0000e+00 - val_loss: 5.3305 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 5.3714 - accuracy: 0.0000e+00 - val_loss: 5.3260 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 5.3668 - accuracy: 0.0000e+00\n",
      "Epoch 00030: saving model to training_0_0/cp-0030.ckpt\n",
      "250/250 [==============================] - 0s 775us/step - loss: 5.3668 - accuracy: 0.0000e+00 - val_loss: 5.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 5.3588 - accuracy: 0.0000e+00 - val_loss: 5.3188 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/2000\n",
      "250/250 [==============================] - 0s 718us/step - loss: 5.3546 - accuracy: 0.0000e+00 - val_loss: 5.3098 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 5.3473 - accuracy: 0.0000e+00 - val_loss: 5.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/2000\n",
      "250/250 [==============================] - 0s 713us/step - loss: 5.3394 - accuracy: 0.0000e+00 - val_loss: 5.2919 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/2000\n",
      "170/250 [===================>..........] - ETA: 0s - loss: 5.3900 - accuracy: 0.0000e+00\n",
      "Epoch 00035: saving model to training_0_0/cp-0035.ckpt\n",
      "250/250 [==============================] - 0s 757us/step - loss: 5.3281 - accuracy: 0.0000e+00 - val_loss: 5.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 5.3178 - accuracy: 0.0000e+00 - val_loss: 5.2689 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/2000\n",
      "250/250 [==============================] - 0s 752us/step - loss: 5.3031 - accuracy: 0.0000e+00 - val_loss: 5.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/2000\n",
      "250/250 [==============================] - 0s 735us/step - loss: 5.2857 - accuracy: 0.0000e+00 - val_loss: 5.2365 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/2000\n",
      "250/250 [==============================] - 0s 723us/step - loss: 5.2676 - accuracy: 0.0000e+00 - val_loss: 5.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 5.2412 - accuracy: 0.0000e+00\n",
      "Epoch 00040: saving model to training_0_0/cp-0040.ckpt\n",
      "250/250 [==============================] - 0s 781us/step - loss: 5.2439 - accuracy: 0.0000e+00 - val_loss: 5.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/2000\n",
      "250/250 [==============================] - 0s 746us/step - loss: 5.2159 - accuracy: 0.0000e+00 - val_loss: 5.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 5.1839 - accuracy: 0.0000e+00 - val_loss: 5.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/2000\n",
      "250/250 [==============================] - 0s 737us/step - loss: 5.1456 - accuracy: 0.0000e+00 - val_loss: 5.0848 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/2000\n",
      "250/250 [==============================] - 0s 735us/step - loss: 5.1007 - accuracy: 0.0000e+00 - val_loss: 5.0377 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/250 [==================>...........] - ETA: 0s - loss: 5.0474 - accuracy: 0.0000e+00\n",
      "Epoch 00045: saving model to training_0_0/cp-0045.ckpt\n",
      "250/250 [==============================] - 0s 760us/step - loss: 5.0486 - accuracy: 0.0000e+00 - val_loss: 4.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 4.9851 - accuracy: 0.0000e+00 - val_loss: 4.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 4.9138 - accuracy: 0.0000e+00 - val_loss: 4.8379 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 4.8271 - accuracy: 0.0000e+00 - val_loss: 4.7433 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/2000\n",
      "250/250 [==============================] - 0s 716us/step - loss: 4.7242 - accuracy: 0.0000e+00 - val_loss: 4.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 4.6093 - accuracy: 0.0000e+00\n",
      "Epoch 00050: saving model to training_0_0/cp-0050.ckpt\n",
      "250/250 [==============================] - 0s 777us/step - loss: 4.6086 - accuracy: 0.0000e+00 - val_loss: 4.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 4.4670 - accuracy: 0.0000e+00 - val_loss: 4.3627 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/2000\n",
      "250/250 [==============================] - 0s 711us/step - loss: 4.3045 - accuracy: 0.0000e+00 - val_loss: 4.1940 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 4.1260 - accuracy: 0.0000e+00 - val_loss: 4.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 3.9282 - accuracy: 0.0000e+00 - val_loss: 3.8000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/2000\n",
      "168/250 [===================>..........] - ETA: 0s - loss: 3.7214 - accuracy: 0.0000e+00\n",
      "Epoch 00055: saving model to training_0_0/cp-0055.ckpt\n",
      "250/250 [==============================] - 0s 768us/step - loss: 3.6908 - accuracy: 0.0000e+00 - val_loss: 3.5633 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/2000\n",
      "250/250 [==============================] - 0s 733us/step - loss: 3.4537 - accuracy: 0.0000e+00 - val_loss: 3.3242 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/2000\n",
      "250/250 [==============================] - 0s 719us/step - loss: 3.2138 - accuracy: 0.0000e+00 - val_loss: 3.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 2.9652 - accuracy: 0.0000e+00 - val_loss: 2.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 2.7458 - accuracy: 0.0000e+00 - val_loss: 2.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/2000\n",
      "165/250 [==================>...........] - ETA: 0s - loss: 2.5831 - accuracy: 0.0000e+00\n",
      "Epoch 00060: saving model to training_0_0/cp-0060.ckpt\n",
      "250/250 [==============================] - 0s 762us/step - loss: 2.5674 - accuracy: 0.0000e+00 - val_loss: 2.5317 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 2.4394 - accuracy: 0.0000e+00 - val_loss: 2.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/2000\n",
      "250/250 [==============================] - 0s 723us/step - loss: 2.3519 - accuracy: 0.0000e+00 - val_loss: 2.3527 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 2.2923 - accuracy: 0.0000e+00 - val_loss: 2.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 2.2449 - accuracy: 0.0000e+00 - val_loss: 2.2635 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/2000\n",
      "167/250 [===================>..........] - ETA: 0s - loss: 2.2386 - accuracy: 0.0000e+00\n",
      "Epoch 00065: saving model to training_0_0/cp-0065.ckpt\n",
      "250/250 [==============================] - 0s 758us/step - loss: 2.2087 - accuracy: 0.0000e+00 - val_loss: 2.2273 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/2000\n",
      "250/250 [==============================] - 0s 752us/step - loss: 2.1777 - accuracy: 0.0000e+00 - val_loss: 2.1981 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/2000\n",
      "250/250 [==============================] - 0s 717us/step - loss: 2.1515 - accuracy: 0.0000e+00 - val_loss: 2.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/2000\n",
      "250/250 [==============================] - 0s 745us/step - loss: 2.1260 - accuracy: 0.0000e+00 - val_loss: 2.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/2000\n",
      "250/250 [==============================] - 0s 748us/step - loss: 2.1060 - accuracy: 0.0000e+00 - val_loss: 2.1254 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/2000\n",
      "171/250 [===================>..........] - ETA: 0s - loss: 2.0938 - accuracy: 0.0000e+00\n",
      "Epoch 00070: saving model to training_0_0/cp-0070.ckpt\n",
      "250/250 [==============================] - 0s 754us/step - loss: 2.0856 - accuracy: 0.0000e+00 - val_loss: 2.1030 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/2000\n",
      "250/250 [==============================] - 0s 735us/step - loss: 2.0679 - accuracy: 0.0000e+00 - val_loss: 2.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/2000\n",
      "250/250 [==============================] - 0s 732us/step - loss: 2.0518 - accuracy: 0.0000e+00 - val_loss: 2.0602 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/2000\n",
      "250/250 [==============================] - 0s 717us/step - loss: 2.0348 - accuracy: 0.0000e+00 - val_loss: 2.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 2.0191 - accuracy: 0.0000e+00 - val_loss: 2.0254 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.9963 - accuracy: 0.0000e+00\n",
      "Epoch 00075: saving model to training_0_0/cp-0075.ckpt\n",
      "250/250 [==============================] - 0s 774us/step - loss: 2.0074 - accuracy: 0.0000e+00 - val_loss: 2.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.9933 - accuracy: 0.0000e+00 - val_loss: 1.9934 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/2000\n",
      "250/250 [==============================] - 0s 724us/step - loss: 1.9813 - accuracy: 0.0000e+00 - val_loss: 1.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/2000\n",
      "250/250 [==============================] - 0s 720us/step - loss: 1.9692 - accuracy: 0.0000e+00 - val_loss: 1.9656 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/2000\n",
      "250/250 [==============================] - 0s 740us/step - loss: 1.9571 - accuracy: 0.0000e+00 - val_loss: 1.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/2000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 1.9361 - accuracy: 0.0000e+00\n",
      "Epoch 00080: saving model to training_0_0/cp-0080.ckpt\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.9460 - accuracy: 0.0000e+00 - val_loss: 1.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.9338 - accuracy: 0.0000e+00 - val_loss: 1.9267 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/2000\n",
      "250/250 [==============================] - 0s 723us/step - loss: 1.9253 - accuracy: 0.0000e+00 - val_loss: 1.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/2000\n",
      "250/250 [==============================] - 0s 737us/step - loss: 1.9162 - accuracy: 0.0000e+00 - val_loss: 1.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/2000\n",
      "250/250 [==============================] - 0s 748us/step - loss: 1.9057 - accuracy: 0.0000e+00 - val_loss: 1.9084 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.8807 - accuracy: 0.0000e+00\n",
      "Epoch 00085: saving model to training_0_0/cp-0085.ckpt\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.8972 - accuracy: 0.0000e+00 - val_loss: 1.8866 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.8886 - accuracy: 0.0000e+00 - val_loss: 1.8765 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/2000\n",
      "250/250 [==============================] - 0s 714us/step - loss: 1.8796 - accuracy: 0.0000e+00 - val_loss: 1.8709 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/2000\n",
      "250/250 [==============================] - 0s 723us/step - loss: 1.8725 - accuracy: 0.0000e+00 - val_loss: 1.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 740us/step - loss: 1.8652 - accuracy: 0.0000e+00 - val_loss: 1.8623 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.8590 - accuracy: 0.0000e+00\n",
      "Epoch 00090: saving model to training_0_0/cp-0090.ckpt\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.8590 - accuracy: 0.0000e+00 - val_loss: 1.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.8522 - accuracy: 0.0000e+00 - val_loss: 1.8372 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/2000\n",
      "250/250 [==============================] - 0s 720us/step - loss: 1.8449 - accuracy: 0.0000e+00 - val_loss: 1.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/2000\n",
      "250/250 [==============================] - 0s 737us/step - loss: 1.8395 - accuracy: 0.0000e+00 - val_loss: 1.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/2000\n",
      "250/250 [==============================] - 0s 716us/step - loss: 1.8330 - accuracy: 0.0000e+00 - val_loss: 1.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.8269 - accuracy: 0.0000e+00\n",
      "Epoch 00095: saving model to training_0_0/cp-0095.ckpt\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.8278 - accuracy: 0.0000e+00 - val_loss: 1.8108 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/2000\n",
      "250/250 [==============================] - 0s 745us/step - loss: 1.8205 - accuracy: 0.0000e+00 - val_loss: 1.8095 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.8160 - accuracy: 0.0000e+00 - val_loss: 1.8045 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/2000\n",
      "250/250 [==============================] - 0s 720us/step - loss: 1.8110 - accuracy: 0.0000e+00 - val_loss: 1.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/2000\n",
      "250/250 [==============================] - 0s 739us/step - loss: 1.8041 - accuracy: 0.0000e+00 - val_loss: 1.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/2000\n",
      "170/250 [===================>..........] - ETA: 0s - loss: 1.7848 - accuracy: 0.0000e+00\n",
      "Epoch 00100: saving model to training_0_0/cp-0100.ckpt\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.8012 - accuracy: 0.0000e+00 - val_loss: 1.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/2000\n",
      "250/250 [==============================] - 0s 719us/step - loss: 1.7945 - accuracy: 0.0000e+00 - val_loss: 1.7792 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.7903 - accuracy: 0.0000e+00 - val_loss: 1.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/2000\n",
      "250/250 [==============================] - 0s 728us/step - loss: 1.7861 - accuracy: 0.0000e+00 - val_loss: 1.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.7818 - accuracy: 0.0000e+00 - val_loss: 1.7619 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.7785 - accuracy: 0.0000e+00\n",
      "Epoch 00105: saving model to training_0_0/cp-0105.ckpt\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.7778 - accuracy: 0.0000e+00 - val_loss: 1.7562 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/2000\n",
      "250/250 [==============================] - 0s 733us/step - loss: 1.7729 - accuracy: 0.0000e+00 - val_loss: 1.7530 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/2000\n",
      "250/250 [==============================] - 0s 734us/step - loss: 1.7682 - accuracy: 0.0000e+00 - val_loss: 1.7466 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/2000\n",
      "250/250 [==============================] - 0s 738us/step - loss: 1.7648 - accuracy: 0.0000e+00 - val_loss: 1.7479 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 1.7605 - accuracy: 0.0000e+00 - val_loss: 1.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.7572 - accuracy: 0.0000e+00\n",
      "Epoch 00110: saving model to training_0_0/cp-0110.ckpt\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.7572 - accuracy: 0.0000e+00 - val_loss: 1.7392 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/2000\n",
      "250/250 [==============================] - 0s 720us/step - loss: 1.7530 - accuracy: 0.0000e+00 - val_loss: 1.7379 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.7492 - accuracy: 0.0000e+00 - val_loss: 1.7274 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/2000\n",
      "250/250 [==============================] - 0s 724us/step - loss: 1.7445 - accuracy: 0.0000e+00 - val_loss: 1.7320 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/2000\n",
      "250/250 [==============================] - 0s 746us/step - loss: 1.7415 - accuracy: 0.0000e+00 - val_loss: 1.7229 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.7386 - accuracy: 0.0000e+00\n",
      "Epoch 00115: saving model to training_0_0/cp-0115.ckpt\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.7386 - accuracy: 0.0000e+00 - val_loss: 1.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.7362 - accuracy: 0.0000e+00 - val_loss: 1.7186 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.7321 - accuracy: 0.0000e+00 - val_loss: 1.7146 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.7288 - accuracy: 0.0000e+00 - val_loss: 1.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/2000\n",
      "250/250 [==============================] - 0s 738us/step - loss: 1.7262 - accuracy: 0.0000e+00 - val_loss: 1.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/2000\n",
      "169/250 [===================>..........] - ETA: 0s - loss: 1.6716 - accuracy: 0.0000e+00\n",
      "Epoch 00120: saving model to training_0_0/cp-0120.ckpt\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.7233 - accuracy: 0.0000e+00 - val_loss: 1.7049 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/2000\n",
      "250/250 [==============================] - 0s 729us/step - loss: 1.7192 - accuracy: 0.0000e+00 - val_loss: 1.6963 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.7155 - accuracy: 0.0000e+00 - val_loss: 1.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.7130 - accuracy: 0.0000e+00 - val_loss: 1.6912 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.7092 - accuracy: 0.0000e+00 - val_loss: 1.6862 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.6965 - accuracy: 0.0000e+00\n",
      "Epoch 00125: saving model to training_0_0/cp-0125.ckpt\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.7074 - accuracy: 0.0000e+00 - val_loss: 1.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.7197 - accuracy: 0.0000e+ - 0s 772us/step - loss: 1.7042 - accuracy: 0.0000e+00 - val_loss: 1.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.7013 - accuracy: 0.0000e+00 - val_loss: 1.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.6986 - accuracy: 0.0000e+00 - val_loss: 1.6735 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.6950 - accuracy: 0.0000e+00 - val_loss: 1.6695 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.6945 - accuracy: 0.0000e+00\n",
      "Epoch 00130: saving model to training_0_0/cp-0130.ckpt\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.6917 - accuracy: 0.0000e+00 - val_loss: 1.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/2000\n",
      "250/250 [==============================] - 0s 746us/step - loss: 1.6883 - accuracy: 0.0000e+00 - val_loss: 1.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.6856 - accuracy: 0.0000e+00 - val_loss: 1.6822 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 774us/step - loss: 1.6836 - accuracy: 0.0000e+00 - val_loss: 1.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/2000\n",
      "250/250 [==============================] - 0s 740us/step - loss: 1.6814 - accuracy: 0.0000e+00 - val_loss: 1.6599 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/2000\n",
      "171/250 [===================>..........] - ETA: 0s - loss: 1.7488 - accuracy: 0.0000e+00\n",
      "Epoch 00135: saving model to training_0_0/cp-0135.ckpt\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.6788 - accuracy: 0.0000e+00 - val_loss: 1.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 1.6746 - accuracy: 0.0000e+00 - val_loss: 1.6518 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/2000\n",
      "250/250 [==============================] - 0s 734us/step - loss: 1.6735 - accuracy: 0.0000e+00 - val_loss: 1.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/2000\n",
      "250/250 [==============================] - 0s 729us/step - loss: 1.6711 - accuracy: 0.0000e+00 - val_loss: 1.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/2000\n",
      "250/250 [==============================] - 0s 752us/step - loss: 1.6679 - accuracy: 0.0000e+00 - val_loss: 1.6460 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/2000\n",
      "243/250 [============================>.] - ETA: 0s - loss: 1.6661 - accuracy: 0.0000e+00\n",
      "Epoch 00140: saving model to training_0_0/cp-0140.ckpt\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.6645 - accuracy: 0.0000e+00 - val_loss: 1.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/2000\n",
      "250/250 [==============================] - 0s 758us/step - loss: 1.6633 - accuracy: 0.0000e+00 - val_loss: 1.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.6607 - accuracy: 0.0000e+00 - val_loss: 1.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.6583 - accuracy: 0.0000e+00 - val_loss: 1.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.6556 - accuracy: 0.0000e+00 - val_loss: 1.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/2000\n",
      "242/250 [============================>.] - ETA: 0s - loss: 1.6668 - accuracy: 0.0000e+00\n",
      "Epoch 00145: saving model to training_0_0/cp-0145.ckpt\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.6527 - accuracy: 0.0000e+00 - val_loss: 1.6293 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/2000\n",
      "250/250 [==============================] - 0s 738us/step - loss: 1.6509 - accuracy: 0.0000e+00 - val_loss: 1.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/2000\n",
      "250/250 [==============================] - 0s 737us/step - loss: 1.6468 - accuracy: 0.0000e+00 - val_loss: 1.6268 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/2000\n",
      "250/250 [==============================] - 0s 721us/step - loss: 1.6455 - accuracy: 0.0000e+00 - val_loss: 1.6232 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.6425 - accuracy: 0.0000e+00 - val_loss: 1.6185 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.6539 - accuracy: 0.0000e+00\n",
      "Epoch 00150: saving model to training_0_0/cp-0150.ckpt\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.6425 - accuracy: 0.0000e+00 - val_loss: 1.6263 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.6378 - accuracy: 0.0000e+00 - val_loss: 1.6170 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/2000\n",
      "250/250 [==============================] - 0s 717us/step - loss: 1.6367 - accuracy: 0.0000e+00 - val_loss: 1.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/2000\n",
      "250/250 [==============================] - 0s 737us/step - loss: 1.6357 - accuracy: 0.0000e+00 - val_loss: 1.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.6341 - accuracy: 0.0000e+00 - val_loss: 1.6154 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.6251 - accuracy: 0.0000e+00\n",
      "Epoch 00155: saving model to training_0_0/cp-0155.ckpt\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.6316 - accuracy: 0.0000e+00 - val_loss: 1.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.6292 - accuracy: 0.0000e+00 - val_loss: 1.6096 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.6268 - accuracy: 0.0000e+00 - val_loss: 1.6071 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.6256 - accuracy: 0.0000e+00 - val_loss: 1.6141 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.6227 - accuracy: 0.0000e+00 - val_loss: 1.5989 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.6259 - accuracy: 0.0000e+00\n",
      "Epoch 00160: saving model to training_0_0/cp-0160.ckpt\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.6218 - accuracy: 0.0000e+00 - val_loss: 1.6008 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/2000\n",
      "250/250 [==============================] - 0s 722us/step - loss: 1.6181 - accuracy: 0.0000e+00 - val_loss: 1.5958 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.6172 - accuracy: 0.0000e+00 - val_loss: 1.5972 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.6150 - accuracy: 0.0000e+00 - val_loss: 1.6076 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 1.6134 - accuracy: 0.0000e+00 - val_loss: 1.5909 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/2000\n",
      "244/250 [============================>.] - ETA: 0s - loss: 1.5987 - accuracy: 0.0000e+00\n",
      "Epoch 00165: saving model to training_0_0/cp-0165.ckpt\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.6126 - accuracy: 0.0000e+00 - val_loss: 1.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.6091 - accuracy: 0.0000e+00 - val_loss: 1.6001 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.6077 - accuracy: 0.0000e+00 - val_loss: 1.5869 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.6060 - accuracy: 0.0000e+00 - val_loss: 1.5860 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.6046 - accuracy: 0.0000e+00 - val_loss: 1.5868 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.6104 - accuracy: 0.0000e+00\n",
      "Epoch 00170: saving model to training_0_0/cp-0170.ckpt\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.6022 - accuracy: 0.0000e+00 - val_loss: 1.5854 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.6005 - accuracy: 0.0000e+00 - val_loss: 1.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.5988 - accuracy: 0.0000e+00 - val_loss: 1.5792 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.5960 - accuracy: 0.0000e+00 - val_loss: 1.5780 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.5954 - accuracy: 0.0000e+00 - val_loss: 1.5767 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.5998 - accuracy: 0.0000e+00\n",
      "Epoch 00175: saving model to training_0_0/cp-0175.ckpt\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.5936 - accuracy: 0.0000e+00 - val_loss: 1.5810 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.5918 - accuracy: 0.0000e+00 - val_loss: 1.5796 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 758us/step - loss: 1.5908 - accuracy: 0.0000e+00 - val_loss: 1.5745 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/2000\n",
      "250/250 [==============================] - 0s 710us/step - loss: 1.5892 - accuracy: 0.0000e+00 - val_loss: 1.5698 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/2000\n",
      "250/250 [==============================] - 0s 715us/step - loss: 1.5878 - accuracy: 0.0000e+00 - val_loss: 1.5889 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/2000\n",
      "167/250 [===================>..........] - ETA: 0s - loss: 1.5533 - accuracy: 0.0000e+00\n",
      "Epoch 00180: saving model to training_0_0/cp-0180.ckpt\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.5850 - accuracy: 0.0000e+00 - val_loss: 1.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.5839 - accuracy: 0.0000e+00 - val_loss: 1.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.5826 - accuracy: 0.0000e+00 - val_loss: 1.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.5811 - accuracy: 0.0000e+00 - val_loss: 1.5655 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.5798 - accuracy: 0.0000e+00 - val_loss: 1.5643 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.5785 - accuracy: 0.0000e+00\n",
      "Epoch 00185: saving model to training_0_0/cp-0185.ckpt\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.5793 - accuracy: 0.0000e+00 - val_loss: 1.5599 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.5765 - accuracy: 0.0000e+00 - val_loss: 1.5758 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.5759 - accuracy: 0.0000e+00 - val_loss: 1.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.5733 - accuracy: 0.0000e+00 - val_loss: 1.5557 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.5729 - accuracy: 0.0000e+00 - val_loss: 1.5556 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.5749 - accuracy: 0.0000e+00\n",
      "Epoch 00190: saving model to training_0_0/cp-0190.ckpt\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.5710 - accuracy: 0.0000e+00 - val_loss: 1.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.5682 - accuracy: 0.0000e+00 - val_loss: 1.5619 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.5684 - accuracy: 0.0000e+00 - val_loss: 1.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.5671 - accuracy: 0.0000e+00 - val_loss: 1.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.5659 - accuracy: 0.0000e+00 - val_loss: 1.5481 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.5684 - accuracy: 0.0000e+00\n",
      "Epoch 00195: saving model to training_0_0/cp-0195.ckpt\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.5633 - accuracy: 0.0000e+00 - val_loss: 1.5505 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.5624 - accuracy: 0.0000e+00 - val_loss: 1.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.5614 - accuracy: 0.0000e+00 - val_loss: 1.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.5595 - accuracy: 0.0000e+00 - val_loss: 1.5447 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 1.5591 - accuracy: 0.0000e+00 - val_loss: 1.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.5625 - accuracy: 0.0000e+00\n",
      "Epoch 00200: saving model to training_0_0/cp-0200.ckpt\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.5579 - accuracy: 0.0000e+00 - val_loss: 1.5504 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.5569 - accuracy: 0.0000e+00 - val_loss: 1.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.5550 - accuracy: 0.0000e+00 - val_loss: 1.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.5528 - accuracy: 0.0000e+00 - val_loss: 1.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.5517 - accuracy: 0.0000e+00 - val_loss: 1.5403 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.5382 - accuracy: 0.0000e+00\n",
      "Epoch 00205: saving model to training_0_0/cp-0205.ckpt\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.5515 - accuracy: 0.0000e+00 - val_loss: 1.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.5500 - accuracy: 0.0000e+00 - val_loss: 1.5396 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.5472 - accuracy: 0.0000e+00 - val_loss: 1.5413 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.5477 - accuracy: 0.0000e+00 - val_loss: 1.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.5463 - accuracy: 0.0000e+00 - val_loss: 1.5406 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.5447 - accuracy: 0.0000e+00\n",
      "Epoch 00210: saving model to training_0_0/cp-0210.ckpt\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.5451 - accuracy: 0.0000e+00 - val_loss: 1.5351 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.5434 - accuracy: 0.0000e+00 - val_loss: 1.5339 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.5430 - accuracy: 0.0000e+00 - val_loss: 1.5412 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.5417 - accuracy: 0.0000e+00 - val_loss: 1.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.5383 - accuracy: 0.0000e+00 - val_loss: 1.5547 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.5214 - accuracy: 0.0000e+00\n",
      "Epoch 00215: saving model to training_0_0/cp-0215.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.5396 - accuracy: 0.0000e+00 - val_loss: 1.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.5390 - accuracy: 0.0000e+00 - val_loss: 1.5382 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.5369 - accuracy: 0.0000e+00 - val_loss: 1.5248 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.5369 - accuracy: 0.0000e+00 - val_loss: 1.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.5354 - accuracy: 0.0000e+00 - val_loss: 1.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/2000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 1.5285 - accuracy: 0.0000e+00\n",
      "Epoch 00220: saving model to training_0_0/cp-0220.ckpt\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.5334 - accuracy: 0.0000e+00 - val_loss: 1.5266 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 770us/step - loss: 1.5339 - accuracy: 0.0000e+00 - val_loss: 1.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.5315 - accuracy: 0.0000e+00 - val_loss: 1.5213 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/2000\n",
      "250/250 [==============================] - 0s 722us/step - loss: 1.5305 - accuracy: 0.0000e+00 - val_loss: 1.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.5296 - accuracy: 0.0000e+00 - val_loss: 1.5245 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.4960 - accuracy: 0.0000e+00\n",
      "Epoch 00225: saving model to training_0_0/cp-0225.ckpt\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.5280 - accuracy: 0.0000e+00 - val_loss: 1.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.5290 - accuracy: 0.0000e+00 - val_loss: 1.5332 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.5277 - accuracy: 0.0000e+00 - val_loss: 1.5292 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/2000\n",
      "250/250 [==============================] - 0s 745us/step - loss: 1.5253 - accuracy: 0.0000e+00 - val_loss: 1.5197 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.5253 - accuracy: 0.0000e+00 - val_loss: 1.5193 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.5239 - accuracy: 0.0000e+00\n",
      "Epoch 00230: saving model to training_0_0/cp-0230.ckpt\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.5243 - accuracy: 0.0000e+00 - val_loss: 1.5354 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.5224 - accuracy: 0.0000e+00 - val_loss: 1.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.5220 - accuracy: 0.0000e+00 - val_loss: 1.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.5211 - accuracy: 0.0000e+00 - val_loss: 1.5155 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.5199 - accuracy: 0.0000e+00 - val_loss: 1.5203 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/2000\n",
      "248/250 [============================>.] - ETA: 0s - loss: 1.5202 - accuracy: 0.0000e+00\n",
      "Epoch 00235: saving model to training_0_0/cp-0235.ckpt\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.5201 - accuracy: 0.0000e+00 - val_loss: 1.5172 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.5183 - accuracy: 0.0000e+00 - val_loss: 1.5422 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.5172 - accuracy: 0.0000e+00 - val_loss: 1.5243 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.5169 - accuracy: 0.0000e+00 - val_loss: 1.5150 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.5157 - accuracy: 0.0000e+00 - val_loss: 1.5141 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.5138 - accuracy: 0.0000e+00\n",
      "Epoch 00240: saving model to training_0_0/cp-0240.ckpt\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.5155 - accuracy: 0.0000e+00 - val_loss: 1.5081 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.5146 - accuracy: 0.0000e+00 - val_loss: 1.5102 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.5135 - accuracy: 0.0000e+00 - val_loss: 1.5071 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.5129 - accuracy: 0.0000e+00 - val_loss: 1.5165 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.5117 - accuracy: 0.0000e+00 - val_loss: 1.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5121 - accuracy: 0.0000e+00\n",
      "Epoch 00245: saving model to training_0_0/cp-0245.ckpt\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.5121 - accuracy: 0.0000e+00 - val_loss: 1.5077 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.5110 - accuracy: 0.0000e+00 - val_loss: 1.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.5103 - accuracy: 0.0000e+00 - val_loss: 1.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/2000\n",
      "250/250 [==============================] - 0s 748us/step - loss: 1.5091 - accuracy: 0.0000e+00 - val_loss: 1.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.5085 - accuracy: 0.0000e+00 - val_loss: 1.5146 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.5065 - accuracy: 0.0000e+00\n",
      "Epoch 00250: saving model to training_0_0/cp-0250.ckpt\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.5065 - accuracy: 0.0000e+00 - val_loss: 1.5161 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.5058 - accuracy: 0.0000e+00 - val_loss: 1.5123 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.5063 - accuracy: 0.0000e+00 - val_loss: 1.5035 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.5039 - accuracy: 0.0000e+00 - val_loss: 1.5005 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.5035 - accuracy: 0.0000e+00 - val_loss: 1.5011 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.5020 - accuracy: 0.0000e+00\n",
      "Epoch 00255: saving model to training_0_0/cp-0255.ckpt\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.5028 - accuracy: 0.0000e+00 - val_loss: 1.5001 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.5032 - accuracy: 0.0000e+00 - val_loss: 1.5008 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.5011 - accuracy: 0.0000e+00 - val_loss: 1.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.4997 - accuracy: 0.0000e+00 - val_loss: 1.5181 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4995 - accuracy: 0.0000e+00 - val_loss: 1.5039 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/2000\n",
      "241/250 [===========================>..] - ETA: 0s - loss: 1.5096 - accuracy: 0.0000e+00\n",
      "Epoch 00260: saving model to training_0_0/cp-0260.ckpt\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.5001 - accuracy: 0.0000e+00 - val_loss: 1.5025 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.4985 - accuracy: 0.0000e+00 - val_loss: 1.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.4979 - accuracy: 0.0000e+00 - val_loss: 1.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.4976 - accuracy: 0.0000e+00 - val_loss: 1.4959 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4975 - accuracy: 0.0000e+00 - val_loss: 1.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.4886 - accuracy: 0.0000e+00\n",
      "Epoch 00265: saving model to training_0_0/cp-0265.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4970 - accuracy: 0.0000e+00 - val_loss: 1.4972 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4947 - accuracy: 0.0000e+00 - val_loss: 1.4928 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/2000\n",
      "250/250 [==============================] - 0s 746us/step - loss: 1.4955 - accuracy: 0.0000e+00 - val_loss: 1.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.4940 - accuracy: 0.0000e+00 - val_loss: 1.4930 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/2000\n",
      "250/250 [==============================] - 0s 708us/step - loss: 1.4935 - accuracy: 0.0000e+00 - val_loss: 1.5009 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4930 - accuracy: 0.0000e+00\n",
      "Epoch 00270: saving model to training_0_0/cp-0270.ckpt\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.4930 - accuracy: 0.0000e+00 - val_loss: 1.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/2000\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.4924 - accuracy: 0.0000e+00 - val_loss: 1.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.4912 - accuracy: 0.0000e+00 - val_loss: 1.4977 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4908 - accuracy: 0.0000e+00 - val_loss: 1.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/2000\n",
      "250/250 [==============================] - 0s 723us/step - loss: 1.4895 - accuracy: 0.0000e+00 - val_loss: 1.4889 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.5103 - accuracy: 0.0000e+00\n",
      "Epoch 00275: saving model to training_0_0/cp-0275.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.4893 - accuracy: 0.0000e+00 - val_loss: 1.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4894 - accuracy: 0.0000e+00 - val_loss: 1.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/2000\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.4888 - accuracy: 0.0000e+00 - val_loss: 1.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.4876 - accuracy: 0.0000e+00 - val_loss: 1.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.4878 - accuracy: 0.0000e+00 - val_loss: 1.4913 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.4905 - accuracy: 0.0000e+00\n",
      "Epoch 00280: saving model to training_0_0/cp-0280.ckpt\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.4863 - accuracy: 0.0000e+00 - val_loss: 1.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.4854 - accuracy: 0.0000e+00 - val_loss: 1.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/2000\n",
      "250/250 [==============================] - 0s 758us/step - loss: 1.4854 - accuracy: 0.0000e+00 - val_loss: 1.4870 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4851 - accuracy: 0.0000e+00 - val_loss: 1.4952 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.4845 - accuracy: 0.0000e+00 - val_loss: 1.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.4865 - accuracy: 0.0000e+00\n",
      "Epoch 00285: saving model to training_0_0/cp-0285.ckpt\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.4837 - accuracy: 0.0000e+00 - val_loss: 1.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4831 - accuracy: 0.0000e+00 - val_loss: 1.4913 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4832 - accuracy: 0.0000e+00 - val_loss: 1.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4816 - accuracy: 0.0000e+00 - val_loss: 1.4895 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.4805 - accuracy: 0.0000e+00 - val_loss: 1.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.4562 - accuracy: 0.0000e+00\n",
      "Epoch 00290: saving model to training_0_0/cp-0290.ckpt\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.4800 - accuracy: 0.0000e+00 - val_loss: 1.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.4798 - accuracy: 0.0000e+00 - val_loss: 1.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.4792 - accuracy: 0.0000e+00 - val_loss: 1.4993 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4785 - accuracy: 0.0000e+00 - val_loss: 1.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.4785 - accuracy: 0.0000e+00 - val_loss: 1.4930 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.4925 - accuracy: 0.0000e+00\n",
      "Epoch 00295: saving model to training_0_0/cp-0295.ckpt\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.4789 - accuracy: 0.0000e+00 - val_loss: 1.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4775 - accuracy: 0.0000e+00 - val_loss: 1.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.4761 - accuracy: 0.0000e+00 - val_loss: 1.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/2000\n",
      "250/250 [==============================] - 0s 745us/step - loss: 1.4768 - accuracy: 0.0000e+00 - val_loss: 1.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4756 - accuracy: 0.0000e+00 - val_loss: 1.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/2000\n",
      "245/250 [============================>.] - ETA: 0s - loss: 1.4737 - accuracy: 0.0000e+00\n",
      "Epoch 00300: saving model to training_0_0/cp-0300.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.4756 - accuracy: 0.0000e+00 - val_loss: 1.4889 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4745 - accuracy: 0.0000e+00 - val_loss: 1.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.4747 - accuracy: 0.0000e+00 - val_loss: 1.4783 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.4741 - accuracy: 0.0000e+00 - val_loss: 1.4992 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4737 - accuracy: 0.0000e+00 - val_loss: 1.5018 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/2000\n",
      "243/250 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.0000e+00\n",
      "Epoch 00305: saving model to training_0_0/cp-0305.ckpt\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4740 - accuracy: 0.0000e+00 - val_loss: 1.4804 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.4721 - accuracy: 0.0000e+00 - val_loss: 1.5050 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.4728 - accuracy: 0.0000e+00 - val_loss: 1.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.4711 - accuracy: 0.0000e+00 - val_loss: 1.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.4714 - accuracy: 0.0000e+00 - val_loss: 1.4843 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.4818 - accuracy: 0.0000e+00\n",
      "Epoch 00310: saving model to training_0_0/cp-0310.ckpt\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.4705 - accuracy: 0.0000e+00 - val_loss: 1.4772 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.4705 - accuracy: 0.0000e+00 - val_loss: 1.4761 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/2000\n",
      "250/250 [==============================] - 0s 748us/step - loss: 1.4677 - accuracy: 0.0000e+00 - val_loss: 1.4774 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.4685 - accuracy: 0.0000e+00 - val_loss: 1.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/2000\n",
      "250/250 [==============================] - 0s 758us/step - loss: 1.4693 - accuracy: 0.0000e+00 - val_loss: 1.4761 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.4712 - accuracy: 0.0000e+00\n",
      "Epoch 00315: saving model to training_0_0/cp-0315.ckpt\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4681 - accuracy: 0.0000e+00 - val_loss: 1.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.4682 - accuracy: 0.0000e+00 - val_loss: 1.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4669 - accuracy: 0.0000e+00 - val_loss: 1.4756 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4649 - accuracy: 0.0000e+00 - val_loss: 1.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.4666 - accuracy: 0.0000e+00 - val_loss: 1.4836 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.4740 - accuracy: 0.0000e+00\n",
      "Epoch 00320: saving model to training_0_0/cp-0320.ckpt\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.4655 - accuracy: 0.0000e+00 - val_loss: 1.4765 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.4655 - accuracy: 0.0000e+00 - val_loss: 1.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4638 - accuracy: 0.0000e+00 - val_loss: 1.4757 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4645 - accuracy: 0.0000e+00 - val_loss: 1.4758 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4638 - accuracy: 0.0000e+00 - val_loss: 1.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/2000\n",
      "237/250 [===========================>..] - ETA: 0s - loss: 1.4798 - accuracy: 0.0000e+00\n",
      "Epoch 00325: saving model to training_0_0/cp-0325.ckpt\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.4634 - accuracy: 0.0000e+00 - val_loss: 1.4743 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4635 - accuracy: 0.0000e+00 - val_loss: 1.4754 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.4631 - accuracy: 0.0000e+00 - val_loss: 1.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4625 - accuracy: 0.0000e+00 - val_loss: 1.4750 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4622 - accuracy: 0.0000e+00 - val_loss: 1.4787 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.4791 - accuracy: 0.0000e+00\n",
      "Epoch 00330: saving model to training_0_0/cp-0330.ckpt\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.4619 - accuracy: 0.0000e+00 - val_loss: 1.4822 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4613 - accuracy: 0.0000e+00 - val_loss: 1.4739 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4604 - accuracy: 0.0000e+00 - val_loss: 1.4780 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.4610 - accuracy: 0.0000e+00 - val_loss: 1.4817 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.4597 - accuracy: 0.0000e+00 - val_loss: 1.4830 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.4639 - accuracy: 0.0000e+00\n",
      "Epoch 00335: saving model to training_0_0/cp-0335.ckpt\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4595 - accuracy: 0.0000e+00 - val_loss: 1.4752 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4584 - accuracy: 0.0000e+00 - val_loss: 1.4725 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.4582 - accuracy: 0.0000e+00 - val_loss: 1.5044 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4584 - accuracy: 0.0000e+00 - val_loss: 1.4714 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4586 - accuracy: 0.0000e+00 - val_loss: 1.4773 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.4500 - accuracy: 0.0000e+00\n",
      "Epoch 00340: saving model to training_0_0/cp-0340.ckpt\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.4574 - accuracy: 0.0000e+00 - val_loss: 1.4693 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.4575 - accuracy: 0.0000e+00 - val_loss: 1.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4566 - accuracy: 0.0000e+00 - val_loss: 1.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4548 - accuracy: 0.0000e+00 - val_loss: 1.5069 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4556 - accuracy: 0.0000e+00 - val_loss: 1.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/2000\n",
      "237/250 [===========================>..] - ETA: 0s - loss: 1.4373 - accuracy: 0.0000e+00\n",
      "Epoch 00345: saving model to training_0_0/cp-0345.ckpt\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.4557 - accuracy: 0.0000e+00 - val_loss: 1.4725 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.4541 - accuracy: 0.0000e+00 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.4526 - accuracy: 0.0000e+00 - val_loss: 1.4746 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4541 - accuracy: 0.0000e+00 - val_loss: 1.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.4547 - accuracy: 0.0000e+00 - val_loss: 1.4811 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.4530 - accuracy: 0.0000e+00\n",
      "Epoch 00350: saving model to training_0_0/cp-0350.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4535 - accuracy: 0.0000e+00 - val_loss: 1.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4511 - accuracy: 0.0000e+00 - val_loss: 1.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.4531 - accuracy: 0.0000e+00 - val_loss: 1.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4524 - accuracy: 0.0000e+00 - val_loss: 1.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4520 - accuracy: 0.0000e+00 - val_loss: 1.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/2000\n",
      "244/250 [============================>.] - ETA: 0s - loss: 1.4570 - accuracy: 0.0000e+00\n",
      "Epoch 00355: saving model to training_0_0/cp-0355.ckpt\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4514 - accuracy: 0.0000e+00 - val_loss: 1.4658 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.4516 - accuracy: 0.0000e+00 - val_loss: 1.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/2000\n",
      "250/250 [==============================] - 0s 752us/step - loss: 1.4514 - accuracy: 0.0000e+00 - val_loss: 1.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/2000\n",
      "250/250 [==============================] - 0s 752us/step - loss: 1.4499 - accuracy: 0.0000e+00 - val_loss: 1.4730 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.4503 - accuracy: 0.0000e+00 - val_loss: 1.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/2000\n",
      "244/250 [============================>.] - ETA: 0s - loss: 1.4465 - accuracy: 0.0000e+00\n",
      "Epoch 00360: saving model to training_0_0/cp-0360.ckpt\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.4499 - accuracy: 0.0000e+00 - val_loss: 1.4690 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.4503 - accuracy: 0.0000e+00 - val_loss: 1.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4489 - accuracy: 0.0000e+00 - val_loss: 1.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4494 - accuracy: 0.0000e+00 - val_loss: 1.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4480 - accuracy: 0.0000e+00 - val_loss: 1.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.4729 - accuracy: 0.0000e+00\n",
      "Epoch 00365: saving model to training_0_0/cp-0365.ckpt\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.4468 - accuracy: 0.0000e+00 - val_loss: 1.5065 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/2000\n",
      "250/250 [==============================] - 0s 751us/step - loss: 1.4476 - accuracy: 0.0000e+00 - val_loss: 1.4789 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 1.4471 - accuracy: 0.0000e+00 - val_loss: 1.4634 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.4471 - accuracy: 0.0000e+00 - val_loss: 1.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.4476 - accuracy: 0.0000e+00 - val_loss: 1.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.4613 - accuracy: 0.0000e+00\n",
      "Epoch 00370: saving model to training_0_0/cp-0370.ckpt\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.4459 - accuracy: 0.0000e+00 - val_loss: 1.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.4459 - accuracy: 0.0000e+00 - val_loss: 1.4641 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/2000\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.4453 - accuracy: 0.0000e+00 - val_loss: 1.4811 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4459 - accuracy: 0.0000e+00 - val_loss: 1.4659 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.4435 - accuracy: 0.0000e+00 - val_loss: 1.4894 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.4407 - accuracy: 0.0000e+00\n",
      "Epoch 00375: saving model to training_0_0/cp-0375.ckpt\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.4441 - accuracy: 0.0000e+00 - val_loss: 1.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4453 - accuracy: 0.0000e+00 - val_loss: 1.4725 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4441 - accuracy: 0.0000e+00 - val_loss: 1.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.4441 - accuracy: 0.0000e+00 - val_loss: 1.4774 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.4438 - accuracy: 0.0000e+00 - val_loss: 1.4681 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/2000\n",
      "229/250 [==========================>...] - ETA: 0s - loss: 1.4532 - accuracy: 0.0000e+00\n",
      "Epoch 00380: saving model to training_0_0/cp-0380.ckpt\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.4434 - accuracy: 0.0000e+00 - val_loss: 1.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.4429 - accuracy: 0.0000e+00 - val_loss: 1.4638 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.4424 - accuracy: 0.0000e+00 - val_loss: 1.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4419 - accuracy: 0.0000e+00 - val_loss: 1.4602 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.4410 - accuracy: 0.0000e+00 - val_loss: 1.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.4435 - accuracy: 0.0000e+00\n",
      "Epoch 00385: saving model to training_0_0/cp-0385.ckpt\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.4405 - accuracy: 0.0000e+00 - val_loss: 1.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4403 - accuracy: 0.0000e+00 - val_loss: 1.4660 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.4405 - accuracy: 0.0000e+00 - val_loss: 1.4599 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4408 - accuracy: 0.0000e+00 - val_loss: 1.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.4409 - accuracy: 0.0000e+00 - val_loss: 1.4617 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.4356 - accuracy: 0.0000e+00\n",
      "Epoch 00390: saving model to training_0_0/cp-0390.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.4398 - accuracy: 0.0000e+00 - val_loss: 1.4636 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.4405 - accuracy: 0.0000e+00 - val_loss: 1.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4390 - accuracy: 0.0000e+00 - val_loss: 1.4606 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.4377 - accuracy: 0.0000e+00 - val_loss: 1.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.4388 - accuracy: 0.0000e+00 - val_loss: 1.4594 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.4374 - accuracy: 0.0000e+00\n",
      "Epoch 00395: saving model to training_0_0/cp-0395.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.4384 - accuracy: 0.0000e+00 - val_loss: 1.4599 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.4379 - accuracy: 0.0000e+00 - val_loss: 1.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.4382 - accuracy: 0.0000e+00 - val_loss: 1.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4377 - accuracy: 0.0000e+00 - val_loss: 1.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.4375 - accuracy: 0.0000e+00 - val_loss: 1.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.4461 - accuracy: 0.0000e+00\n",
      "Epoch 00400: saving model to training_0_0/cp-0400.ckpt\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.4370 - accuracy: 0.0000e+00 - val_loss: 1.4697 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4354 - accuracy: 0.0000e+00 - val_loss: 1.4896 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.4365 - accuracy: 0.0000e+00 - val_loss: 1.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.4338 - accuracy: 0.0000e+00 - val_loss: 1.4980 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/2000\n",
      "250/250 [==============================] - 0s 766us/step - loss: 1.4364 - accuracy: 0.0000e+00 - val_loss: 1.4586 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/2000\n",
      "244/250 [============================>.] - ETA: 0s - loss: 1.4377 - accuracy: 0.0000e+00\n",
      "Epoch 00405: saving model to training_0_0/cp-0405.ckpt\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.4346 - accuracy: 0.0000e+00 - val_loss: 1.4903 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4359 - accuracy: 0.0000e+00 - val_loss: 1.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4353 - accuracy: 0.0000e+00 - val_loss: 1.4631 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4348 - accuracy: 0.0000e+00 - val_loss: 1.4644 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.4343 - accuracy: 0.0000e+00 - val_loss: 1.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/2000\n",
      "242/250 [============================>.] - ETA: 0s - loss: 1.4194 - accuracy: 0.0000e+00\n",
      "Epoch 00410: saving model to training_0_0/cp-0410.ckpt\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.4341 - accuracy: 0.0000e+00 - val_loss: 1.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.4339 - accuracy: 0.0000e+00 - val_loss: 1.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4332 - accuracy: 0.0000e+00 - val_loss: 1.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.4337 - accuracy: 0.0000e+00 - val_loss: 1.4647 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.4325 - accuracy: 0.0000e+00 - val_loss: 1.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.4256 - accuracy: 0.0000e+00\n",
      "Epoch 00415: saving model to training_0_0/cp-0415.ckpt\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.4328 - accuracy: 0.0000e+00 - val_loss: 1.4611 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4325 - accuracy: 0.0000e+00 - val_loss: 1.4666 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4321 - accuracy: 0.0000e+00 - val_loss: 1.4603 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4316 - accuracy: 0.0000e+00 - val_loss: 1.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.4324 - accuracy: 0.0000e+00 - val_loss: 1.4571 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.4306 - accuracy: 0.0000e+00\n",
      "Epoch 00420: saving model to training_0_0/cp-0420.ckpt\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.4308 - accuracy: 0.0000e+00 - val_loss: 1.4608 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.4298 - accuracy: 0.0000e+00 - val_loss: 1.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.4309 - accuracy: 0.0000e+00 - val_loss: 1.4673 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.4308 - accuracy: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.4298 - accuracy: 0.0000e+00 - val_loss: 1.4572 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.4193 - accuracy: 0.0000e+00\n",
      "Epoch 00425: saving model to training_0_0/cp-0425.ckpt\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.4285 - accuracy: 0.0000e+00 - val_loss: 1.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.4296 - accuracy: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.4292 - accuracy: 0.0000e+00 - val_loss: 1.4578 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.4288 - accuracy: 0.0000e+00 - val_loss: 1.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.4290 - accuracy: 0.0000e+00 - val_loss: 1.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.4172 - accuracy: 0.0000e+00\n",
      "Epoch 00430: saving model to training_0_0/cp-0430.ckpt\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.4274 - accuracy: 0.0000e+00 - val_loss: 1.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.4281 - accuracy: 0.0000e+00 - val_loss: 1.4748 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4278 - accuracy: 0.0000e+00 - val_loss: 1.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.4278 - accuracy: 0.0000e+00 - val_loss: 1.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.4275 - accuracy: 0.0000e+00 - val_loss: 1.4732 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.3832 - accuracy: 0.0000e+00\n",
      "Epoch 00435: saving model to training_0_0/cp-0435.ckpt\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.4262 - accuracy: 0.0000e+00 - val_loss: 1.4557 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.4265 - accuracy: 0.0000e+00 - val_loss: 1.4692 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.4266 - accuracy: 0.0000e+00 - val_loss: 1.4747 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.4268 - accuracy: 0.0000e+00 - val_loss: 1.4581 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4246 - accuracy: 0.0000e+00 - val_loss: 1.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/2000\n",
      "237/250 [===========================>..] - ETA: 0s - loss: 1.4290 - accuracy: 0.0000e+00\n",
      "Epoch 00440: saving model to training_0_0/cp-0440.ckpt\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.4249 - accuracy: 0.0000e+00 - val_loss: 1.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/2000\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.4247 - accuracy: 0.0000e+00 - val_loss: 1.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.4253 - accuracy: 0.0000e+00 - val_loss: 1.4608 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4244 - accuracy: 0.0000e+00 - val_loss: 1.4589 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4226 - accuracy: 0.0000e+00 - val_loss: 1.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.4469 - accuracy: 0.0000e+00\n",
      "Epoch 00445: saving model to training_0_0/cp-0445.ckpt\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.4240 - accuracy: 0.0000e+00 - val_loss: 1.4773 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.4242 - accuracy: 0.0000e+00 - val_loss: 1.4610 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/2000\n",
      "250/250 [==============================] - 0s 738us/step - loss: 1.4234 - accuracy: 0.0000e+00 - val_loss: 1.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4238 - accuracy: 0.0000e+00 - val_loss: 1.4557 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 1.4215 - accuracy: 0.0000e+00 - val_loss: 1.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/2000\n",
      "203/250 [=======================>......] - ETA: 0s - loss: 1.3988 - accuracy: 0.0000e+00\n",
      "Epoch 00450: saving model to training_0_0/cp-0450.ckpt\n",
      "250/250 [==============================] - 0s 957us/step - loss: 1.4234 - accuracy: 0.0000e+00 - val_loss: 1.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.4219 - accuracy: 0.0000e+00 - val_loss: 1.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/2000\n",
      "250/250 [==============================] - 0s 728us/step - loss: 1.4214 - accuracy: 0.0000e+00 - val_loss: 1.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/2000\n",
      "250/250 [==============================] - 0s 740us/step - loss: 1.4209 - accuracy: 0.0000e+00 - val_loss: 1.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.4221 - accuracy: 0.0000e+00 - val_loss: 1.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/2000\n",
      "243/250 [============================>.] - ETA: 0s - loss: 1.4315 - accuracy: 0.0000e+00\n",
      "Epoch 00455: saving model to training_0_0/cp-0455.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4222 - accuracy: 0.0000e+00 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.4215 - accuracy: 0.0000e+00 - val_loss: 1.4569 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.4213 - accuracy: 0.0000e+00 - val_loss: 1.4528 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4199 - accuracy: 0.0000e+00 - val_loss: 1.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.4204 - accuracy: 0.0000e+00 - val_loss: 1.4628 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.4230 - accuracy: 0.0000e+00\n",
      "Epoch 00460: saving model to training_0_0/cp-0460.ckpt\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.4211 - accuracy: 0.0000e+00 - val_loss: 1.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4198 - accuracy: 0.0000e+00 - val_loss: 1.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.4201 - accuracy: 0.0000e+00 - val_loss: 1.4598 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.4197 - accuracy: 0.0000e+00 - val_loss: 1.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4198 - accuracy: 0.0000e+00 - val_loss: 1.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3876 - accuracy: 0.0000e+00\n",
      "Epoch 00465: saving model to training_0_0/cp-0465.ckpt\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.4195 - accuracy: 0.0000e+00 - val_loss: 1.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.4194 - accuracy: 0.0000e+00 - val_loss: 1.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.4187 - accuracy: 0.0000e+00 - val_loss: 1.4619 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.4180 - accuracy: 0.0000e+00 - val_loss: 1.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4171 - accuracy: 0.0000e+00 - val_loss: 1.4576 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.4284 - accuracy: 0.0000e+00\n",
      "Epoch 00470: saving model to training_0_0/cp-0470.ckpt\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.4171 - accuracy: 0.0000e+00 - val_loss: 1.4590 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.4177 - accuracy: 0.0000e+00 - val_loss: 1.4619 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.4173 - accuracy: 0.0000e+00 - val_loss: 1.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.4172 - accuracy: 0.0000e+00 - val_loss: 1.4528 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.4161 - accuracy: 0.0000e+00 - val_loss: 1.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.4267 - accuracy: 0.0000e+00\n",
      "Epoch 00475: saving model to training_0_0/cp-0475.ckpt\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.4154 - accuracy: 0.0000e+00 - val_loss: 1.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.4157 - accuracy: 0.0000e+00 - val_loss: 1.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.4155 - accuracy: 0.0000e+00 - val_loss: 1.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.4163 - accuracy: 0.0000e+00 - val_loss: 1.4651 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.4154 - accuracy: 0.0000e+00 - val_loss: 1.4528 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.4008 - accuracy: 0.0000e+00\n",
      "Epoch 00480: saving model to training_0_0/cp-0480.ckpt\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.4147 - accuracy: 0.0000e+00 - val_loss: 1.4588 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4146 - accuracy: 0.0000e+00 - val_loss: 1.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.4144 - accuracy: 0.0000e+00 - val_loss: 1.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.4143 - accuracy: 0.0000e+00 - val_loss: 1.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.4131 - accuracy: 0.0000e+00 - val_loss: 1.4499 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.3977 - accuracy: 0.0000e+00\n",
      "Epoch 00485: saving model to training_0_0/cp-0485.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.4144 - accuracy: 0.0000e+00 - val_loss: 1.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4137 - accuracy: 0.0000e+00 - val_loss: 1.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.4142 - accuracy: 0.0000e+00 - val_loss: 1.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.4130 - accuracy: 0.0000e+00 - val_loss: 1.4547 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.4134 - accuracy: 0.0000e+00 - val_loss: 1.4609 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.4467 - accuracy: 0.0000e+00\n",
      "Epoch 00490: saving model to training_0_0/cp-0490.ckpt\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.4125 - accuracy: 0.0000e+00 - val_loss: 1.4640 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4131 - accuracy: 0.0000e+00 - val_loss: 1.4564 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.4125 - accuracy: 0.0000e+00 - val_loss: 1.4507 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.4118 - accuracy: 0.0000e+00 - val_loss: 1.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.4123 - accuracy: 0.0000e+00 - val_loss: 1.4606 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.4192 - accuracy: 0.0000e+00\n",
      "Epoch 00495: saving model to training_0_0/cp-0495.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.4114 - accuracy: 0.0000e+00 - val_loss: 1.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.4118 - accuracy: 0.0000e+00 - val_loss: 1.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.4111 - accuracy: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/2000\n",
      "250/250 [==============================] - 0s 750us/step - loss: 1.4101 - accuracy: 0.0000e+00 - val_loss: 1.4556 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.4106 - accuracy: 0.0000e+00 - val_loss: 1.4565 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.3777 - accuracy: 0.0000e+00\n",
      "Epoch 00500: saving model to training_0_0/cp-0500.ckpt\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.4105 - accuracy: 0.0000e+00 - val_loss: 1.4506 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.4105 - accuracy: 0.0000e+00 - val_loss: 1.4484 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.4104 - accuracy: 0.0000e+00 - val_loss: 1.4671 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.4096 - accuracy: 0.0000e+00 - val_loss: 1.4499 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.4096 - accuracy: 0.0000e+00 - val_loss: 1.4493 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.3897 - accuracy: 0.0000e+00\n",
      "Epoch 00505: saving model to training_0_0/cp-0505.ckpt\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.4094 - accuracy: 0.0000e+00 - val_loss: 1.4470 - val_accuracy: 0.0000e+00\n",
      "Epoch 506/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4082 - accuracy: 0.0000e+00 - val_loss: 1.4793 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.4101 - accuracy: 0.0000e+00 - val_loss: 1.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.4094 - accuracy: 0.0000e+00 - val_loss: 1.4507 - val_accuracy: 0.0000e+00\n",
      "Epoch 509/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.4086 - accuracy: 0.0000e+00 - val_loss: 1.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.4107 - accuracy: 0.0000e+00\n",
      "Epoch 00510: saving model to training_0_0/cp-0510.ckpt\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.4078 - accuracy: 0.0000e+00 - val_loss: 1.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.4097 - accuracy: 0.0000e+00 - val_loss: 1.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 512/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.4078 - accuracy: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 513/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.4083 - accuracy: 0.0000e+00 - val_loss: 1.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.4072 - accuracy: 0.0000e+00 - val_loss: 1.4497 - val_accuracy: 0.0000e+00\n",
      "Epoch 515/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.4046 - accuracy: 0.0000e+00\n",
      "Epoch 00515: saving model to training_0_0/cp-0515.ckpt\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.4075 - accuracy: 0.0000e+00 - val_loss: 1.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4079 - accuracy: 0.0000e+00 - val_loss: 1.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.4071 - accuracy: 0.0000e+00 - val_loss: 1.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.4142 - accuracy: 0.0000e+ - 0s 795us/step - loss: 1.4058 - accuracy: 0.0000e+00 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.4067 - accuracy: 0.0000e+00 - val_loss: 1.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.4075 - accuracy: 0.0000e+00\n",
      "Epoch 00520: saving model to training_0_0/cp-0520.ckpt\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.4069 - accuracy: 0.0000e+00 - val_loss: 1.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.4065 - accuracy: 0.0000e+00 - val_loss: 1.4491 - val_accuracy: 0.0000e+00\n",
      "Epoch 522/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.4058 - accuracy: 0.0000e+00 - val_loss: 1.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 523/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.4059 - accuracy: 0.0000e+00 - val_loss: 1.4481 - val_accuracy: 0.0000e+00\n",
      "Epoch 524/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.4057 - accuracy: 0.0000e+00 - val_loss: 1.4507 - val_accuracy: 0.0000e+00\n",
      "Epoch 525/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.4109 - accuracy: 0.0000e+00\n",
      "Epoch 00525: saving model to training_0_0/cp-0525.ckpt\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.4058 - accuracy: 0.0000e+00 - val_loss: 1.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.4045 - accuracy: 0.0000e+00 - val_loss: 1.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.4050 - accuracy: 0.0000e+00 - val_loss: 1.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.4055 - accuracy: 0.0000e+00 - val_loss: 1.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.4049 - accuracy: 0.0000e+00 - val_loss: 1.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.4066 - accuracy: 0.0000e+00\n",
      "Epoch 00530: saving model to training_0_0/cp-0530.ckpt\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.4039 - accuracy: 0.0000e+00 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.4029 - accuracy: 0.0000e+00 - val_loss: 1.4460 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.4024 - accuracy: 0.0000e+00 - val_loss: 1.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4043 - accuracy: 0.0000e+00 - val_loss: 1.4524 - val_accuracy: 0.0000e+00\n",
      "Epoch 534/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.4040 - accuracy: 0.0000e+00 - val_loss: 1.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.4186 - accuracy: 0.0000e+00\n",
      "Epoch 00535: saving model to training_0_0/cp-0535.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 828us/step - loss: 1.4024 - accuracy: 0.0000e+00 - val_loss: 1.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.4033 - accuracy: 0.0000e+00 - val_loss: 1.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.4027 - accuracy: 0.0000e+00 - val_loss: 1.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.4033 - accuracy: 0.0000e+00 - val_loss: 1.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 539/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.4028 - accuracy: 0.0000e+00 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 540/2000\n",
      "242/250 [============================>.] - ETA: 0s - loss: 1.4046 - accuracy: 0.0000e+00\n",
      "Epoch 00540: saving model to training_0_0/cp-0540.ckpt\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.4028 - accuracy: 0.0000e+00 - val_loss: 1.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 541/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.4014 - accuracy: 0.0000e+00 - val_loss: 1.4560 - val_accuracy: 0.0000e+00\n",
      "Epoch 542/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4022 - accuracy: 0.0000e+00 - val_loss: 1.4492 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.4020 - accuracy: 0.0000e+00 - val_loss: 1.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.4021 - accuracy: 0.0000e+00 - val_loss: 1.4455 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.4110 - accuracy: 0.0000e+00\n",
      "Epoch 00545: saving model to training_0_0/cp-0545.ckpt\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.4009 - accuracy: 0.0000e+00 - val_loss: 1.4461 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.4006 - accuracy: 0.0000e+00 - val_loss: 1.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.4018 - accuracy: 0.0000e+00 - val_loss: 1.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.4009 - accuracy: 0.0000e+00 - val_loss: 1.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.4007 - accuracy: 0.0000e+00 - val_loss: 1.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.3823 - accuracy: 0.0000e+00\n",
      "Epoch 00550: saving model to training_0_0/cp-0550.ckpt\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.4009 - accuracy: 0.0000e+00 - val_loss: 1.4488 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.4005 - accuracy: 0.0000e+00 - val_loss: 1.4581 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.3997 - accuracy: 0.0000e+00 - val_loss: 1.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3997 - accuracy: 0.0000e+00 - val_loss: 1.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3996 - accuracy: 0.0000e+00 - val_loss: 1.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3908 - accuracy: 0.0000e+00\n",
      "Epoch 00555: saving model to training_0_0/cp-0555.ckpt\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.3998 - accuracy: 0.0000e+00 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3982 - accuracy: 0.0000e+00 - val_loss: 1.4624 - val_accuracy: 0.0000e+00\n",
      "Epoch 557/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3986 - accuracy: 0.0000e+00 - val_loss: 1.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.3978 - accuracy: 0.0000e+00 - val_loss: 1.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.3980 - accuracy: 0.0000e+00 - val_loss: 1.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.3930 - accuracy: 0.0000e+00\n",
      "Epoch 00560: saving model to training_0_0/cp-0560.ckpt\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3981 - accuracy: 0.0000e+00 - val_loss: 1.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/2000\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.3985 - accuracy: 0.0000e+00 - val_loss: 1.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.3986 - accuracy: 0.0000e+00 - val_loss: 1.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.3966 - accuracy: 0.0000e+00 - val_loss: 1.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3973 - accuracy: 0.0000e+00 - val_loss: 1.4579 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3912 - accuracy: 0.0000e+00\n",
      "Epoch 00565: saving model to training_0_0/cp-0565.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3983 - accuracy: 0.0000e+00 - val_loss: 1.4508 - val_accuracy: 0.0000e+00\n",
      "Epoch 566/2000\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.3975 - accuracy: 0.0000e+00 - val_loss: 1.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/2000\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.3968 - accuracy: 0.0000e+00 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.3972 - accuracy: 0.0000e+00 - val_loss: 1.4436 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.3962 - accuracy: 0.0000e+00 - val_loss: 1.4590 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.3791 - accuracy: 0.0000e+00\n",
      "Epoch 00570: saving model to training_0_0/cp-0570.ckpt\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3956 - accuracy: 0.0000e+00 - val_loss: 1.4431 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3975 - accuracy: 0.0000e+00 - val_loss: 1.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 572/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3963 - accuracy: 0.0000e+00 - val_loss: 1.4539 - val_accuracy: 0.0000e+00\n",
      "Epoch 573/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3939 - accuracy: 0.0000e+00 - val_loss: 1.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 574/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3950 - accuracy: 0.0000e+00 - val_loss: 1.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 575/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.3905 - accuracy: 0.0000e+00\n",
      "Epoch 00575: saving model to training_0_0/cp-0575.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3947 - accuracy: 0.0000e+00 - val_loss: 1.4446 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3955 - accuracy: 0.0000e+00 - val_loss: 1.4449 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.3953 - accuracy: 0.0000e+00 - val_loss: 1.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3960 - accuracy: 0.0000e+00 - val_loss: 1.4539 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3947 - accuracy: 0.0000e+00 - val_loss: 1.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 580/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/250 [=========================>....] - ETA: 0s - loss: 1.3946 - accuracy: 0.0000e+00\n",
      "Epoch 00580: saving model to training_0_0/cp-0580.ckpt\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.3942 - accuracy: 0.0000e+00 - val_loss: 1.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 581/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.3952 - accuracy: 0.0000e+00 - val_loss: 1.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 582/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3941 - accuracy: 0.0000e+00 - val_loss: 1.4571 - val_accuracy: 0.0000e+00\n",
      "Epoch 583/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.3950 - accuracy: 0.0000e+00 - val_loss: 1.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 584/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.3933 - accuracy: 0.0000e+00 - val_loss: 1.4449 - val_accuracy: 0.0000e+00\n",
      "Epoch 585/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.3984 - accuracy: 0.0000e+00\n",
      "Epoch 00585: saving model to training_0_0/cp-0585.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.3940 - accuracy: 0.0000e+00 - val_loss: 1.4435 - val_accuracy: 0.0000e+00\n",
      "Epoch 586/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.3943 - accuracy: 0.0000e+00 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 587/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3935 - accuracy: 0.0000e+00 - val_loss: 1.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 588/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3940 - accuracy: 0.0000e+00 - val_loss: 1.4426 - val_accuracy: 0.0000e+00\n",
      "Epoch 589/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3938 - accuracy: 0.0000e+00 - val_loss: 1.4449 - val_accuracy: 0.0000e+00\n",
      "Epoch 590/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3821 - accuracy: 0.0000e+00\n",
      "Epoch 00590: saving model to training_0_0/cp-0590.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.3928 - accuracy: 0.0000e+00 - val_loss: 1.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 591/2000\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.3929 - accuracy: 0.0000e+00 - val_loss: 1.4426 - val_accuracy: 0.0000e+00\n",
      "Epoch 592/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3924 - accuracy: 0.0000e+00 - val_loss: 1.4427 - val_accuracy: 0.0000e+00\n",
      "Epoch 593/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.3858 - accuracy: 0.0000e+ - 0s 795us/step - loss: 1.3929 - accuracy: 0.0000e+00 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 594/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3924 - accuracy: 0.0000e+00 - val_loss: 1.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 595/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.4041 - accuracy: 0.0000e+00\n",
      "Epoch 00595: saving model to training_0_0/cp-0595.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3918 - accuracy: 0.0000e+00 - val_loss: 1.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 596/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3925 - accuracy: 0.0000e+00 - val_loss: 1.4514 - val_accuracy: 0.0000e+00\n",
      "Epoch 597/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.3914 - accuracy: 0.0000e+00 - val_loss: 1.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3918 - accuracy: 0.0000e+00 - val_loss: 1.4462 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.3911 - accuracy: 0.0000e+00 - val_loss: 1.4433 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.3891 - accuracy: 0.0000e+00\n",
      "Epoch 00600: saving model to training_0_0/cp-0600.ckpt\n",
      "250/250 [==============================] - 0s 891us/step - loss: 1.3911 - accuracy: 0.0000e+00 - val_loss: 1.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/2000\n",
      "250/250 [==============================] - 0s 876us/step - loss: 1.3916 - accuracy: 0.0000e+00 - val_loss: 1.4594 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.3916 - accuracy: 0.0000e+00 - val_loss: 1.4591 - val_accuracy: 0.0000e+00\n",
      "Epoch 603/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3903 - accuracy: 0.0000e+00 - val_loss: 1.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 604/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3911 - accuracy: 0.0000e+00 - val_loss: 1.4479 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/2000\n",
      "229/250 [==========================>...] - ETA: 0s - loss: 1.3976 - accuracy: 0.0000e+00\n",
      "Epoch 00605: saving model to training_0_0/cp-0605.ckpt\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3898 - accuracy: 0.0000e+00 - val_loss: 1.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 606/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.3904 - accuracy: 0.0000e+00 - val_loss: 1.4461 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3902 - accuracy: 0.0000e+00 - val_loss: 1.4465 - val_accuracy: 0.0000e+00\n",
      "Epoch 608/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3904 - accuracy: 0.0000e+00 - val_loss: 1.4496 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3910 - accuracy: 0.0000e+00 - val_loss: 1.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3804 - accuracy: 0.0000e+00\n",
      "Epoch 00610: saving model to training_0_0/cp-0610.ckpt\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.3890 - accuracy: 0.0000e+00 - val_loss: 1.4393 - val_accuracy: 0.0000e+00\n",
      "Epoch 611/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.3887 - accuracy: 0.0000e+00 - val_loss: 1.4589 - val_accuracy: 0.0000e+00\n",
      "Epoch 612/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.3889 - accuracy: 0.0000e+00 - val_loss: 1.4392 - val_accuracy: 0.0000e+00\n",
      "Epoch 613/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.3893 - accuracy: 0.0000e+00 - val_loss: 1.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 614/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3890 - accuracy: 0.0000e+00 - val_loss: 1.4481 - val_accuracy: 0.0000e+00\n",
      "Epoch 615/2000\n",
      "229/250 [==========================>...] - ETA: 0s - loss: 1.3868 - accuracy: 0.0000e+00\n",
      "Epoch 00615: saving model to training_0_0/cp-0615.ckpt\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.3892 - accuracy: 0.0000e+00 - val_loss: 1.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 616/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3883 - accuracy: 0.0000e+00 - val_loss: 1.4462 - val_accuracy: 0.0000e+00\n",
      "Epoch 617/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3872 - accuracy: 0.0000e+00 - val_loss: 1.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 618/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3876 - accuracy: 0.0000e+00 - val_loss: 1.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 619/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.3881 - accuracy: 0.0000e+00 - val_loss: 1.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 620/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.4196 - accuracy: 0.0000e+00\n",
      "Epoch 00620: saving model to training_0_0/cp-0620.ckpt\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3881 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 621/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3878 - accuracy: 0.0000e+00 - val_loss: 1.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3886 - accuracy: 0.0000e+00 - val_loss: 1.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/2000\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.3870 - accuracy: 0.0000e+00 - val_loss: 1.4441 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 785us/step - loss: 1.3873 - accuracy: 0.0000e+00 - val_loss: 1.4385 - val_accuracy: 0.0000e+00\n",
      "Epoch 625/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3702 - accuracy: 0.0000e+00\n",
      "Epoch 00625: saving model to training_0_0/cp-0625.ckpt\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3860 - accuracy: 0.0000e+00 - val_loss: 1.4666 - val_accuracy: 0.0000e+00\n",
      "Epoch 626/2000\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.3872 - accuracy: 0.0000e+00 - val_loss: 1.4646 - val_accuracy: 0.0000e+00\n",
      "Epoch 627/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.3873 - accuracy: 0.0000e+00 - val_loss: 1.4394 - val_accuracy: 0.0000e+00\n",
      "Epoch 628/2000\n",
      "250/250 [==============================] - 0s 776us/step - loss: 1.3867 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 629/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3859 - accuracy: 0.0000e+00 - val_loss: 1.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.3833 - accuracy: 0.0000e+00\n",
      "Epoch 00630: saving model to training_0_0/cp-0630.ckpt\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.3861 - accuracy: 0.0000e+00 - val_loss: 1.4496 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.3863 - accuracy: 0.0000e+00 - val_loss: 1.4572 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3867 - accuracy: 0.0000e+00 - val_loss: 1.4392 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.3857 - accuracy: 0.0000e+00 - val_loss: 1.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3861 - accuracy: 0.0000e+00 - val_loss: 1.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.3745 - accuracy: 0.0000e+00\n",
      "Epoch 00635: saving model to training_0_0/cp-0635.ckpt\n",
      "250/250 [==============================] - 0s 932us/step - loss: 1.3858 - accuracy: 0.0000e+00 - val_loss: 1.4392 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3856 - accuracy: 0.0000e+00 - val_loss: 1.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3856 - accuracy: 0.0000e+00 - val_loss: 1.4445 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3850 - accuracy: 0.0000e+00 - val_loss: 1.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3849 - accuracy: 0.0000e+00 - val_loss: 1.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.3806 - accuracy: 0.0000e+00\n",
      "Epoch 00640: saving model to training_0_0/cp-0640.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3833 - accuracy: 0.0000e+00 - val_loss: 1.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 641/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3849 - accuracy: 0.0000e+00 - val_loss: 1.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 642/2000\n",
      "250/250 [==============================] - 0s 758us/step - loss: 1.3852 - accuracy: 0.0000e+00 - val_loss: 1.4443 - val_accuracy: 0.0000e+00\n",
      "Epoch 643/2000\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.3835 - accuracy: 0.0000e+00 - val_loss: 1.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 644/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.3828 - accuracy: 0.0000e+00 - val_loss: 1.4488 - val_accuracy: 0.0000e+00\n",
      "Epoch 645/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3925 - accuracy: 0.0000e+00\n",
      "Epoch 00645: saving model to training_0_0/cp-0645.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3827 - accuracy: 0.0000e+00 - val_loss: 1.4709 - val_accuracy: 0.0000e+00\n",
      "Epoch 646/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3838 - accuracy: 0.0000e+00 - val_loss: 1.4496 - val_accuracy: 0.0000e+00\n",
      "Epoch 647/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3837 - accuracy: 0.0000e+00 - val_loss: 1.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 648/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3842 - accuracy: 0.0000e+00 - val_loss: 1.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 649/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3827 - accuracy: 0.0000e+00 - val_loss: 1.4430 - val_accuracy: 0.0000e+00\n",
      "Epoch 650/2000\n",
      "241/250 [===========================>..] - ETA: 0s - loss: 1.3975 - accuracy: 0.0000e+00\n",
      "Epoch 00650: saving model to training_0_0/cp-0650.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3837 - accuracy: 0.0000e+00 - val_loss: 1.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 651/2000\n",
      "250/250 [==============================] - 0s 894us/step - loss: 1.3837 - accuracy: 0.0000e+00 - val_loss: 1.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 652/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.3829 - accuracy: 0.0000e+00 - val_loss: 1.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 653/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3823 - accuracy: 0.0000e+00 - val_loss: 1.4455 - val_accuracy: 0.0000e+00\n",
      "Epoch 654/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.3826 - accuracy: 0.0000e+00 - val_loss: 1.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 655/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.3790 - accuracy: 0.0000e+00\n",
      "Epoch 00655: saving model to training_0_0/cp-0655.ckpt\n",
      "250/250 [==============================] - 0s 919us/step - loss: 1.3820 - accuracy: 0.0000e+00 - val_loss: 1.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 656/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3816 - accuracy: 0.0000e+00 - val_loss: 1.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 657/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3818 - accuracy: 0.0000e+00 - val_loss: 1.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 658/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3818 - accuracy: 0.0000e+00 - val_loss: 1.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 659/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3804 - accuracy: 0.0000e+00 - val_loss: 1.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 660/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.3607 - accuracy: 0.0000e+00\n",
      "Epoch 00660: saving model to training_0_0/cp-0660.ckpt\n",
      "250/250 [==============================] - 0s 927us/step - loss: 1.3806 - accuracy: 0.0000e+00 - val_loss: 1.4587 - val_accuracy: 0.0000e+00\n",
      "Epoch 661/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.3817 - accuracy: 0.0000e+00 - val_loss: 1.4384 - val_accuracy: 0.0000e+00\n",
      "Epoch 662/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3814 - accuracy: 0.0000e+00 - val_loss: 1.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3817 - accuracy: 0.0000e+00 - val_loss: 1.4582 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.3817 - accuracy: 0.0000e+00 - val_loss: 1.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.3353 - accuracy: 0.0000e+00\n",
      "Epoch 00665: saving model to training_0_0/cp-0665.ckpt\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 1.3806 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 666/2000\n",
      "250/250 [==============================] - 0s 892us/step - loss: 1.3797 - accuracy: 0.0000e+00 - val_loss: 1.4410 - val_accuracy: 0.0000e+00\n",
      "Epoch 667/2000\n",
      "250/250 [==============================] - 0s 747us/step - loss: 1.3807 - accuracy: 0.0000e+00 - val_loss: 1.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 668/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 781us/step - loss: 1.3807 - accuracy: 0.0000e+00 - val_loss: 1.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 669/2000\n",
      "250/250 [==============================] - 0s 731us/step - loss: 1.3806 - accuracy: 0.0000e+00 - val_loss: 1.4462 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/2000\n",
      "170/250 [===================>..........] - ETA: 0s - loss: 1.3424 - accuracy: 0.0000e+00\n",
      "Epoch 00670: saving model to training_0_0/cp-0670.ckpt\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.3796 - accuracy: 0.0000e+00 - val_loss: 1.4376 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.3803 - accuracy: 0.0000e+00 - val_loss: 1.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.3792 - accuracy: 0.0000e+00 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 673/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.3795 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 674/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3795 - accuracy: 0.0000e+00 - val_loss: 1.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 675/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3818 - accuracy: 0.0000e+00\n",
      "Epoch 00675: saving model to training_0_0/cp-0675.ckpt\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.3798 - accuracy: 0.0000e+00 - val_loss: 1.4362 - val_accuracy: 0.0000e+00\n",
      "Epoch 676/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.3795 - accuracy: 0.0000e+00 - val_loss: 1.4378 - val_accuracy: 0.0000e+00\n",
      "Epoch 677/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3789 - accuracy: 0.0000e+00 - val_loss: 1.4632 - val_accuracy: 0.0000e+00\n",
      "Epoch 678/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3788 - accuracy: 0.0000e+00 - val_loss: 1.4531 - val_accuracy: 0.0000e+00\n",
      "Epoch 679/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3778 - accuracy: 0.0000e+00 - val_loss: 1.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 680/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3888 - accuracy: 0.0000e+00\n",
      "Epoch 00680: saving model to training_0_0/cp-0680.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3774 - accuracy: 0.0000e+00 - val_loss: 1.4455 - val_accuracy: 0.0000e+00\n",
      "Epoch 681/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3777 - accuracy: 0.0000e+00 - val_loss: 1.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 682/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3784 - accuracy: 0.0000e+00 - val_loss: 1.4424 - val_accuracy: 0.0000e+00\n",
      "Epoch 683/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3774 - accuracy: 0.0000e+00 - val_loss: 1.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.3776 - accuracy: 0.0000e+00 - val_loss: 1.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3710 - accuracy: 0.0000e+00\n",
      "Epoch 00685: saving model to training_0_0/cp-0685.ckpt\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3777 - accuracy: 0.0000e+00 - val_loss: 1.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 686/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3774 - accuracy: 0.0000e+00 - val_loss: 1.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 687/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3773 - accuracy: 0.0000e+00 - val_loss: 1.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 688/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3769 - accuracy: 0.0000e+00 - val_loss: 1.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 689/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3762 - accuracy: 0.0000e+00 - val_loss: 1.4573 - val_accuracy: 0.0000e+00\n",
      "Epoch 690/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3993 - accuracy: 0.0000e+00\n",
      "Epoch 00690: saving model to training_0_0/cp-0690.ckpt\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3760 - accuracy: 0.0000e+00 - val_loss: 1.4405 - val_accuracy: 0.0000e+00\n",
      "Epoch 691/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3765 - accuracy: 0.0000e+00 - val_loss: 1.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 692/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3774 - accuracy: 0.0000e+00 - val_loss: 1.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 693/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.3769 - accuracy: 0.0000e+00 - val_loss: 1.4466 - val_accuracy: 0.0000e+00\n",
      "Epoch 694/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3770 - accuracy: 0.0000e+00 - val_loss: 1.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 695/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3987 - accuracy: 0.0000e+00\n",
      "Epoch 00695: saving model to training_0_0/cp-0695.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3764 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 696/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3766 - accuracy: 0.0000e+00 - val_loss: 1.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3757 - accuracy: 0.0000e+00 - val_loss: 1.4353 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.3754 - accuracy: 0.0000e+00 - val_loss: 1.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3756 - accuracy: 0.0000e+00 - val_loss: 1.4481 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3859 - accuracy: 0.0000e+00\n",
      "Epoch 00700: saving model to training_0_0/cp-0700.ckpt\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3764 - accuracy: 0.0000e+00 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 701/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3759 - accuracy: 0.0000e+00 - val_loss: 1.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 702/2000\n",
      "250/250 [==============================] - 0s 757us/step - loss: 1.3756 - accuracy: 0.0000e+00 - val_loss: 1.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 703/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3755 - accuracy: 0.0000e+00 - val_loss: 1.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 704/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3751 - accuracy: 0.0000e+00 - val_loss: 1.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 705/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.4084 - accuracy: 0.0000e+00\n",
      "Epoch 00705: saving model to training_0_0/cp-0705.ckpt\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.3746 - accuracy: 0.0000e+00 - val_loss: 1.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 706/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.3747 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 707/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.3745 - accuracy: 0.0000e+00 - val_loss: 1.4405 - val_accuracy: 0.0000e+00\n",
      "Epoch 708/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3746 - accuracy: 0.0000e+00 - val_loss: 1.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 709/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3741 - accuracy: 0.0000e+00 - val_loss: 1.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 710/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3800 - accuracy: 0.0000e+00\n",
      "Epoch 00710: saving model to training_0_0/cp-0710.ckpt\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.3730 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 711/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3746 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 712/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 809us/step - loss: 1.3737 - accuracy: 0.0000e+00 - val_loss: 1.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 713/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3726 - accuracy: 0.0000e+00 - val_loss: 1.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 714/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.3728 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 715/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3693 - accuracy: 0.0000e+00\n",
      "Epoch 00715: saving model to training_0_0/cp-0715.ckpt\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3736 - accuracy: 0.0000e+00 - val_loss: 1.4376 - val_accuracy: 0.0000e+00\n",
      "Epoch 716/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.3729 - accuracy: 0.0000e+00 - val_loss: 1.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 717/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3720 - accuracy: 0.0000e+00 - val_loss: 1.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 718/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3736 - accuracy: 0.0000e+00 - val_loss: 1.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 719/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3733 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 720/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3570 - accuracy: 0.0000e+00\n",
      "Epoch 00720: saving model to training_0_0/cp-0720.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.3728 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 721/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.3716 - accuracy: 0.0000e+00 - val_loss: 1.4557 - val_accuracy: 0.0000e+00\n",
      "Epoch 722/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3712 - accuracy: 0.0000e+00 - val_loss: 1.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 723/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3719 - accuracy: 0.0000e+00 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 724/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.3722 - accuracy: 0.0000e+00 - val_loss: 1.4456 - val_accuracy: 0.0000e+00\n",
      "Epoch 725/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.3877 - accuracy: 0.0000e+00\n",
      "Epoch 00725: saving model to training_0_0/cp-0725.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.3700 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 726/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.3723 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 727/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3717 - accuracy: 0.0000e+00 - val_loss: 1.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 728/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.3705 - accuracy: 0.0000e+00 - val_loss: 1.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 729/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.3712 - accuracy: 0.0000e+00 - val_loss: 1.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 730/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.3627 - accuracy: 0.0000e+00\n",
      "Epoch 00730: saving model to training_0_0/cp-0730.ckpt\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3704 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 731/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3712 - accuracy: 0.0000e+00 - val_loss: 1.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 732/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3714 - accuracy: 0.0000e+00 - val_loss: 1.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 733/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.3713 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 734/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3708 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 735/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.3460 - accuracy: 0.0000e+00\n",
      "Epoch 00735: saving model to training_0_0/cp-0735.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.3702 - accuracy: 0.0000e+00 - val_loss: 1.4341 - val_accuracy: 0.0000e+00\n",
      "Epoch 736/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.3705 - accuracy: 0.0000e+00 - val_loss: 1.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 737/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.3698 - accuracy: 0.0000e+00 - val_loss: 1.4340 - val_accuracy: 0.0000e+00\n",
      "Epoch 738/2000\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3695 - accuracy: 0.0000e+00 - val_loss: 1.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 739/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.3692 - accuracy: 0.0000e+00 - val_loss: 1.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 740/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3710 - accuracy: 0.0000e+00\n",
      "Epoch 00740: saving model to training_0_0/cp-0740.ckpt\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3695 - accuracy: 0.0000e+00 - val_loss: 1.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 741/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3702 - accuracy: 0.0000e+00 - val_loss: 1.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 742/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.3699 - accuracy: 0.0000e+00 - val_loss: 1.4431 - val_accuracy: 0.0000e+00\n",
      "Epoch 743/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.3700 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 744/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3686 - accuracy: 0.0000e+00 - val_loss: 1.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 745/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3255 - accuracy: 0.0000e+00\n",
      "Epoch 00745: saving model to training_0_0/cp-0745.ckpt\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.3677 - accuracy: 0.0000e+00 - val_loss: 1.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 746/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.3690 - accuracy: 0.0000e+00 - val_loss: 1.4412 - val_accuracy: 0.0000e+00\n",
      "Epoch 747/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3685 - accuracy: 0.0000e+00 - val_loss: 1.4356 - val_accuracy: 0.0000e+00\n",
      "Epoch 748/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3685 - accuracy: 0.0000e+00 - val_loss: 1.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 749/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3686 - accuracy: 0.0000e+00 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 750/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.3764 - accuracy: 0.0000e+00\n",
      "Epoch 00750: saving model to training_0_0/cp-0750.ckpt\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3681 - accuracy: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 751/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3686 - accuracy: 0.0000e+00 - val_loss: 1.4364 - val_accuracy: 0.0000e+00\n",
      "Epoch 752/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3680 - accuracy: 0.0000e+00 - val_loss: 1.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 753/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3680 - accuracy: 0.0000e+00 - val_loss: 1.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 754/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3664 - accuracy: 0.0000e+00 - val_loss: 1.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 755/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3817 - accuracy: 0.0000e+00\n",
      "Epoch 00755: saving model to training_0_0/cp-0755.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.3660 - accuracy: 0.0000e+00 - val_loss: 1.4617 - val_accuracy: 0.0000e+00\n",
      "Epoch 756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 757us/step - loss: 1.3679 - accuracy: 0.0000e+00 - val_loss: 1.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 757/2000\n",
      "250/250 [==============================] - 0s 743us/step - loss: 1.3671 - accuracy: 0.0000e+00 - val_loss: 1.4561 - val_accuracy: 0.0000e+00\n",
      "Epoch 758/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.3663 - accuracy: 0.0000e+00 - val_loss: 1.4410 - val_accuracy: 0.0000e+00\n",
      "Epoch 759/2000\n",
      "250/250 [==============================] - 0s 735us/step - loss: 1.3662 - accuracy: 0.0000e+00 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 760/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.3572 - accuracy: 0.0000e+00\n",
      "Epoch 00760: saving model to training_0_0/cp-0760.ckpt\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3667 - accuracy: 0.0000e+00 - val_loss: 1.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 761/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.3666 - accuracy: 0.0000e+00 - val_loss: 1.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 762/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3668 - accuracy: 0.0000e+00 - val_loss: 1.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 763/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.3663 - accuracy: 0.0000e+00 - val_loss: 1.4361 - val_accuracy: 0.0000e+00\n",
      "Epoch 764/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.3663 - accuracy: 0.0000e+00 - val_loss: 1.4330 - val_accuracy: 0.0000e+00\n",
      "Epoch 765/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3497 - accuracy: 0.0000e+00\n",
      "Epoch 00765: saving model to training_0_0/cp-0765.ckpt\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3662 - accuracy: 0.0000e+00 - val_loss: 1.4389 - val_accuracy: 0.0000e+00\n",
      "Epoch 766/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3665 - accuracy: 0.0000e+00 - val_loss: 1.4403 - val_accuracy: 0.0000e+00\n",
      "Epoch 767/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.3668 - accuracy: 0.0000e+00 - val_loss: 1.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 768/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.3646 - accuracy: 0.0000e+00 - val_loss: 1.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 769/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.3646 - accuracy: 0.0000e+00 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 770/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.3351 - accuracy: 0.0000e+00\n",
      "Epoch 00770: saving model to training_0_0/cp-0770.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.3647 - accuracy: 0.0000e+00 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 771/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.3650 - accuracy: 0.0000e+00 - val_loss: 1.4466 - val_accuracy: 0.0000e+00\n",
      "Epoch 772/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3646 - accuracy: 0.0000e+00 - val_loss: 1.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 773/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3648 - accuracy: 0.0000e+00 - val_loss: 1.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 774/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.3643 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 775/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3656 - accuracy: 0.0000e+00\n",
      "Epoch 00775: saving model to training_0_0/cp-0775.ckpt\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3643 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 776/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.3646 - accuracy: 0.0000e+00 - val_loss: 1.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 777/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3640 - accuracy: 0.0000e+00 - val_loss: 1.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 778/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3640 - accuracy: 0.0000e+00 - val_loss: 1.4332 - val_accuracy: 0.0000e+00\n",
      "Epoch 779/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3639 - accuracy: 0.0000e+00 - val_loss: 1.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 780/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3558 - accuracy: 0.0000e+00\n",
      "Epoch 00780: saving model to training_0_0/cp-0780.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3636 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 781/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3627 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 782/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.3634 - accuracy: 0.0000e+00 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 783/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3634 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 784/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.3625 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 785/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.3601 - accuracy: 0.0000e+00\n",
      "Epoch 00785: saving model to training_0_0/cp-0785.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.3629 - accuracy: 0.0000e+00 - val_loss: 1.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 786/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3634 - accuracy: 0.0000e+00 - val_loss: 1.4358 - val_accuracy: 0.0000e+00\n",
      "Epoch 787/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.3618 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 788/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3630 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 789/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.3614 - accuracy: 0.0000e+00 - val_loss: 1.4572 - val_accuracy: 0.0000e+00\n",
      "Epoch 790/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3547 - accuracy: 0.0000e+00\n",
      "Epoch 00790: saving model to training_0_0/cp-0790.ckpt\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.3620 - accuracy: 0.0000e+00 - val_loss: 1.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 791/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3622 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 792/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3624 - accuracy: 0.0000e+00 - val_loss: 1.4367 - val_accuracy: 0.0000e+00\n",
      "Epoch 793/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3625 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 794/2000\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.3622 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 795/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3816 - accuracy: 0.0000e+00\n",
      "Epoch 00795: saving model to training_0_0/cp-0795.ckpt\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3606 - accuracy: 0.0000e+00 - val_loss: 1.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 796/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3614 - accuracy: 0.0000e+00 - val_loss: 1.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 797/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.3614 - accuracy: 0.0000e+00 - val_loss: 1.4449 - val_accuracy: 0.0000e+00\n",
      "Epoch 798/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3609 - accuracy: 0.0000e+00 - val_loss: 1.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 799/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.3615 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 800/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.3381 - accuracy: 0.0000e+00\n",
      "Epoch 00800: saving model to training_0_0/cp-0800.ckpt\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3604 - accuracy: 0.0000e+00 - val_loss: 1.4328 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3608 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 802/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.3599 - accuracy: 0.0000e+00 - val_loss: 1.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 803/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.3595 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 804/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3605 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 805/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.3626 - accuracy: 0.0000e+00\n",
      "Epoch 00805: saving model to training_0_0/cp-0805.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3598 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 806/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3596 - accuracy: 0.0000e+00 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 807/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3597 - accuracy: 0.0000e+00 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 808/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3597 - accuracy: 0.0000e+00 - val_loss: 1.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 809/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3594 - accuracy: 0.0000e+00 - val_loss: 1.4517 - val_accuracy: 0.0000e+00\n",
      "Epoch 810/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3649 - accuracy: 0.0000e+00\n",
      "Epoch 00810: saving model to training_0_0/cp-0810.ckpt\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.3595 - accuracy: 0.0000e+00 - val_loss: 1.4379 - val_accuracy: 0.0000e+00\n",
      "Epoch 811/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3585 - accuracy: 0.0000e+00 - val_loss: 1.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 812/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3582 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 813/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.3589 - accuracy: 0.0000e+00 - val_loss: 1.4308 - val_accuracy: 0.0000e+00\n",
      "Epoch 814/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.3576 - accuracy: 0.0000e+00 - val_loss: 1.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 815/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.3721 - accuracy: 0.0000e+00\n",
      "Epoch 00815: saving model to training_0_0/cp-0815.ckpt\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.3568 - accuracy: 0.0000e+00 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 816/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3579 - accuracy: 0.0000e+00 - val_loss: 1.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 817/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3573 - accuracy: 0.0000e+00 - val_loss: 1.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 818/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3587 - accuracy: 0.0000e+00 - val_loss: 1.4354 - val_accuracy: 0.0000e+00\n",
      "Epoch 819/2000\n",
      "250/250 [==============================] - 0s 772us/step - loss: 1.3578 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 820/2000\n",
      "209/250 [========================>.....] - ETA: 0s - loss: 1.3807 - accuracy: 0.0000e+00\n",
      "Epoch 00820: saving model to training_0_0/cp-0820.ckpt\n",
      "250/250 [==============================] - 0s 897us/step - loss: 1.3578 - accuracy: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 821/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3567 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 822/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3580 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 823/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3584 - accuracy: 0.0000e+00 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 824/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3570 - accuracy: 0.0000e+00 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 825/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.3355 - accuracy: 0.0000e+00\n",
      "Epoch 00825: saving model to training_0_0/cp-0825.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3571 - accuracy: 0.0000e+00 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 826/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.3570 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 827/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3578 - accuracy: 0.0000e+00 - val_loss: 1.4446 - val_accuracy: 0.0000e+00\n",
      "Epoch 828/2000\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3572 - accuracy: 0.0000e+00 - val_loss: 1.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 829/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.3558 - accuracy: 0.0000e+00 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 830/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3312 - accuracy: 0.0000e+00\n",
      "Epoch 00830: saving model to training_0_0/cp-0830.ckpt\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.3564 - accuracy: 0.0000e+00 - val_loss: 1.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 831/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.3566 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 832/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3561 - accuracy: 0.0000e+00 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 833/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3567 - accuracy: 0.0000e+00 - val_loss: 1.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 834/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.3556 - accuracy: 0.0000e+00 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 835/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3890 - accuracy: 0.0000e+00\n",
      "Epoch 00835: saving model to training_0_0/cp-0835.ckpt\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.3544 - accuracy: 0.0000e+00 - val_loss: 1.4349 - val_accuracy: 0.0000e+00\n",
      "Epoch 836/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3560 - accuracy: 0.0000e+00 - val_loss: 1.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 837/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3559 - accuracy: 0.0000e+00 - val_loss: 1.4550 - val_accuracy: 0.0000e+00\n",
      "Epoch 838/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3554 - accuracy: 0.0000e+00 - val_loss: 1.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 839/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3556 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 840/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3944 - accuracy: 0.0000e+00\n",
      "Epoch 00840: saving model to training_0_0/cp-0840.ckpt\n",
      "250/250 [==============================] - 0s 860us/step - loss: 1.3551 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 841/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3546 - accuracy: 0.0000e+00 - val_loss: 1.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 842/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.3552 - accuracy: 0.0000e+00 - val_loss: 1.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 843/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3537 - accuracy: 0.0000e+00 - val_loss: 1.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 844/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3537 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 845/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.3454 - accuracy: 0.0000e+00\n",
      "Epoch 00845: saving model to training_0_0/cp-0845.ckpt\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.3544 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3536 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 847/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3547 - accuracy: 0.0000e+00 - val_loss: 1.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 848/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.3525 - accuracy: 0.0000e+00 - val_loss: 1.4445 - val_accuracy: 0.0000e+00\n",
      "Epoch 849/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3547 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 850/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3459 - accuracy: 0.0000e+00\n",
      "Epoch 00850: saving model to training_0_0/cp-0850.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3536 - accuracy: 0.0000e+00 - val_loss: 1.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 851/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.3535 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_accuracy: 0.0000e+00\n",
      "Epoch 852/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3531 - accuracy: 0.0000e+00 - val_loss: 1.4397 - val_accuracy: 0.0000e+00\n",
      "Epoch 853/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3531 - accuracy: 0.0000e+00 - val_loss: 1.4421 - val_accuracy: 0.0000e+00\n",
      "Epoch 854/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3531 - accuracy: 0.0000e+00 - val_loss: 1.4479 - val_accuracy: 0.0000e+00\n",
      "Epoch 855/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3508 - accuracy: 0.0000e+00\n",
      "Epoch 00855: saving model to training_0_0/cp-0855.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3525 - accuracy: 0.0000e+00 - val_loss: 1.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 856/2000\n",
      "250/250 [==============================] - 0s 900us/step - loss: 1.3530 - accuracy: 0.0000e+00 - val_loss: 1.4330 - val_accuracy: 0.0000e+00\n",
      "Epoch 857/2000\n",
      "250/250 [==============================] - 0s 980us/step - loss: 1.3529 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 858/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3512 - accuracy: 0.0000e+00 - val_loss: 1.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 859/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3508 - accuracy: 0.0000e+00 - val_loss: 1.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 860/2000\n",
      "249/250 [============================>.] - ETA: 0s - loss: 1.3527 - accuracy: 0.0000e+00\n",
      "Epoch 00860: saving model to training_0_0/cp-0860.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.3522 - accuracy: 0.0000e+00 - val_loss: 1.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 861/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3527 - accuracy: 0.0000e+00 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 862/2000\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.3523 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 863/2000\n",
      "250/250 [==============================] - 0s 897us/step - loss: 1.3521 - accuracy: 0.0000e+00 - val_loss: 1.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 864/2000\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.3502 - accuracy: 0.0000e+00 - val_loss: 1.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 865/2000\n",
      "238/250 [===========================>..] - ETA: 0s - loss: 1.3322 - accuracy: 0.0000e+00\n",
      "Epoch 00865: saving model to training_0_0/cp-0865.ckpt\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3514 - accuracy: 0.0000e+00 - val_loss: 1.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 866/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3516 - accuracy: 0.0000e+00 - val_loss: 1.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 867/2000\n",
      "250/250 [==============================] - 0s 739us/step - loss: 1.3512 - accuracy: 0.0000e+00 - val_loss: 1.4367 - val_accuracy: 0.0000e+00\n",
      "Epoch 868/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.3496 - accuracy: 0.0000e+00 - val_loss: 1.4375 - val_accuracy: 0.0000e+00\n",
      "Epoch 869/2000\n",
      "250/250 [==============================] - 0s 764us/step - loss: 1.3511 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 870/2000\n",
      "235/250 [===========================>..] - ETA: 0s - loss: 1.3627 - accuracy: 0.0000e+00\n",
      "Epoch 00870: saving model to training_0_0/cp-0870.ckpt\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.3503 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 871/2000\n",
      "250/250 [==============================] - 0s 742us/step - loss: 1.3502 - accuracy: 0.0000e+00 - val_loss: 1.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 872/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.3499 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 873/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3503 - accuracy: 0.0000e+00 - val_loss: 1.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 874/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.3498 - accuracy: 0.0000e+00 - val_loss: 1.4358 - val_accuracy: 0.0000e+00\n",
      "Epoch 875/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3418 - accuracy: 0.0000e+00\n",
      "Epoch 00875: saving model to training_0_0/cp-0875.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3500 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_accuracy: 0.0000e+00\n",
      "Epoch 876/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3502 - accuracy: 0.0000e+00 - val_loss: 1.4327 - val_accuracy: 0.0000e+00\n",
      "Epoch 877/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.3491 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 878/2000\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.3497 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 879/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3482 - accuracy: 0.0000e+00 - val_loss: 1.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 880/2000\n",
      "200/250 [=======================>......] - ETA: 0s - loss: 1.3959 - accuracy: 0.0000e+00\n",
      "Epoch 00880: saving model to training_0_0/cp-0880.ckpt\n",
      "250/250 [==============================] - 0s 955us/step - loss: 1.3483 - accuracy: 0.0000e+00 - val_loss: 1.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 881/2000\n",
      "250/250 [==============================] - 0s 894us/step - loss: 1.3496 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 882/2000\n",
      "250/250 [==============================] - 0s 874us/step - loss: 1.3486 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 883/2000\n",
      "250/250 [==============================] - 0s 918us/step - loss: 1.3485 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 884/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3483 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 885/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.3502 - accuracy: 0.0000e+00\n",
      "Epoch 00885: saving model to training_0_0/cp-0885.ckpt\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.3477 - accuracy: 0.0000e+00 - val_loss: 1.4441 - val_accuracy: 0.0000e+00\n",
      "Epoch 886/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3468 - accuracy: 0.0000e+00 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 887/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.3476 - accuracy: 0.0000e+00 - val_loss: 1.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 888/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3478 - accuracy: 0.0000e+00 - val_loss: 1.4341 - val_accuracy: 0.0000e+00\n",
      "Epoch 889/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.3477 - accuracy: 0.0000e+00 - val_loss: 1.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 890/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3298 - accuracy: 0.0000e+00\n",
      "Epoch 00890: saving model to training_0_0/cp-0890.ckpt\n",
      "250/250 [==============================] - 0s 894us/step - loss: 1.3481 - accuracy: 0.0000e+00 - val_loss: 1.4271 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 891/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.3478 - accuracy: 0.0000e+00 - val_loss: 1.4367 - val_accuracy: 0.0000e+00\n",
      "Epoch 892/2000\n",
      "250/250 [==============================] - 0s 916us/step - loss: 1.3475 - accuracy: 0.0000e+00 - val_loss: 1.4445 - val_accuracy: 0.0000e+00\n",
      "Epoch 893/2000\n",
      "250/250 [==============================] - 0s 932us/step - loss: 1.3471 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 894/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3470 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 895/2000\n",
      "242/250 [============================>.] - ETA: 0s - loss: 1.3438 - accuracy: 0.0000e+00\n",
      "Epoch 00895: saving model to training_0_0/cp-0895.ckpt\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3473 - accuracy: 0.0000e+00 - val_loss: 1.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 896/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.3462 - accuracy: 0.0000e+00 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 897/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3471 - accuracy: 0.0000e+00 - val_loss: 1.4385 - val_accuracy: 0.0000e+00\n",
      "Epoch 898/2000\n",
      "250/250 [==============================] - 0s 927us/step - loss: 1.3459 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 899/2000\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.3461 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 900/2000\n",
      "247/250 [============================>.] - ETA: 0s - loss: 1.3479 - accuracy: 0.0000e+00\n",
      "Epoch 00900: saving model to training_0_0/cp-0900.ckpt\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3462 - accuracy: 0.0000e+00 - val_loss: 1.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 901/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3461 - accuracy: 0.0000e+00 - val_loss: 1.4271 - val_accuracy: 0.0000e+00\n",
      "Epoch 902/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3466 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 903/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3452 - accuracy: 0.0000e+00 - val_loss: 1.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 904/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.3463 - accuracy: 0.0000e+00 - val_loss: 1.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 905/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.3455 - accuracy: 0.0000e+00\n",
      "Epoch 00905: saving model to training_0_0/cp-0905.ckpt\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.3450 - accuracy: 0.0000e+00 - val_loss: 1.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 906/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.3446 - accuracy: 0.0000e+00 - val_loss: 1.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 907/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.3452 - accuracy: 0.0000e+00 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 908/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.3447 - accuracy: 0.0000e+00 - val_loss: 1.4384 - val_accuracy: 0.0000e+00\n",
      "Epoch 909/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.3440 - accuracy: 0.0000e+00 - val_loss: 1.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 910/2000\n",
      "243/250 [============================>.] - ETA: 0s - loss: 1.3546 - accuracy: 0.0000e+00\n",
      "Epoch 00910: saving model to training_0_0/cp-0910.ckpt\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3440 - accuracy: 0.0000e+00 - val_loss: 1.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 911/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3442 - accuracy: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 912/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3448 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 913/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.3447 - accuracy: 0.0000e+00 - val_loss: 1.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 914/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3439 - accuracy: 0.0000e+00 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 915/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.3213 - accuracy: 0.0000e+00\n",
      "Epoch 00915: saving model to training_0_0/cp-0915.ckpt\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3441 - accuracy: 0.0000e+00 - val_loss: 1.4314 - val_accuracy: 0.0000e+00\n",
      "Epoch 916/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.3439 - accuracy: 0.0000e+00 - val_loss: 1.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 917/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.3436 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 918/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.3426 - accuracy: 0.0000e+00 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 919/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.3439 - accuracy: 0.0000e+00 - val_loss: 1.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 920/2000\n",
      "246/250 [============================>.] - ETA: 0s - loss: 1.3448 - accuracy: 0.0000e+00\n",
      "Epoch 00920: saving model to training_0_0/cp-0920.ckpt\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.3435 - accuracy: 0.0000e+00 - val_loss: 1.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 921/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3441 - accuracy: 0.0000e+00 - val_loss: 1.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 922/2000\n",
      "250/250 [==============================] - 0s 754us/step - loss: 1.3427 - accuracy: 0.0000e+00 - val_loss: 1.4533 - val_accuracy: 0.0000e+00\n",
      "Epoch 923/2000\n",
      "250/250 [==============================] - 0s 755us/step - loss: 1.3431 - accuracy: 0.0000e+00 - val_loss: 1.4308 - val_accuracy: 0.0000e+00\n",
      "Epoch 924/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3427 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 925/2000\n",
      "242/250 [============================>.] - ETA: 0s - loss: 1.3346 - accuracy: 0.0000e+00\n",
      "Epoch 00925: saving model to training_0_0/cp-0925.ckpt\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3427 - accuracy: 0.0000e+00 - val_loss: 1.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 926/2000\n",
      "250/250 [==============================] - 0s 748us/step - loss: 1.3426 - accuracy: 0.0000e+00 - val_loss: 1.4314 - val_accuracy: 0.0000e+00\n",
      "Epoch 927/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3408 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 928/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3413 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 929/2000\n",
      "250/250 [==============================] - 0s 761us/step - loss: 1.3425 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 930/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.3603 - accuracy: 0.0000e+00\n",
      "Epoch 00930: saving model to training_0_0/cp-0930.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3412 - accuracy: 0.0000e+00 - val_loss: 1.4243 - val_accuracy: 0.0000e+00\n",
      "Epoch 931/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.3419 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 932/2000\n",
      "250/250 [==============================] - 0s 753us/step - loss: 1.3409 - accuracy: 0.0000e+00 - val_loss: 1.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 933/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3400 - accuracy: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 934/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.3416 - accuracy: 0.0000e+00 - val_loss: 1.4277 - val_accuracy: 0.0000e+00\n",
      "Epoch 935/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.3494 - accuracy: 0.0000e+00\n",
      "Epoch 00935: saving model to training_0_0/cp-0935.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3416 - accuracy: 0.0000e+00 - val_loss: 1.4381 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 936/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.3410 - accuracy: 0.0000e+00 - val_loss: 1.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 937/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.3397 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 938/2000\n",
      "250/250 [==============================] - 0s 759us/step - loss: 1.3406 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 939/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.3399 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 940/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.3442 - accuracy: 0.0000e+00\n",
      "Epoch 00940: saving model to training_0_0/cp-0940.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3398 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 941/2000\n",
      "250/250 [==============================] - 0s 726us/step - loss: 1.3404 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 942/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3393 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 943/2000\n",
      "250/250 [==============================] - 0s 871us/step - loss: 1.3400 - accuracy: 0.0000e+00 - val_loss: 1.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 944/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3398 - accuracy: 0.0000e+00 - val_loss: 1.4436 - val_accuracy: 0.0000e+00\n",
      "Epoch 945/2000\n",
      "239/250 [===========================>..] - ETA: 0s - loss: 1.3514 - accuracy: 0.0000e+00\n",
      "Epoch 00945: saving model to training_0_0/cp-0945.ckpt\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.3397 - accuracy: 0.0000e+00 - val_loss: 1.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 946/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3384 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 947/2000\n",
      "250/250 [==============================] - 0s 734us/step - loss: 1.3397 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 948/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3393 - accuracy: 0.0000e+00 - val_loss: 1.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 949/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3386 - accuracy: 0.0000e+00 - val_loss: 1.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 950/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.3389 - accuracy: 0.0000e+00\n",
      "Epoch 00950: saving model to training_0_0/cp-0950.ckpt\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3392 - accuracy: 0.0000e+00 - val_loss: 1.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 951/2000\n",
      "250/250 [==============================] - 0s 774us/step - loss: 1.3380 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 952/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3372 - accuracy: 0.0000e+00 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 953/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3368 - accuracy: 0.0000e+00 - val_loss: 1.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 954/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.3385 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 955/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3540 - accuracy: 0.0000e+00\n",
      "Epoch 00955: saving model to training_0_0/cp-0955.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3387 - accuracy: 0.0000e+00 - val_loss: 1.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 956/2000\n",
      "250/250 [==============================] - 0s 735us/step - loss: 1.3380 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 957/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.3377 - accuracy: 0.0000e+00 - val_loss: 1.4410 - val_accuracy: 0.0000e+00\n",
      "Epoch 958/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3383 - accuracy: 0.0000e+00 - val_loss: 1.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 959/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3378 - accuracy: 0.0000e+00 - val_loss: 1.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 960/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3313 - accuracy: 0.0000e+00\n",
      "Epoch 00960: saving model to training_0_0/cp-0960.ckpt\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.3361 - accuracy: 0.0000e+00 - val_loss: 1.4379 - val_accuracy: 0.0000e+00\n",
      "Epoch 961/2000\n",
      "250/250 [==============================] - 0s 744us/step - loss: 1.3377 - accuracy: 0.0000e+00 - val_loss: 1.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 962/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3378 - accuracy: 0.0000e+00 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 963/2000\n",
      "250/250 [==============================] - 0s 756us/step - loss: 1.3366 - accuracy: 0.0000e+00 - val_loss: 1.4280 - val_accuracy: 0.0000e+00\n",
      "Epoch 964/2000\n",
      "250/250 [==============================] - 0s 773us/step - loss: 1.3365 - accuracy: 0.0000e+00 - val_loss: 1.4433 - val_accuracy: 0.0000e+00\n",
      "Epoch 965/2000\n",
      "245/250 [============================>.] - ETA: 0s - loss: 1.3410 - accuracy: 0.0000e+00\n",
      "Epoch 00965: saving model to training_0_0/cp-0965.ckpt\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3365 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 966/2000\n",
      "250/250 [==============================] - 0s 758us/step - loss: 1.3369 - accuracy: 0.0000e+00 - val_loss: 1.4285 - val_accuracy: 0.0000e+00\n",
      "Epoch 967/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3372 - accuracy: 0.0000e+00 - val_loss: 1.4289 - val_accuracy: 0.0000e+00\n",
      "Epoch 968/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.3364 - accuracy: 0.0000e+00 - val_loss: 1.4246 - val_accuracy: 0.0000e+00\n",
      "Epoch 969/2000\n",
      "250/250 [==============================] - 0s 765us/step - loss: 1.3357 - accuracy: 0.0000e+00 - val_loss: 1.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 970/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.3198 - accuracy: 0.0000e+00\n",
      "Epoch 00970: saving model to training_0_0/cp-0970.ckpt\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.3356 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 971/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.3363 - accuracy: 0.0000e+00 - val_loss: 1.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 972/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3369 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 973/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.3346 - accuracy: 0.0000e+00 - val_loss: 1.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 974/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3350 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 975/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3296 - accuracy: 0.0000e+00\n",
      "Epoch 00975: saving model to training_0_0/cp-0975.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3346 - accuracy: 0.0000e+00 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 976/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.3353 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 977/2000\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.3328 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 978/2000\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.3351 - accuracy: 0.0000e+00 - val_loss: 1.4303 - val_accuracy: 0.0000e+00\n",
      "Epoch 979/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3336 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 980/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.3512 - accuracy: 0.0000e+00\n",
      "Epoch 00980: saving model to training_0_0/cp-0980.ckpt\n",
      "250/250 [==============================] - 0s 882us/step - loss: 1.3334 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/2000\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.3346 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 982/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3343 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 983/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3338 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 984/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3340 - accuracy: 0.0000e+00 - val_loss: 1.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 985/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.3469 - accuracy: 0.0000e+00\n",
      "Epoch 00985: saving model to training_0_0/cp-0985.ckpt\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3334 - accuracy: 0.0000e+00 - val_loss: 1.4322 - val_accuracy: 0.0000e+00\n",
      "Epoch 986/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3334 - accuracy: 0.0000e+00 - val_loss: 1.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 987/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.3335 - accuracy: 0.0000e+00 - val_loss: 1.4261 - val_accuracy: 0.0000e+00\n",
      "Epoch 988/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.3336 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 989/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3331 - accuracy: 0.0000e+00 - val_loss: 1.4309 - val_accuracy: 0.0000e+00\n",
      "Epoch 990/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3449 - accuracy: 0.0000e+00\n",
      "Epoch 00990: saving model to training_0_0/cp-0990.ckpt\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.3332 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 991/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3325 - accuracy: 0.0000e+00 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 992/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3333 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 993/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.3335 - accuracy: 0.0000e+00 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 994/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3330 - accuracy: 0.0000e+00 - val_loss: 1.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 995/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.3709 - accuracy: 0.0000e+00\n",
      "Epoch 00995: saving model to training_0_0/cp-0995.ckpt\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.3315 - accuracy: 0.0000e+00 - val_loss: 1.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 996/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3315 - accuracy: 0.0000e+00 - val_loss: 1.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 997/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3319 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 998/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3314 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 999/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3304 - accuracy: 0.0000e+00 - val_loss: 1.4364 - val_accuracy: 0.0000e+00\n",
      "Epoch 1000/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3425 - accuracy: 0.0000e+00\n",
      "Epoch 01000: saving model to training_0_0/cp-1000.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.3311 - accuracy: 0.0000e+00 - val_loss: 1.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1001/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3319 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 1002/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3311 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1003/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3315 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 1004/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3315 - accuracy: 0.0000e+00 - val_loss: 1.4205 - val_accuracy: 0.0000e+00\n",
      "Epoch 1005/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.3137 - accuracy: 0.0000e+00\n",
      "Epoch 01005: saving model to training_0_0/cp-1005.ckpt\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3308 - accuracy: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 1006/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3300 - accuracy: 0.0000e+00 - val_loss: 1.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 1007/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3307 - accuracy: 0.0000e+00 - val_loss: 1.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 1008/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.3308 - accuracy: 0.0000e+00 - val_loss: 1.4322 - val_accuracy: 0.0000e+00\n",
      "Epoch 1009/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.3298 - accuracy: 0.0000e+00 - val_loss: 1.4275 - val_accuracy: 0.0000e+00\n",
      "Epoch 1010/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.3277 - accuracy: 0.0000e+00\n",
      "Epoch 01010: saving model to training_0_0/cp-1010.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.3306 - accuracy: 0.0000e+00 - val_loss: 1.4243 - val_accuracy: 0.0000e+00\n",
      "Epoch 1011/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3306 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1012/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3304 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1013/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.3287 - accuracy: 0.0000e+00 - val_loss: 1.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 1014/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3297 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1015/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3388 - accuracy: 0.0000e+00\n",
      "Epoch 01015: saving model to training_0_0/cp-1015.ckpt\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.3300 - accuracy: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 1016/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3293 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 1017/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3296 - accuracy: 0.0000e+00 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1018/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3291 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1019/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3285 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 1020/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.3148 - accuracy: 0.0000e+00\n",
      "Epoch 01020: saving model to training_0_0/cp-1020.ckpt\n",
      "250/250 [==============================] - 0s 880us/step - loss: 1.3292 - accuracy: 0.0000e+00 - val_loss: 1.4322 - val_accuracy: 0.0000e+00\n",
      "Epoch 1021/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3285 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1022/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.3271 - accuracy: 0.0000e+00 - val_loss: 1.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1023/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3276 - accuracy: 0.0000e+00 - val_loss: 1.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 1024/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.3284 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1025/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3206 - accuracy: 0.0000e+00\n",
      "Epoch 01025: saving model to training_0_0/cp-1025.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.3277 - accuracy: 0.0000e+00 - val_loss: 1.4200 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1026/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3281 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1027/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.3283 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1028/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3279 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 1029/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3273 - accuracy: 0.0000e+00 - val_loss: 1.4291 - val_accuracy: 0.0000e+00\n",
      "Epoch 1030/2000\n",
      "229/250 [==========================>...] - ETA: 0s - loss: 1.3444 - accuracy: 0.0000e+00\n",
      "Epoch 01030: saving model to training_0_0/cp-1030.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3266 - accuracy: 0.0000e+00 - val_loss: 1.4433 - val_accuracy: 0.0000e+00\n",
      "Epoch 1031/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.3277 - accuracy: 0.0000e+00 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1032/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3273 - accuracy: 0.0000e+00 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 1033/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3265 - accuracy: 0.0000e+00 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 1034/2000\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.3278 - accuracy: 0.0000e+00 - val_loss: 1.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1035/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3263 - accuracy: 0.0000e+00\n",
      "Epoch 01035: saving model to training_0_0/cp-1035.ckpt\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.3274 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1036/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.3270 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1037/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3256 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1038/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3268 - accuracy: 0.0000e+00 - val_loss: 1.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1039/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.3263 - accuracy: 0.0000e+00 - val_loss: 1.4364 - val_accuracy: 0.0000e+00\n",
      "Epoch 1040/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.3544 - accuracy: 0.0000e+00\n",
      "Epoch 01040: saving model to training_0_0/cp-1040.ckpt\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.3271 - accuracy: 0.0000e+00 - val_loss: 1.4207 - val_accuracy: 0.0000e+00\n",
      "Epoch 1041/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3258 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1042/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3251 - accuracy: 0.0000e+00 - val_loss: 1.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1043/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3266 - accuracy: 0.0000e+00 - val_loss: 1.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 1044/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3252 - accuracy: 0.0000e+00 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1045/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.3099 - accuracy: 0.0000e+00\n",
      "Epoch 01045: saving model to training_0_0/cp-1045.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.3251 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1046/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3255 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1047/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.3256 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1048/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3247 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1049/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.3244 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1050/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.2887 - accuracy: 0.0000e+00\n",
      "Epoch 01050: saving model to training_0_0/cp-1050.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3251 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1051/2000\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.3256 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 1052/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3240 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1053/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3242 - accuracy: 0.0000e+00 - val_loss: 1.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 1054/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3248 - accuracy: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1055/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2956 - accuracy: 0.0000e+00\n",
      "Epoch 01055: saving model to training_0_0/cp-1055.ckpt\n",
      "250/250 [==============================] - 0s 854us/step - loss: 1.3246 - accuracy: 0.0000e+00 - val_loss: 1.4277 - val_accuracy: 0.0000e+00\n",
      "Epoch 1056/2000\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.3238 - accuracy: 0.0000e+00 - val_loss: 1.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 1057/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3229 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1058/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3240 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1059/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3230 - accuracy: 0.0000e+00 - val_loss: 1.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1060/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2805 - accuracy: 0.0000e+00\n",
      "Epoch 01060: saving model to training_0_0/cp-1060.ckpt\n",
      "250/250 [==============================] - 0s 887us/step - loss: 1.3229 - accuracy: 0.0000e+00 - val_loss: 1.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 1061/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3217 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1062/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3207 - accuracy: 0.0000e+00 - val_loss: 1.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 1063/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3228 - accuracy: 0.0000e+00 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 1064/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3233 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1065/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3394 - accuracy: 0.0000e+00\n",
      "Epoch 01065: saving model to training_0_0/cp-1065.ckpt\n",
      "250/250 [==============================] - 0s 874us/step - loss: 1.3229 - accuracy: 0.0000e+00 - val_loss: 1.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1066/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.3225 - accuracy: 0.0000e+00 - val_loss: 1.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1067/2000\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.3229 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1068/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3226 - accuracy: 0.0000e+00 - val_loss: 1.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 1069/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.3211 - accuracy: 0.0000e+00 - val_loss: 1.4280 - val_accuracy: 0.0000e+00\n",
      "Epoch 1070/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3622 - accuracy: 0.0000e+00\n",
      "Epoch 01070: saving model to training_0_0/cp-1070.ckpt\n",
      "250/250 [==============================] - 0s 879us/step - loss: 1.3206 - accuracy: 0.0000e+00 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1071/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.3219 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1072/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.3217 - accuracy: 0.0000e+00 - val_loss: 1.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1073/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3207 - accuracy: 0.0000e+00 - val_loss: 1.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 1074/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3217 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1075/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.3393 - accuracy: 0.0000e+00\n",
      "Epoch 01075: saving model to training_0_0/cp-1075.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.3214 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 1076/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.3214 - accuracy: 0.0000e+00 - val_loss: 1.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 1077/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3217 - accuracy: 0.0000e+00 - val_loss: 1.4222 - val_accuracy: 0.0000e+00\n",
      "Epoch 1078/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3206 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1079/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3201 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1080/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3431 - accuracy: 0.0000e+00\n",
      "Epoch 01080: saving model to training_0_0/cp-1080.ckpt\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.3213 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1081/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.3199 - accuracy: 0.0000e+00 - val_loss: 1.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 1082/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3200 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 1083/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.3206 - accuracy: 0.0000e+00 - val_loss: 1.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1084/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.3196 - accuracy: 0.0000e+00 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 1085/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2862 - accuracy: 0.0000e+00\n",
      "Epoch 01085: saving model to training_0_0/cp-1085.ckpt\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.3208 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1086/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3200 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1087/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3197 - accuracy: 0.0000e+00 - val_loss: 1.4194 - val_accuracy: 0.0000e+00\n",
      "Epoch 1088/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3205 - accuracy: 0.0000e+00 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 1089/2000\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.3185 - accuracy: 0.0000e+00 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1090/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2909 - accuracy: 0.0000e+00\n",
      "Epoch 01090: saving model to training_0_0/cp-1090.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.3195 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 1091/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3199 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 1092/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3195 - accuracy: 0.0000e+00 - val_loss: 1.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1093/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3191 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 1094/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3193 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1095/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3110 - accuracy: 0.0000e+00\n",
      "Epoch 01095: saving model to training_0_0/cp-1095.ckpt\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.3194 - accuracy: 0.0000e+00 - val_loss: 1.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 1096/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3187 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1097/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3183 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 1098/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3179 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1099/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3182 - accuracy: 0.0000e+00 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 1100/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.3216 - accuracy: 0.0000e+00\n",
      "Epoch 01100: saving model to training_0_0/cp-1100.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.3180 - accuracy: 0.0000e+00 - val_loss: 1.4302 - val_accuracy: 0.0000e+00\n",
      "Epoch 1101/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3177 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1102/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.3174 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1103/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3183 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1104/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3173 - accuracy: 0.0000e+00 - val_loss: 1.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 1105/2000\n",
      "208/250 [=======================>......] - ETA: 0s - loss: 1.3300 - accuracy: 0.0000e+00\n",
      "Epoch 01105: saving model to training_0_0/cp-1105.ckpt\n",
      "250/250 [==============================] - 0s 916us/step - loss: 1.3162 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1106/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.3169 - accuracy: 0.0000e+00 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1107/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3168 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1108/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3172 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 1109/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3177 - accuracy: 0.0000e+00 - val_loss: 1.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 1110/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.3211 - accuracy: 0.0000e+00\n",
      "Epoch 01110: saving model to training_0_0/cp-1110.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.3160 - accuracy: 0.0000e+00 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 1111/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3160 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 1112/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.3172 - accuracy: 0.0000e+00 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1113/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.3157 - accuracy: 0.0000e+00 - val_loss: 1.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 1114/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3167 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1115/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.3058 - accuracy: 0.0000e+00\n",
      "Epoch 01115: saving model to training_0_0/cp-1115.ckpt\n",
      "250/250 [==============================] - 0s 884us/step - loss: 1.3166 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1116/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.3166 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_accuracy: 0.0000e+00\n",
      "Epoch 1117/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3158 - accuracy: 0.0000e+00 - val_loss: 1.4362 - val_accuracy: 0.0000e+00\n",
      "Epoch 1118/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.3162 - accuracy: 0.0000e+00 - val_loss: 1.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 1119/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.3149 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1120/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.3180 - accuracy: 0.0000e+00\n",
      "Epoch 01120: saving model to training_0_0/cp-1120.ckpt\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3141 - accuracy: 0.0000e+00 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 1121/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.3153 - accuracy: 0.0000e+00 - val_loss: 1.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 1122/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3151 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1123/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3143 - accuracy: 0.0000e+00 - val_loss: 1.4259 - val_accuracy: 0.0000e+00\n",
      "Epoch 1124/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3141 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1125/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.3245 - accuracy: 0.0000e+00\n",
      "Epoch 01125: saving model to training_0_0/cp-1125.ckpt\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.3141 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1126/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3144 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1127/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3137 - accuracy: 0.0000e+00 - val_loss: 1.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 1128/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3137 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1129/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3145 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1130/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.2978 - accuracy: 0.0000e+00\n",
      "Epoch 01130: saving model to training_0_0/cp-1130.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.3140 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1131/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3138 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1132/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3138 - accuracy: 0.0000e+00 - val_loss: 1.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 1133/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3123 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1134/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3129 - accuracy: 0.0000e+00 - val_loss: 1.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 1135/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.3083 - accuracy: 0.0000e+00\n",
      "Epoch 01135: saving model to training_0_0/cp-1135.ckpt\n",
      "250/250 [==============================] - 0s 891us/step - loss: 1.3133 - accuracy: 0.0000e+00 - val_loss: 1.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 1136/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3135 - accuracy: 0.0000e+00 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1137/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3134 - accuracy: 0.0000e+00 - val_loss: 1.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 1138/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3137 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_accuracy: 0.0000e+00\n",
      "Epoch 1139/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.3120 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1140/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3039 - accuracy: 0.0000e+00\n",
      "Epoch 01140: saving model to training_0_0/cp-1140.ckpt\n",
      "250/250 [==============================] - 0s 897us/step - loss: 1.3105 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1141/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.3123 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1142/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.3130 - accuracy: 0.0000e+00 - val_loss: 1.4341 - val_accuracy: 0.0000e+00\n",
      "Epoch 1143/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.3123 - accuracy: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 1144/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3110 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1145/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.3151 - accuracy: 0.0000e+00\n",
      "Epoch 01145: saving model to training_0_0/cp-1145.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.3122 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1146/2000\n",
      "250/250 [==============================] - 0s 889us/step - loss: 1.3114 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1147/2000\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.3114 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1148/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3119 - accuracy: 0.0000e+00 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 1149/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3118 - accuracy: 0.0000e+00 - val_loss: 1.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 1150/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.3403 - accuracy: 0.0000e+00\n",
      "Epoch 01150: saving model to training_0_0/cp-1150.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.3122 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 1151/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.3106 - accuracy: 0.0000e+00 - val_loss: 1.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 1152/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3112 - accuracy: 0.0000e+00 - val_loss: 1.4318 - val_accuracy: 0.0000e+00\n",
      "Epoch 1153/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3098 - accuracy: 0.0000e+00 - val_loss: 1.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 1154/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.3112 - accuracy: 0.0000e+00 - val_loss: 1.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1155/2000\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 1.2812 - accuracy: 0.0000e+00\n",
      "Epoch 01155: saving model to training_0_0/cp-1155.ckpt\n",
      "250/250 [==============================] - 0s 882us/step - loss: 1.3113 - accuracy: 0.0000e+00 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1156/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3109 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1157/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.3100 - accuracy: 0.0000e+00 - val_loss: 1.4483 - val_accuracy: 0.0000e+00\n",
      "Epoch 1158/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3098 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1159/2000\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.3106 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1160/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3280 - accuracy: 0.0000e+00\n",
      "Epoch 01160: saving model to training_0_0/cp-1160.ckpt\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.3094 - accuracy: 0.0000e+00 - val_loss: 1.4262 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1161/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.3097 - accuracy: 0.0000e+00 - val_loss: 1.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 1162/2000\n",
      "250/250 [==============================] - 0s 749us/step - loss: 1.3090 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1163/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.3099 - accuracy: 0.0000e+00 - val_loss: 1.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 1164/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.3099 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 1165/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2770 - accuracy: 0.0000e+00\n",
      "Epoch 01165: saving model to training_0_0/cp-1165.ckpt\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.3084 - accuracy: 0.0000e+00 - val_loss: 1.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 1166/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.3086 - accuracy: 0.0000e+00 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 1167/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.3082 - accuracy: 0.0000e+00 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1168/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.3081 - accuracy: 0.0000e+00 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 1169/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3092 - accuracy: 0.0000e+00 - val_loss: 1.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1170/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2843 - accuracy: 0.0000e+00\n",
      "Epoch 01170: saving model to training_0_0/cp-1170.ckpt\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.3078 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1171/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3077 - accuracy: 0.0000e+00 - val_loss: 1.4248 - val_accuracy: 0.0000e+00\n",
      "Epoch 1172/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.3088 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1173/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.3080 - accuracy: 0.0000e+00 - val_loss: 1.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 1174/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3088 - accuracy: 0.0000e+00 - val_loss: 1.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 1175/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2595 - accuracy: 0.0000e+00\n",
      "Epoch 01175: saving model to training_0_0/cp-1175.ckpt\n",
      "250/250 [==============================] - 0s 865us/step - loss: 1.3064 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 1176/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3080 - accuracy: 0.0000e+00 - val_loss: 1.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 1177/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.3072 - accuracy: 0.0000e+00 - val_loss: 1.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1178/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.3078 - accuracy: 0.0000e+00 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 1179/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3072 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1180/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3402 - accuracy: 0.0000e+00\n",
      "Epoch 01180: saving model to training_0_0/cp-1180.ckpt\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.3077 - accuracy: 0.0000e+00 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1181/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3067 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1182/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3068 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1183/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3069 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1184/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.3070 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1185/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3046 - accuracy: 0.0000e+00\n",
      "Epoch 01185: saving model to training_0_0/cp-1185.ckpt\n",
      "250/250 [==============================] - 0s 895us/step - loss: 1.3073 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1186/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.3063 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1187/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.3062 - accuracy: 0.0000e+00 - val_loss: 1.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 1188/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.3065 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1189/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.3061 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1190/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3132 - accuracy: 0.0000e+00\n",
      "Epoch 01190: saving model to training_0_0/cp-1190.ckpt\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.3066 - accuracy: 0.0000e+00 - val_loss: 1.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 1191/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.3064 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1192/2000\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.3051 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1193/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.3061 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1194/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.3054 - accuracy: 0.0000e+00 - val_loss: 1.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1195/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2742 - accuracy: 0.0000e+00\n",
      "Epoch 01195: saving model to training_0_0/cp-1195.ckpt\n",
      "250/250 [==============================] - 0s 909us/step - loss: 1.3050 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1196/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.3051 - accuracy: 0.0000e+00 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1197/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3055 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1198/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.3053 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1199/2000\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.3049 - accuracy: 0.0000e+00 - val_loss: 1.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 1200/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2961 - accuracy: 0.0000e+00\n",
      "Epoch 01200: saving model to training_0_0/cp-1200.ckpt\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3052 - accuracy: 0.0000e+00 - val_loss: 1.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1201/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3034 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1202/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.3051 - accuracy: 0.0000e+00 - val_loss: 1.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1203/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.3032 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1204/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.3045 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1205/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2884 - accuracy: 0.0000e+00\n",
      "Epoch 01205: saving model to training_0_0/cp-1205.ckpt\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.3035 - accuracy: 0.0000e+00 - val_loss: 1.4308 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1206/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3042 - accuracy: 0.0000e+00 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1207/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.3041 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1208/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.3038 - accuracy: 0.0000e+00 - val_loss: 1.4207 - val_accuracy: 0.0000e+00\n",
      "Epoch 1209/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.3030 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1210/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.3112 - accuracy: 0.0000e+00\n",
      "Epoch 01210: saving model to training_0_0/cp-1210.ckpt\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3033 - accuracy: 0.0000e+00 - val_loss: 1.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 1211/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.3034 - accuracy: 0.0000e+00 - val_loss: 1.4484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1212/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.3038 - accuracy: 0.0000e+00 - val_loss: 1.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 1213/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.3041 - accuracy: 0.0000e+00 - val_loss: 1.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1214/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.3024 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_accuracy: 0.0000e+00\n",
      "Epoch 1215/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.2912 - accuracy: 0.0000e+00\n",
      "Epoch 01215: saving model to training_0_0/cp-1215.ckpt\n",
      "250/250 [==============================] - 0s 871us/step - loss: 1.3008 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1216/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.3029 - accuracy: 0.0000e+00 - val_loss: 1.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 1217/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.3017 - accuracy: 0.0000e+00 - val_loss: 1.4347 - val_accuracy: 0.0000e+00\n",
      "Epoch 1218/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.3017 - accuracy: 0.0000e+00 - val_loss: 1.4335 - val_accuracy: 0.0000e+00\n",
      "Epoch 1219/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.3024 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1220/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.3076 - accuracy: 0.0000e+00\n",
      "Epoch 01220: saving model to training_0_0/cp-1220.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.3021 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1221/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.3014 - accuracy: 0.0000e+00 - val_loss: 1.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 1222/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.3016 - accuracy: 0.0000e+00 - val_loss: 1.4261 - val_accuracy: 0.0000e+00\n",
      "Epoch 1223/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3001 - accuracy: 0.0000e+00 - val_loss: 1.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1224/2000\n",
      "250/250 [==============================] - 0s 912us/step - loss: 1.3015 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1225/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.3301 - accuracy: 0.0000e+00\n",
      "Epoch 01225: saving model to training_0_0/cp-1225.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.3002 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1226/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.3001 - accuracy: 0.0000e+00 - val_loss: 1.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1227/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2999 - accuracy: 0.0000e+00 - val_loss: 1.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 1228/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3014 - accuracy: 0.0000e+00 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 1229/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.3003 - accuracy: 0.0000e+00 - val_loss: 1.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 1230/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.3175 - accuracy: 0.0000e+00\n",
      "Epoch 01230: saving model to training_0_0/cp-1230.ckpt\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2988 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1231/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2994 - accuracy: 0.0000e+00 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 1232/2000\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.2994 - accuracy: 0.0000e+00 - val_loss: 1.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 1233/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2996 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1234/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2987 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1235/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3131 - accuracy: 0.0000e+00\n",
      "Epoch 01235: saving model to training_0_0/cp-1235.ckpt\n",
      "250/250 [==============================] - 0s 866us/step - loss: 1.2995 - accuracy: 0.0000e+00 - val_loss: 1.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 1236/2000\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2992 - accuracy: 0.0000e+00 - val_loss: 1.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 1237/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2989 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1238/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.3004 - accuracy: 0.0000e+00 - val_loss: 1.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1239/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2984 - accuracy: 0.0000e+00 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1240/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.3130 - accuracy: 0.0000e+00\n",
      "Epoch 01240: saving model to training_0_0/cp-1240.ckpt\n",
      "250/250 [==============================] - 0s 876us/step - loss: 1.2995 - accuracy: 0.0000e+00 - val_loss: 1.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1241/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2975 - accuracy: 0.0000e+00 - val_loss: 1.4376 - val_accuracy: 0.0000e+00\n",
      "Epoch 1242/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2984 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1243/2000\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.2994 - accuracy: 0.0000e+00 - val_loss: 1.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 1244/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2987 - accuracy: 0.0000e+00 - val_loss: 1.4285 - val_accuracy: 0.0000e+00\n",
      "Epoch 1245/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.3058 - accuracy: 0.0000e+00\n",
      "Epoch 01245: saving model to training_0_0/cp-1245.ckpt\n",
      "250/250 [==============================] - 0s 872us/step - loss: 1.2987 - accuracy: 0.0000e+00 - val_loss: 1.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 1246/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2988 - accuracy: 0.0000e+00 - val_loss: 1.4436 - val_accuracy: 0.0000e+00\n",
      "Epoch 1247/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2975 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1248/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.2976 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1249/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2975 - accuracy: 0.0000e+00 - val_loss: 1.4234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1250/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2944 - accuracy: 0.0000e+00\n",
      "Epoch 01250: saving model to training_0_0/cp-1250.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2980 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1251/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2982 - accuracy: 0.0000e+00 - val_loss: 1.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 1252/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.2973 - accuracy: 0.0000e+00 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1253/2000\n",
      "250/250 [==============================] - 0s 865us/step - loss: 1.2980 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1254/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2973 - accuracy: 0.0000e+00 - val_loss: 1.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1255/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2771 - accuracy: 0.0000e+00\n",
      "Epoch 01255: saving model to training_0_0/cp-1255.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2961 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1256/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.2973 - accuracy: 0.0000e+00 - val_loss: 1.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 1257/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2975 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1258/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2956 - accuracy: 0.0000e+00 - val_loss: 1.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 1259/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.2966 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1260/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2875 - accuracy: 0.0000e+00\n",
      "Epoch 01260: saving model to training_0_0/cp-1260.ckpt\n",
      "250/250 [==============================] - 0s 880us/step - loss: 1.2962 - accuracy: 0.0000e+00 - val_loss: 1.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 1261/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2963 - accuracy: 0.0000e+00 - val_loss: 1.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 1262/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2971 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1263/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2957 - accuracy: 0.0000e+00 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 1264/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.2960 - accuracy: 0.0000e+00 - val_loss: 1.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1265/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.3048 - accuracy: 0.0000e+00\n",
      "Epoch 01265: saving model to training_0_0/cp-1265.ckpt\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.2954 - accuracy: 0.0000e+00 - val_loss: 1.4493 - val_accuracy: 0.0000e+00\n",
      "Epoch 1266/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2957 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1267/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2962 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1268/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2959 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 1269/2000\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2955 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1270/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2502 - accuracy: 0.0000e+00\n",
      "Epoch 01270: saving model to training_0_0/cp-1270.ckpt\n",
      "250/250 [==============================] - 0s 872us/step - loss: 1.2953 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1271/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2957 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1272/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2951 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1273/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2945 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1274/2000\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.2950 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1275/2000\n",
      "209/250 [========================>.....] - ETA: 0s - loss: 1.2966 - accuracy: 0.0000e+00\n",
      "Epoch 01275: saving model to training_0_0/cp-1275.ckpt\n",
      "250/250 [==============================] - 0s 899us/step - loss: 1.2945 - accuracy: 0.0000e+00 - val_loss: 1.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 1276/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2955 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1277/2000\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.2944 - accuracy: 0.0000e+00 - val_loss: 1.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 1278/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2940 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1279/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2942 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1280/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.3060 - accuracy: 0.0000e+00\n",
      "Epoch 01280: saving model to training_0_0/cp-1280.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2947 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1281/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2929 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1282/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2936 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1283/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2936 - accuracy: 0.0000e+00 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 1284/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2936 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1285/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2941 - accuracy: 0.0000e+00\n",
      "Epoch 01285: saving model to training_0_0/cp-1285.ckpt\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.2929 - accuracy: 0.0000e+00 - val_loss: 1.4222 - val_accuracy: 0.0000e+00\n",
      "Epoch 1286/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2933 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1287/2000\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.2936 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1288/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2936 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1289/2000\n",
      "250/250 [==============================] - 0s 877us/step - loss: 1.2928 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1290/2000\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 1.2929 - accuracy: 0.0000e+00\n",
      "Epoch 01290: saving model to training_0_0/cp-1290.ckpt\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.2926 - accuracy: 0.0000e+00 - val_loss: 1.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 1291/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2935 - accuracy: 0.0000e+00 - val_loss: 1.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1292/2000\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.2929 - accuracy: 0.0000e+00 - val_loss: 1.4343 - val_accuracy: 0.0000e+00\n",
      "Epoch 1293/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2921 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1294/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2909 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1295/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2636 - accuracy: 0.0000e+00\n",
      "Epoch 01295: saving model to training_0_0/cp-1295.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2910 - accuracy: 0.0000e+00 - val_loss: 1.4182 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1296/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2923 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1297/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2920 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1298/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2905 - accuracy: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 1299/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2918 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1300/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.3020 - accuracy: 0.0000e+00\n",
      "Epoch 01300: saving model to training_0_0/cp-1300.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2907 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1301/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.2903 - accuracy: 0.0000e+00 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 1302/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2895 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1303/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2893 - accuracy: 0.0000e+00 - val_loss: 1.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 1304/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2918 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1305/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2854 - accuracy: 0.0000e+00\n",
      "Epoch 01305: saving model to training_0_0/cp-1305.ckpt\n",
      "250/250 [==============================] - 0s 854us/step - loss: 1.2910 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1306/2000\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2904 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 1307/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2906 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1308/2000\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.2896 - accuracy: 0.0000e+00 - val_loss: 1.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1309/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2900 - accuracy: 0.0000e+00 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 1310/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.2892 - accuracy: 0.0000e+00\n",
      "Epoch 01310: saving model to training_0_0/cp-1310.ckpt\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.2905 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1311/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2897 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 1312/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2895 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1313/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2893 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1314/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2897 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1315/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.3086 - accuracy: 0.0000e+00\n",
      "Epoch 01315: saving model to training_0_0/cp-1315.ckpt\n",
      "250/250 [==============================] - 0s 876us/step - loss: 1.2883 - accuracy: 0.0000e+00 - val_loss: 1.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 1316/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.2886 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1317/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2885 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 1318/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2875 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1319/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2891 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1320/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.3268 - accuracy: 0.0000e+00\n",
      "Epoch 01320: saving model to training_0_0/cp-1320.ckpt\n",
      "250/250 [==============================] - 0s 854us/step - loss: 1.2885 - accuracy: 0.0000e+00 - val_loss: 1.4332 - val_accuracy: 0.0000e+00\n",
      "Epoch 1321/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2881 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1322/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2878 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1323/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2888 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1324/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2887 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1325/2000\n",
      "211/250 [========================>.....] - ETA: 0s - loss: 1.2834 - accuracy: 0.0000e+00\n",
      "Epoch 01325: saving model to training_0_0/cp-1325.ckpt\n",
      "250/250 [==============================] - 0s 882us/step - loss: 1.2876 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1326/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2877 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1327/2000\n",
      "250/250 [==============================] - 0s 854us/step - loss: 1.2880 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1328/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.2869 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1329/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2862 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1330/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.3040 - accuracy: 0.0000e+00\n",
      "Epoch 01330: saving model to training_0_0/cp-1330.ckpt\n",
      "250/250 [==============================] - 0s 866us/step - loss: 1.2863 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1331/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2874 - accuracy: 0.0000e+00 - val_loss: 1.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 1332/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2850 - accuracy: 0.0000e+00 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 1333/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2852 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 1334/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.2861 - accuracy: 0.0000e+00 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 1335/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.3001 - accuracy: 0.0000e+00\n",
      "Epoch 01335: saving model to training_0_0/cp-1335.ckpt\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.2855 - accuracy: 0.0000e+00 - val_loss: 1.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1336/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2858 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1337/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2860 - accuracy: 0.0000e+00 - val_loss: 1.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 1338/2000\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.2852 - accuracy: 0.0000e+00 - val_loss: 1.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 1339/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2839 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1340/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2872 - accuracy: 0.0000e+00\n",
      "Epoch 01340: saving model to training_0_0/cp-1340.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2849 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1341/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2846 - accuracy: 0.0000e+00 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1342/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.2854 - accuracy: 0.0000e+00 - val_loss: 1.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 1343/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2859 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1344/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2857 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1345/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2838 - accuracy: 0.0000e+00\n",
      "Epoch 01345: saving model to training_0_0/cp-1345.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2846 - accuracy: 0.0000e+00 - val_loss: 1.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 1346/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2851 - accuracy: 0.0000e+00 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1347/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2832 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1348/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2858 - accuracy: 0.0000e+00 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 1349/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2846 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1350/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.3380 - accuracy: 0.0000e+00\n",
      "Epoch 01350: saving model to training_0_0/cp-1350.ckpt\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.2830 - accuracy: 0.0000e+00 - val_loss: 1.4545 - val_accuracy: 0.0000e+00\n",
      "Epoch 1351/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2843 - accuracy: 0.0000e+00 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 1352/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2845 - accuracy: 0.0000e+00 - val_loss: 1.4135 - val_accuracy: 0.0000e+00\n",
      "Epoch 1353/2000\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2840 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1354/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2837 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1355/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.3048 - accuracy: 0.0000e+00\n",
      "Epoch 01355: saving model to training_0_0/cp-1355.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2829 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1356/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2834 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1357/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2824 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1358/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2831 - accuracy: 0.0000e+00 - val_loss: 1.4144 - val_accuracy: 0.0000e+00\n",
      "Epoch 1359/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2840 - accuracy: 0.0000e+00 - val_loss: 1.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 1360/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2677 - accuracy: 0.0000e+00\n",
      "Epoch 01360: saving model to training_0_0/cp-1360.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2823 - accuracy: 0.0000e+00 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1361/2000\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2834 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1362/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.2826 - accuracy: 0.0000e+00 - val_loss: 1.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1363/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2826 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1364/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.2821 - accuracy: 0.0000e+00 - val_loss: 1.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 1365/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2942 - accuracy: 0.0000e+00\n",
      "Epoch 01365: saving model to training_0_0/cp-1365.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2819 - accuracy: 0.0000e+00 - val_loss: 1.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1366/2000\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.2814 - accuracy: 0.0000e+00 - val_loss: 1.4205 - val_accuracy: 0.0000e+00\n",
      "Epoch 1367/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2820 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1368/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2819 - accuracy: 0.0000e+00 - val_loss: 1.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 1369/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.2817 - accuracy: 0.0000e+00 - val_loss: 1.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 1370/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.2904 - accuracy: 0.0000e+00\n",
      "Epoch 01370: saving model to training_0_0/cp-1370.ckpt\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 1.2822 - accuracy: 0.0000e+00 - val_loss: 1.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1371/2000\n",
      "250/250 [==============================] - 0s 886us/step - loss: 1.2817 - accuracy: 0.0000e+00 - val_loss: 1.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1372/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2817 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1373/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2821 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1374/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.2814 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1375/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.2678 - accuracy: 0.0000e+00\n",
      "Epoch 01375: saving model to training_0_0/cp-1375.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2807 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1376/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2806 - accuracy: 0.0000e+00 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1377/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.2808 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1378/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2806 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1379/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2796 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1380/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.3006 - accuracy: 0.0000e+00\n",
      "Epoch 01380: saving model to training_0_0/cp-1380.ckpt\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2803 - accuracy: 0.0000e+00 - val_loss: 1.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 1381/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2808 - accuracy: 0.0000e+00 - val_loss: 1.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 1382/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2795 - accuracy: 0.0000e+00 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1383/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2800 - accuracy: 0.0000e+00 - val_loss: 1.4222 - val_accuracy: 0.0000e+00\n",
      "Epoch 1384/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2789 - accuracy: 0.0000e+00 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 1385/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232/250 [==========================>...] - ETA: 0s - loss: 1.2917 - accuracy: 0.0000e+00\n",
      "Epoch 01385: saving model to training_0_0/cp-1385.ckpt\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2794 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1386/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2798 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1387/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2780 - accuracy: 0.0000e+00 - val_loss: 1.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1388/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2800 - accuracy: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1389/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2774 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1390/2000\n",
      "225/250 [==========================>...] - ETA: 0s - loss: 1.2656 - accuracy: 0.0000e+00\n",
      "Epoch 01390: saving model to training_0_0/cp-1390.ckpt\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.2788 - accuracy: 0.0000e+00 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 1391/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2792 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1392/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2790 - accuracy: 0.0000e+00 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1393/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2783 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1394/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2771 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1395/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2766 - accuracy: 0.0000e+00\n",
      "Epoch 01395: saving model to training_0_0/cp-1395.ckpt\n",
      "250/250 [==============================] - 0s 879us/step - loss: 1.2787 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1396/2000\n",
      "250/250 [==============================] - 0s 767us/step - loss: 1.2781 - accuracy: 0.0000e+00 - val_loss: 1.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 1397/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2784 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1398/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2776 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1399/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2781 - accuracy: 0.0000e+00 - val_loss: 1.4154 - val_accuracy: 0.0000e+00\n",
      "Epoch 1400/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.3032 - accuracy: 0.0000e+00\n",
      "Epoch 01400: saving model to training_0_0/cp-1400.ckpt\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2777 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1401/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2775 - accuracy: 0.0000e+00 - val_loss: 1.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 1402/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2753 - accuracy: 0.0000e+00 - val_loss: 1.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 1403/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2771 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1404/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.2767 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1405/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.2568 - accuracy: 0.0000e+00\n",
      "Epoch 01405: saving model to training_0_0/cp-1405.ckpt\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2769 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1406/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2762 - accuracy: 0.0000e+00 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1407/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2751 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1408/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2765 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1409/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2757 - accuracy: 0.0000e+00 - val_loss: 1.4497 - val_accuracy: 0.0000e+00\n",
      "Epoch 1410/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.2878 - accuracy: 0.0000e+00\n",
      "Epoch 01410: saving model to training_0_0/cp-1410.ckpt\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.2748 - accuracy: 0.0000e+00 - val_loss: 1.4397 - val_accuracy: 0.0000e+00\n",
      "Epoch 1411/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2757 - accuracy: 0.0000e+00 - val_loss: 1.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 1412/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2743 - accuracy: 0.0000e+00 - val_loss: 1.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 1413/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2748 - accuracy: 0.0000e+00 - val_loss: 1.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1414/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2739 - accuracy: 0.0000e+00 - val_loss: 1.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1415/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.2553 - accuracy: 0.0000e+00\n",
      "Epoch 01415: saving model to training_0_0/cp-1415.ckpt\n",
      "250/250 [==============================] - 0s 862us/step - loss: 1.2755 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 1416/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2746 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1417/2000\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.2745 - accuracy: 0.0000e+00 - val_loss: 1.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1418/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2752 - accuracy: 0.0000e+00 - val_loss: 1.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1419/2000\n",
      "250/250 [==============================] - 0s 876us/step - loss: 1.2755 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1420/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2724 - accuracy: 0.0000e+00\n",
      "Epoch 01420: saving model to training_0_0/cp-1420.ckpt\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2747 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1421/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2740 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1422/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2737 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1423/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2756 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1424/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2748 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1425/2000\n",
      "195/250 [======================>.......] - ETA: 0s - loss: 1.2635 - accuracy: 0.0000e+00\n",
      "Epoch 01425: saving model to training_0_0/cp-1425.ckpt\n",
      "250/250 [==============================] - 0s 927us/step - loss: 1.2746 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1426/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2744 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1427/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2734 - accuracy: 0.0000e+00 - val_loss: 1.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 1428/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.2732 - accuracy: 0.0000e+00 - val_loss: 1.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1429/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 809us/step - loss: 1.2733 - accuracy: 0.0000e+00 - val_loss: 1.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 1430/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2819 - accuracy: 0.0000e+00\n",
      "Epoch 01430: saving model to training_0_0/cp-1430.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2726 - accuracy: 0.0000e+00 - val_loss: 1.4356 - val_accuracy: 0.0000e+00\n",
      "Epoch 1431/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.2720 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1432/2000\n",
      "250/250 [==============================] - 0s 740us/step - loss: 1.2737 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1433/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.2728 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1434/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.2736 - accuracy: 0.0000e+00 - val_loss: 1.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1435/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2899 - accuracy: 0.0000e+00\n",
      "Epoch 01435: saving model to training_0_0/cp-1435.ckpt\n",
      "250/250 [==============================] - 0s 924us/step - loss: 1.2729 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1436/2000\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.2720 - accuracy: 0.0000e+00 - val_loss: 1.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 1437/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2708 - accuracy: 0.0000e+00 - val_loss: 1.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 1438/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2725 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1439/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2730 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1440/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2341 - accuracy: 0.0000e+00\n",
      "Epoch 01440: saving model to training_0_0/cp-1440.ckpt\n",
      "250/250 [==============================] - 0s 884us/step - loss: 1.2714 - accuracy: 0.0000e+00 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 1441/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2716 - accuracy: 0.0000e+00 - val_loss: 1.4246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1442/2000\n",
      "250/250 [==============================] - 0s 860us/step - loss: 1.2722 - accuracy: 0.0000e+00 - val_loss: 1.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1443/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2716 - accuracy: 0.0000e+00 - val_loss: 1.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 1444/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2710 - accuracy: 0.0000e+00 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1445/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2804 - accuracy: 0.0000e+00\n",
      "Epoch 01445: saving model to training_0_0/cp-1445.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2710 - accuracy: 0.0000e+00 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1446/2000\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.2714 - accuracy: 0.0000e+00 - val_loss: 1.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1447/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2701 - accuracy: 0.0000e+00 - val_loss: 1.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1448/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2718 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1449/2000\n",
      "250/250 [==============================] - 0s 877us/step - loss: 1.2719 - accuracy: 0.0000e+00 - val_loss: 1.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1450/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2943 - accuracy: 0.0000e+00\n",
      "Epoch 01450: saving model to training_0_0/cp-1450.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2706 - accuracy: 0.0000e+00 - val_loss: 1.4335 - val_accuracy: 0.0000e+00\n",
      "Epoch 1451/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2705 - accuracy: 0.0000e+00 - val_loss: 1.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1452/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2703 - accuracy: 0.0000e+00 - val_loss: 1.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 1453/2000\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2702 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1454/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2690 - accuracy: 0.0000e+00 - val_loss: 1.4365 - val_accuracy: 0.0000e+00\n",
      "Epoch 1455/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2372 - accuracy: 0.0000e+00\n",
      "Epoch 01455: saving model to training_0_0/cp-1455.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2710 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1456/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2696 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1457/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2701 - accuracy: 0.0000e+00 - val_loss: 1.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 1458/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2693 - accuracy: 0.0000e+00 - val_loss: 1.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1459/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2691 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 1460/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.2839 - accuracy: 0.0000e+00\n",
      "Epoch 01460: saving model to training_0_0/cp-1460.ckpt\n",
      "250/250 [==============================] - 0s 874us/step - loss: 1.2691 - accuracy: 0.0000e+00 - val_loss: 1.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1461/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2690 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1462/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2690 - accuracy: 0.0000e+00 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1463/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2681 - accuracy: 0.0000e+00 - val_loss: 1.4445 - val_accuracy: 0.0000e+00\n",
      "Epoch 1464/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.2699 - accuracy: 0.0000e+00 - val_loss: 1.4226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1465/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2407 - accuracy: 0.0000e+00\n",
      "Epoch 01465: saving model to training_0_0/cp-1465.ckpt\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.2695 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1466/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2683 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1467/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2690 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_accuracy: 0.0000e+00\n",
      "Epoch 1468/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2684 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1469/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2681 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1470/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2569 - accuracy: 0.0000e+00\n",
      "Epoch 01470: saving model to training_0_0/cp-1470.ckpt\n",
      "250/250 [==============================] - 0s 862us/step - loss: 1.2673 - accuracy: 0.0000e+00 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1471/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2683 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1472/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2682 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1473/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 881us/step - loss: 1.2678 - accuracy: 0.0000e+00 - val_loss: 1.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 1474/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2674 - accuracy: 0.0000e+00 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 1475/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.2641 - accuracy: 0.0000e+00\n",
      "Epoch 01475: saving model to training_0_0/cp-1475.ckpt\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2685 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1476/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.2685 - accuracy: 0.0000e+00 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 1477/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.2666 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1478/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2672 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1479/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2669 - accuracy: 0.0000e+00 - val_loss: 1.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1480/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2596 - accuracy: 0.0000e+00\n",
      "Epoch 01480: saving model to training_0_0/cp-1480.ckpt\n",
      "250/250 [==============================] - 0s 899us/step - loss: 1.2669 - accuracy: 0.0000e+00 - val_loss: 1.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 1481/2000\n",
      "250/250 [==============================] - 0s 771us/step - loss: 1.2668 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1482/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2656 - accuracy: 0.0000e+00 - val_loss: 1.4200 - val_accuracy: 0.0000e+00\n",
      "Epoch 1483/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2678 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1484/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2655 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 1485/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2860 - accuracy: 0.0000e+00\n",
      "Epoch 01485: saving model to training_0_0/cp-1485.ckpt\n",
      "250/250 [==============================] - 0s 895us/step - loss: 1.2665 - accuracy: 0.0000e+00 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1486/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2667 - accuracy: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1487/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2662 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1488/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2670 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1489/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2658 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1490/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2655 - accuracy: 0.0000e+00\n",
      "Epoch 01490: saving model to training_0_0/cp-1490.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2664 - accuracy: 0.0000e+00 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 1491/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2657 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1492/2000\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.2642 - accuracy: 0.0000e+00 - val_loss: 1.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1493/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2651 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1494/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2659 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1495/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.2995 - accuracy: 0.0000e+00\n",
      "Epoch 01495: saving model to training_0_0/cp-1495.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2656 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1496/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2648 - accuracy: 0.0000e+00 - val_loss: 1.4205 - val_accuracy: 0.0000e+00\n",
      "Epoch 1497/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2639 - accuracy: 0.0000e+00 - val_loss: 1.4153 - val_accuracy: 0.0000e+00\n",
      "Epoch 1498/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2651 - accuracy: 0.0000e+00 - val_loss: 1.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1499/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2645 - accuracy: 0.0000e+00 - val_loss: 1.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1500/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2917 - accuracy: 0.0000e+00\n",
      "Epoch 01500: saving model to training_0_0/cp-1500.ckpt\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.2646 - accuracy: 0.0000e+00 - val_loss: 1.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1501/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2634 - accuracy: 0.0000e+00 - val_loss: 1.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1502/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2644 - accuracy: 0.0000e+00 - val_loss: 1.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1503/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2655 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1504/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.2611 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1505/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2537 - accuracy: 0.0000e+00\n",
      "Epoch 01505: saving model to training_0_0/cp-1505.ckpt\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2651 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1506/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2634 - accuracy: 0.0000e+00 - val_loss: 1.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 1507/2000\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.2624 - accuracy: 0.0000e+00 - val_loss: 1.4280 - val_accuracy: 0.0000e+00\n",
      "Epoch 1508/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2638 - accuracy: 0.0000e+00 - val_loss: 1.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1509/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2636 - accuracy: 0.0000e+00 - val_loss: 1.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1510/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2604 - accuracy: 0.0000e+00\n",
      "Epoch 01510: saving model to training_0_0/cp-1510.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.2622 - accuracy: 0.0000e+00 - val_loss: 1.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1511/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2620 - accuracy: 0.0000e+00 - val_loss: 1.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 1512/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2641 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1513/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2632 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1514/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2639 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1515/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2665 - accuracy: 0.0000e+00\n",
      "Epoch 01515: saving model to training_0_0/cp-1515.ckpt\n",
      "250/250 [==============================] - 0s 884us/step - loss: 1.2637 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1516/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2626 - accuracy: 0.0000e+00 - val_loss: 1.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 1517/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 828us/step - loss: 1.2621 - accuracy: 0.0000e+00 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1518/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2631 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1519/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2620 - accuracy: 0.0000e+00 - val_loss: 1.4119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1520/2000\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 1.2456 - accuracy: 0.0000e+00\n",
      "Epoch 01520: saving model to training_0_0/cp-1520.ckpt\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.2624 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1521/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2612 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1522/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.2619 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1523/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2612 - accuracy: 0.0000e+00 - val_loss: 1.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 1524/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2618 - accuracy: 0.0000e+00 - val_loss: 1.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 1525/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.2815 - accuracy: 0.0000e+00\n",
      "Epoch 01525: saving model to training_0_0/cp-1525.ckpt\n",
      "250/250 [==============================] - 0s 884us/step - loss: 1.2618 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1526/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2615 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1527/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2607 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1528/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2608 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1529/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2604 - accuracy: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 1530/2000\n",
      "208/250 [=======================>......] - ETA: 0s - loss: 1.2723 - accuracy: 0.0000e+00\n",
      "Epoch 01530: saving model to training_0_0/cp-1530.ckpt\n",
      "250/250 [==============================] - 0s 888us/step - loss: 1.2607 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1531/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2595 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 1532/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2607 - accuracy: 0.0000e+00 - val_loss: 1.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 1533/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2607 - accuracy: 0.0000e+00 - val_loss: 1.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 1534/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2600 - accuracy: 0.0000e+00 - val_loss: 1.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 1535/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2646 - accuracy: 0.0000e+00\n",
      "Epoch 01535: saving model to training_0_0/cp-1535.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2594 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1536/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2591 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1537/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2601 - accuracy: 0.0000e+00 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1538/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2598 - accuracy: 0.0000e+00 - val_loss: 1.4297 - val_accuracy: 0.0000e+00\n",
      "Epoch 1539/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.2600 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1540/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2694 - accuracy: 0.0000e+00\n",
      "Epoch 01540: saving model to training_0_0/cp-1540.ckpt\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2594 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1541/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2597 - accuracy: 0.0000e+00 - val_loss: 1.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 1542/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2592 - accuracy: 0.0000e+00 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1543/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2594 - accuracy: 0.0000e+00 - val_loss: 1.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 1544/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2600 - accuracy: 0.0000e+00 - val_loss: 1.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 1545/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.2628 - accuracy: 0.0000e+00\n",
      "Epoch 01545: saving model to training_0_0/cp-1545.ckpt\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2587 - accuracy: 0.0000e+00 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 1546/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2585 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1547/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2588 - accuracy: 0.0000e+00 - val_loss: 1.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 1548/2000\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2579 - accuracy: 0.0000e+00 - val_loss: 1.4098 - val_accuracy: 0.0000e+00\n",
      "Epoch 1549/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2586 - accuracy: 0.0000e+00 - val_loss: 1.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1550/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2328 - accuracy: 0.0000e+00\n",
      "Epoch 01550: saving model to training_0_0/cp-1550.ckpt\n",
      "250/250 [==============================] - 0s 865us/step - loss: 1.2582 - accuracy: 0.0000e+00 - val_loss: 1.4129 - val_accuracy: 0.0000e+00\n",
      "Epoch 1551/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2589 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1552/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2588 - accuracy: 0.0000e+00 - val_loss: 1.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1553/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2581 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1554/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2583 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 1555/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2565 - accuracy: 0.0000e+00\n",
      "Epoch 01555: saving model to training_0_0/cp-1555.ckpt\n",
      "250/250 [==============================] - 0s 880us/step - loss: 1.2577 - accuracy: 0.0000e+00 - val_loss: 1.4419 - val_accuracy: 0.0000e+00\n",
      "Epoch 1556/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2561 - accuracy: 0.0000e+00 - val_loss: 1.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1557/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2575 - accuracy: 0.0000e+00 - val_loss: 1.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 1558/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2579 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1559/2000\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2573 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1560/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2723 - accuracy: 0.0000e+00\n",
      "Epoch 01560: saving model to training_0_0/cp-1560.ckpt\n",
      "250/250 [==============================] - 0s 879us/step - loss: 1.2573 - accuracy: 0.0000e+00 - val_loss: 1.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 1561/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 808us/step - loss: 1.2568 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1562/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2570 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1563/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2562 - accuracy: 0.0000e+00 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 1564/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2556 - accuracy: 0.0000e+00 - val_loss: 1.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 1565/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2894 - accuracy: 0.0000e+00\n",
      "Epoch 01565: saving model to training_0_0/cp-1565.ckpt\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.2568 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1566/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2555 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1567/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2565 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1568/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2556 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1569/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2550 - accuracy: 0.0000e+00 - val_loss: 1.4119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1570/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2893 - accuracy: 0.0000e+00\n",
      "Epoch 01570: saving model to training_0_0/cp-1570.ckpt\n",
      "250/250 [==============================] - 0s 889us/step - loss: 1.2549 - accuracy: 0.0000e+00 - val_loss: 1.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1571/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2548 - accuracy: 0.0000e+00 - val_loss: 1.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 1572/2000\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2540 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1573/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2552 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1574/2000\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2550 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1575/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2839 - accuracy: 0.0000e+00\n",
      "Epoch 01575: saving model to training_0_0/cp-1575.ckpt\n",
      "250/250 [==============================] - 0s 866us/step - loss: 1.2553 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1576/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2545 - accuracy: 0.0000e+00 - val_loss: 1.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 1577/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2555 - accuracy: 0.0000e+00 - val_loss: 1.4246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1578/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2546 - accuracy: 0.0000e+00 - val_loss: 1.4103 - val_accuracy: 0.0000e+00\n",
      "Epoch 1579/2000\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2552 - accuracy: 0.0000e+00 - val_loss: 1.4210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1580/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.2551 - accuracy: 0.0000e+00\n",
      "Epoch 01580: saving model to training_0_0/cp-1580.ckpt\n",
      "250/250 [==============================] - 0s 876us/step - loss: 1.2539 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1581/2000\n",
      "250/250 [==============================] - 0s 769us/step - loss: 1.2534 - accuracy: 0.0000e+00 - val_loss: 1.4287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1582/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2545 - accuracy: 0.0000e+00 - val_loss: 1.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 1583/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2535 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1584/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2547 - accuracy: 0.0000e+00 - val_loss: 1.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 1585/2000\n",
      "215/250 [========================>.....] - ETA: 0s - loss: 1.2910 - accuracy: 0.0000e+00\n",
      "Epoch 01585: saving model to training_0_0/cp-1585.ckpt\n",
      "250/250 [==============================] - 0s 872us/step - loss: 1.2538 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1586/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2542 - accuracy: 0.0000e+00 - val_loss: 1.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1587/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2536 - accuracy: 0.0000e+00 - val_loss: 1.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 1588/2000\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.2333 - accuracy: 0.0000e+ - 0s 797us/step - loss: 1.2545 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1589/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2527 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1590/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2509 - accuracy: 0.0000e+00\n",
      "Epoch 01590: saving model to training_0_0/cp-1590.ckpt\n",
      "250/250 [==============================] - 0s 891us/step - loss: 1.2523 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1591/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2538 - accuracy: 0.0000e+00 - val_loss: 1.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 1592/2000\n",
      "250/250 [==============================] - 0s 865us/step - loss: 1.2512 - accuracy: 0.0000e+00 - val_loss: 1.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 1593/2000\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2538 - accuracy: 0.0000e+00 - val_loss: 1.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1594/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2523 - accuracy: 0.0000e+00 - val_loss: 1.4113 - val_accuracy: 0.0000e+00\n",
      "Epoch 1595/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2354 - accuracy: 0.0000e+00\n",
      "Epoch 01595: saving model to training_0_0/cp-1595.ckpt\n",
      "250/250 [==============================] - 0s 888us/step - loss: 1.2505 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 1596/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2529 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1597/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2522 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1598/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2524 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1599/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2511 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1600/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2654 - accuracy: 0.0000e+00\n",
      "Epoch 01600: saving model to training_0_0/cp-1600.ckpt\n",
      "250/250 [==============================] - 0s 857us/step - loss: 1.2510 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1601/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.2523 - accuracy: 0.0000e+00 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 1602/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2515 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1603/2000\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.2512 - accuracy: 0.0000e+00 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1604/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2513 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1605/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/250 [==========================>...] - ETA: 0s - loss: 1.2438 - accuracy: 0.0000e+00\n",
      "Epoch 01605: saving model to training_0_0/cp-1605.ckpt\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2509 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1606/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2516 - accuracy: 0.0000e+00 - val_loss: 1.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1607/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2503 - accuracy: 0.0000e+00 - val_loss: 1.4097 - val_accuracy: 0.0000e+00\n",
      "Epoch 1608/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2497 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1609/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2504 - accuracy: 0.0000e+00 - val_loss: 1.4118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1610/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2310 - accuracy: 0.0000e+00\n",
      "Epoch 01610: saving model to training_0_0/cp-1610.ckpt\n",
      "250/250 [==============================] - 0s 862us/step - loss: 1.2506 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1611/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2492 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1612/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2509 - accuracy: 0.0000e+00 - val_loss: 1.4124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1613/2000\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2505 - accuracy: 0.0000e+00 - val_loss: 1.4318 - val_accuracy: 0.0000e+00\n",
      "Epoch 1614/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2494 - accuracy: 0.0000e+00 - val_loss: 1.4118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1615/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2401 - accuracy: 0.0000e+00\n",
      "Epoch 01615: saving model to training_0_0/cp-1615.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2510 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1616/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2502 - accuracy: 0.0000e+00 - val_loss: 1.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1617/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2489 - accuracy: 0.0000e+00 - val_loss: 1.4161 - val_accuracy: 0.0000e+00\n",
      "Epoch 1618/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2488 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1619/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2493 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1620/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2445 - accuracy: 0.0000e+00\n",
      "Epoch 01620: saving model to training_0_0/cp-1620.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2501 - accuracy: 0.0000e+00 - val_loss: 1.4248 - val_accuracy: 0.0000e+00\n",
      "Epoch 1621/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2499 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1622/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2507 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1623/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2485 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1624/2000\n",
      "250/250 [==============================] - 0s 865us/step - loss: 1.2490 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 1625/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2452 - accuracy: 0.0000e+00\n",
      "Epoch 01625: saving model to training_0_0/cp-1625.ckpt\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2481 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1626/2000\n",
      "250/250 [==============================] - 0s 839us/step - loss: 1.2494 - accuracy: 0.0000e+00 - val_loss: 1.4271 - val_accuracy: 0.0000e+00\n",
      "Epoch 1627/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2480 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1628/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2480 - accuracy: 0.0000e+00 - val_loss: 1.4293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1629/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2487 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1630/2000\n",
      "228/250 [==========================>...] - ETA: 0s - loss: 1.2617 - accuracy: 0.0000e+00\n",
      "Epoch 01630: saving model to training_0_0/cp-1630.ckpt\n",
      "250/250 [==============================] - 0s 845us/step - loss: 1.2481 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1631/2000\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2477 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 1632/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2471 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1633/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2473 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1634/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2484 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1635/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.2320 - accuracy: 0.0000e+00\n",
      "Epoch 01635: saving model to training_0_0/cp-1635.ckpt\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2478 - accuracy: 0.0000e+00 - val_loss: 1.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1636/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2475 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1637/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.2454 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1638/2000\n",
      "250/250 [==============================] - 0s 879us/step - loss: 1.2476 - accuracy: 0.0000e+00 - val_loss: 1.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1639/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2475 - accuracy: 0.0000e+00 - val_loss: 1.4117 - val_accuracy: 0.0000e+00\n",
      "Epoch 1640/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2494 - accuracy: 0.0000e+00\n",
      "Epoch 01640: saving model to training_0_0/cp-1640.ckpt\n",
      "250/250 [==============================] - 0s 891us/step - loss: 1.2472 - accuracy: 0.0000e+00 - val_loss: 1.4337 - val_accuracy: 0.0000e+00\n",
      "Epoch 1641/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2472 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 1642/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2460 - accuracy: 0.0000e+00 - val_loss: 1.4331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1643/2000\n",
      "250/250 [==============================] - 0s 859us/step - loss: 1.2469 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1644/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2465 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1645/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2466 - accuracy: 0.0000e+00\n",
      "Epoch 01645: saving model to training_0_0/cp-1645.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.2474 - accuracy: 0.0000e+00 - val_loss: 1.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1646/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.2461 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1647/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2453 - accuracy: 0.0000e+00 - val_loss: 1.4341 - val_accuracy: 0.0000e+00\n",
      "Epoch 1648/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2472 - accuracy: 0.0000e+00 - val_loss: 1.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 1649/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 836us/step - loss: 1.2464 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1650/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2504 - accuracy: 0.0000e+00\n",
      "Epoch 01650: saving model to training_0_0/cp-1650.ckpt\n",
      "250/250 [==============================] - 0s 849us/step - loss: 1.2456 - accuracy: 0.0000e+00 - val_loss: 1.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1651/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2455 - accuracy: 0.0000e+00 - val_loss: 1.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 1652/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2455 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 1653/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2452 - accuracy: 0.0000e+00 - val_loss: 1.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 1654/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2448 - accuracy: 0.0000e+00 - val_loss: 1.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 1655/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2574 - accuracy: 0.0000e+00\n",
      "Epoch 01655: saving model to training_0_0/cp-1655.ckpt\n",
      "250/250 [==============================] - 0s 871us/step - loss: 1.2452 - accuracy: 0.0000e+00 - val_loss: 1.4329 - val_accuracy: 0.0000e+00\n",
      "Epoch 1656/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2443 - accuracy: 0.0000e+00 - val_loss: 1.4082 - val_accuracy: 0.0000e+00\n",
      "Epoch 1657/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2442 - accuracy: 0.0000e+00 - val_loss: 1.4094 - val_accuracy: 0.0000e+00\n",
      "Epoch 1658/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2447 - accuracy: 0.0000e+00 - val_loss: 1.4138 - val_accuracy: 0.0000e+00\n",
      "Epoch 1659/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2448 - accuracy: 0.0000e+00 - val_loss: 1.4107 - val_accuracy: 0.0000e+00\n",
      "Epoch 1660/2000\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 1.2567 - accuracy: 0.0000e+00\n",
      "Epoch 01660: saving model to training_0_0/cp-1660.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2443 - accuracy: 0.0000e+00 - val_loss: 1.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1661/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2451 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1662/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2451 - accuracy: 0.0000e+00 - val_loss: 1.4110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1663/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2441 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1664/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2443 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1665/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2638 - accuracy: 0.0000e+00\n",
      "Epoch 01665: saving model to training_0_0/cp-1665.ckpt\n",
      "250/250 [==============================] - 0s 895us/step - loss: 1.2444 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1666/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2438 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1667/2000\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2439 - accuracy: 0.0000e+00 - val_loss: 1.4131 - val_accuracy: 0.0000e+00\n",
      "Epoch 1668/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2431 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1669/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2439 - accuracy: 0.0000e+00 - val_loss: 1.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 1670/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2546 - accuracy: 0.0000e+00\n",
      "Epoch 01670: saving model to training_0_0/cp-1670.ckpt\n",
      "250/250 [==============================] - 0s 877us/step - loss: 1.2428 - accuracy: 0.0000e+00 - val_loss: 1.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1671/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2433 - accuracy: 0.0000e+00 - val_loss: 1.4124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1672/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2435 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1673/2000\n",
      "250/250 [==============================] - 0s 851us/step - loss: 1.2429 - accuracy: 0.0000e+00 - val_loss: 1.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 1674/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2425 - accuracy: 0.0000e+00 - val_loss: 1.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1675/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2481 - accuracy: 0.0000e+00\n",
      "Epoch 01675: saving model to training_0_0/cp-1675.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2430 - accuracy: 0.0000e+00 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1676/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2431 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1677/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2424 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1678/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2429 - accuracy: 0.0000e+00 - val_loss: 1.4118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1679/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2425 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1680/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2786 - accuracy: 0.0000e+00\n",
      "Epoch 01680: saving model to training_0_0/cp-1680.ckpt\n",
      "250/250 [==============================] - 0s 882us/step - loss: 1.2423 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1681/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2425 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1682/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2400 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1683/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2425 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1684/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2415 - accuracy: 0.0000e+00 - val_loss: 1.4138 - val_accuracy: 0.0000e+00\n",
      "Epoch 1685/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2395 - accuracy: 0.0000e+00\n",
      "Epoch 01685: saving model to training_0_0/cp-1685.ckpt\n",
      "250/250 [==============================] - 0s 880us/step - loss: 1.2415 - accuracy: 0.0000e+00 - val_loss: 1.4257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1686/2000\n",
      "250/250 [==============================] - 0s 834us/step - loss: 1.2413 - accuracy: 0.0000e+00 - val_loss: 1.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1687/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2407 - accuracy: 0.0000e+00 - val_loss: 1.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1688/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2399 - accuracy: 0.0000e+00 - val_loss: 1.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1689/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2415 - accuracy: 0.0000e+00 - val_loss: 1.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1690/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2519 - accuracy: 0.0000e+00\n",
      "Epoch 01690: saving model to training_0_0/cp-1690.ckpt\n",
      "250/250 [==============================] - 0s 875us/step - loss: 1.2402 - accuracy: 0.0000e+00 - val_loss: 1.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 1691/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2406 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1692/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2410 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1693/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 816us/step - loss: 1.2411 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1694/2000\n",
      "250/250 [==============================] - 0s 763us/step - loss: 1.2409 - accuracy: 0.0000e+00 - val_loss: 1.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 1695/2000\n",
      "236/250 [===========================>..] - ETA: 0s - loss: 1.2386 - accuracy: 0.0000e+00\n",
      "Epoch 01695: saving model to training_0_0/cp-1695.ckpt\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2396 - accuracy: 0.0000e+00 - val_loss: 1.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1696/2000\n",
      "250/250 [==============================] - 0s 879us/step - loss: 1.2392 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1697/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2403 - accuracy: 0.0000e+00 - val_loss: 1.4152 - val_accuracy: 0.0000e+00\n",
      "Epoch 1698/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2392 - accuracy: 0.0000e+00 - val_loss: 1.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 1699/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2410 - accuracy: 0.0000e+00 - val_loss: 1.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 1700/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2215 - accuracy: 0.0000e+00\n",
      "Epoch 01700: saving model to training_0_0/cp-1700.ckpt\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2395 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1701/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2392 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1702/2000\n",
      "250/250 [==============================] - 0s 833us/step - loss: 1.2403 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1703/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2387 - accuracy: 0.0000e+00 - val_loss: 1.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1704/2000\n",
      "250/250 [==============================] - 0s 848us/step - loss: 1.2399 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1705/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2489 - accuracy: 0.0000e+00\n",
      "Epoch 01705: saving model to training_0_0/cp-1705.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2397 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1706/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2392 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1707/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2385 - accuracy: 0.0000e+00 - val_loss: 1.4129 - val_accuracy: 0.0000e+00\n",
      "Epoch 1708/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2392 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1709/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2386 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1710/2000\n",
      "207/250 [=======================>......] - ETA: 0s - loss: 1.2348 - accuracy: 0.0000e+00\n",
      "Epoch 01710: saving model to training_0_0/cp-1710.ckpt\n",
      "250/250 [==============================] - 0s 911us/step - loss: 1.2383 - accuracy: 0.0000e+00 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1711/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2379 - accuracy: 0.0000e+00 - val_loss: 1.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 1712/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2383 - accuracy: 0.0000e+00 - val_loss: 1.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 1713/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2384 - accuracy: 0.0000e+00 - val_loss: 1.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1714/2000\n",
      "250/250 [==============================] - 0s 939us/step - loss: 1.2385 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_accuracy: 0.0000e+00\n",
      "Epoch 1715/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2831 - accuracy: 0.0000e+00\n",
      "Epoch 01715: saving model to training_0_0/cp-1715.ckpt\n",
      "250/250 [==============================] - 0s 921us/step - loss: 1.2378 - accuracy: 0.0000e+00 - val_loss: 1.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 1716/2000\n",
      "250/250 [==============================] - 0s 873us/step - loss: 1.2385 - accuracy: 0.0000e+00 - val_loss: 1.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1717/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.2376 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1718/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2381 - accuracy: 0.0000e+00 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 1719/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2380 - accuracy: 0.0000e+00 - val_loss: 1.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1720/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2338 - accuracy: 0.0000e+00\n",
      "Epoch 01720: saving model to training_0_0/cp-1720.ckpt\n",
      "250/250 [==============================] - 0s 902us/step - loss: 1.2378 - accuracy: 0.0000e+00 - val_loss: 1.4129 - val_accuracy: 0.0000e+00\n",
      "Epoch 1721/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2359 - accuracy: 0.0000e+00 - val_loss: 1.4147 - val_accuracy: 0.0000e+00\n",
      "Epoch 1722/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2382 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1723/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2371 - accuracy: 0.0000e+00 - val_loss: 1.4129 - val_accuracy: 0.0000e+00\n",
      "Epoch 1724/2000\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2366 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1725/2000\n",
      "213/250 [========================>.....] - ETA: 0s - loss: 1.2317 - accuracy: 0.0000e+00\n",
      "Epoch 01725: saving model to training_0_0/cp-1725.ckpt\n",
      "250/250 [==============================] - 0s 885us/step - loss: 1.2366 - accuracy: 0.0000e+00 - val_loss: 1.4106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1726/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.2367 - accuracy: 0.0000e+00 - val_loss: 1.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 1727/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2356 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1728/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2357 - accuracy: 0.0000e+00 - val_loss: 1.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1729/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.2354 - accuracy: 0.0000e+00 - val_loss: 1.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1730/2000\n",
      "214/250 [========================>.....] - ETA: 0s - loss: 1.2923 - accuracy: 0.0000e+00\n",
      "Epoch 01730: saving model to training_0_0/cp-1730.ckpt\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.2358 - accuracy: 0.0000e+00 - val_loss: 1.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 1731/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2353 - accuracy: 0.0000e+00 - val_loss: 1.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1732/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2364 - accuracy: 0.0000e+00 - val_loss: 1.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 1733/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2357 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1734/2000\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2344 - accuracy: 0.0000e+00 - val_loss: 1.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1735/2000\n",
      "219/250 [=========================>....] - ETA: 0s - loss: 1.2091 - accuracy: 0.0000e+00\n",
      "Epoch 01735: saving model to training_0_0/cp-1735.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2356 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1736/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2347 - accuracy: 0.0000e+00 - val_loss: 1.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 1737/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 825us/step - loss: 1.2361 - accuracy: 0.0000e+00 - val_loss: 1.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1738/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2355 - accuracy: 0.0000e+00 - val_loss: 1.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1739/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.2352 - accuracy: 0.0000e+00 - val_loss: 1.4246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1740/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.2500 - accuracy: 0.0000e+00\n",
      "Epoch 01740: saving model to training_0_0/cp-1740.ckpt\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2353 - accuracy: 0.0000e+00 - val_loss: 1.4223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1741/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.2344 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1742/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2339 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1743/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2349 - accuracy: 0.0000e+00 - val_loss: 1.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1744/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2343 - accuracy: 0.0000e+00 - val_loss: 1.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1745/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2259 - accuracy: 0.0000e+00\n",
      "Epoch 01745: saving model to training_0_0/cp-1745.ckpt\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.2320 - accuracy: 0.0000e+00 - val_loss: 1.4119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1746/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2348 - accuracy: 0.0000e+00 - val_loss: 1.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 1747/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2337 - accuracy: 0.0000e+00 - val_loss: 1.4414 - val_accuracy: 0.0000e+00\n",
      "Epoch 1748/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2350 - accuracy: 0.0000e+00 - val_loss: 1.4161 - val_accuracy: 0.0000e+00\n",
      "Epoch 1749/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2341 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1750/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.2310 - accuracy: 0.0000e+00\n",
      "Epoch 01750: saving model to training_0_0/cp-1750.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2334 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 1751/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.2339 - accuracy: 0.0000e+00 - val_loss: 1.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1752/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2341 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1753/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2336 - accuracy: 0.0000e+00 - val_loss: 1.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1754/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2345 - accuracy: 0.0000e+00 - val_loss: 1.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 1755/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2257 - accuracy: 0.0000e+00\n",
      "Epoch 01755: saving model to training_0_0/cp-1755.ckpt\n",
      "250/250 [==============================] - 0s 867us/step - loss: 1.2317 - accuracy: 0.0000e+00 - val_loss: 1.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 1756/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2335 - accuracy: 0.0000e+00 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 1757/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2320 - accuracy: 0.0000e+00 - val_loss: 1.4103 - val_accuracy: 0.0000e+00\n",
      "Epoch 1758/2000\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2327 - accuracy: 0.0000e+00 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 1759/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2333 - accuracy: 0.0000e+00 - val_loss: 1.4161 - val_accuracy: 0.0000e+00\n",
      "Epoch 1760/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2347 - accuracy: 0.0000e+00\n",
      "Epoch 01760: saving model to training_0_0/cp-1760.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2337 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1761/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2325 - accuracy: 0.0000e+00 - val_loss: 1.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 1762/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.2318 - accuracy: 0.0000e+00 - val_loss: 1.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 1763/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2330 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1764/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2305 - accuracy: 0.0000e+00 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1765/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.1934 - accuracy: 0.0000e+00\n",
      "Epoch 01765: saving model to training_0_0/cp-1765.ckpt\n",
      "250/250 [==============================] - 0s 862us/step - loss: 1.2312 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1766/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2317 - accuracy: 0.0000e+00 - val_loss: 1.4112 - val_accuracy: 0.0000e+00\n",
      "Epoch 1767/2000\n",
      "250/250 [==============================] - 0s 860us/step - loss: 1.2305 - accuracy: 0.0000e+00 - val_loss: 1.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 1768/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2311 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1769/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2323 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1770/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2350 - accuracy: 0.0000e+00\n",
      "Epoch 01770: saving model to training_0_0/cp-1770.ckpt\n",
      "250/250 [==============================] - 0s 843us/step - loss: 1.2317 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1771/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2317 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1772/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2309 - accuracy: 0.0000e+00 - val_loss: 1.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1773/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2290 - accuracy: 0.0000e+00 - val_loss: 1.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 1774/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2295 - accuracy: 0.0000e+00 - val_loss: 1.4093 - val_accuracy: 0.0000e+00\n",
      "Epoch 1775/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2415 - accuracy: 0.0000e+00\n",
      "Epoch 01775: saving model to training_0_0/cp-1775.ckpt\n",
      "250/250 [==============================] - 0s 858us/step - loss: 1.2318 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1776/2000\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2318 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1777/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2311 - accuracy: 0.0000e+00 - val_loss: 1.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 1778/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2298 - accuracy: 0.0000e+00 - val_loss: 1.4437 - val_accuracy: 0.0000e+00\n",
      "Epoch 1779/2000\n",
      "250/250 [==============================] - 0s 822us/step - loss: 1.2308 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1780/2000\n",
      "210/250 [========================>.....] - ETA: 0s - loss: 1.2253 - accuracy: 0.0000e+00\n",
      "Epoch 01780: saving model to training_0_0/cp-1780.ckpt\n",
      "250/250 [==============================] - 0s 888us/step - loss: 1.2306 - accuracy: 0.0000e+00 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 1781/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 852us/step - loss: 1.2286 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1782/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2291 - accuracy: 0.0000e+00 - val_loss: 1.4464 - val_accuracy: 0.0000e+00\n",
      "Epoch 1783/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2311 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1784/2000\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2291 - accuracy: 0.0000e+00 - val_loss: 1.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1785/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.2314 - accuracy: 0.0000e+00\n",
      "Epoch 01785: saving model to training_0_0/cp-1785.ckpt\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2290 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1786/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.2294 - accuracy: 0.0000e+00 - val_loss: 1.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 1787/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2283 - accuracy: 0.0000e+00 - val_loss: 1.4259 - val_accuracy: 0.0000e+00\n",
      "Epoch 1788/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.2288 - accuracy: 0.0000e+00 - val_loss: 1.4117 - val_accuracy: 0.0000e+00\n",
      "Epoch 1789/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.2297 - accuracy: 0.0000e+00 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 1790/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.2301 - accuracy: 0.0000e+00\n",
      "Epoch 01790: saving model to training_0_0/cp-1790.ckpt\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2277 - accuracy: 0.0000e+00 - val_loss: 1.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1791/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2283 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 1792/2000\n",
      "250/250 [==============================] - 0s 782us/step - loss: 1.2287 - accuracy: 0.0000e+00 - val_loss: 1.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 1793/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2274 - accuracy: 0.0000e+00 - val_loss: 1.4084 - val_accuracy: 0.0000e+00\n",
      "Epoch 1794/2000\n",
      "250/250 [==============================] - 0s 768us/step - loss: 1.2296 - accuracy: 0.0000e+00 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 1795/2000\n",
      "244/250 [============================>.] - ETA: 0s - loss: 1.2442 - accuracy: 0.0000e+00\n",
      "Epoch 01795: saving model to training_0_0/cp-1795.ckpt\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.2291 - accuracy: 0.0000e+00 - val_loss: 1.4154 - val_accuracy: 0.0000e+00\n",
      "Epoch 1796/2000\n",
      "250/250 [==============================] - 0s 785us/step - loss: 1.2285 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1797/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.2284 - accuracy: 0.0000e+00 - val_loss: 1.4207 - val_accuracy: 0.0000e+00\n",
      "Epoch 1798/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2273 - accuracy: 0.0000e+00 - val_loss: 1.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1799/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2279 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1800/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.1983 - accuracy: 0.0000e+00\n",
      "Epoch 01800: saving model to training_0_0/cp-1800.ckpt\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2270 - accuracy: 0.0000e+00 - val_loss: 1.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 1801/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.2267 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1802/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.2276 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1803/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.2272 - accuracy: 0.0000e+00 - val_loss: 1.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 1804/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.2265 - accuracy: 0.0000e+00 - val_loss: 1.4165 - val_accuracy: 0.0000e+00\n",
      "Epoch 1805/2000\n",
      "233/250 [==========================>...] - ETA: 0s - loss: 1.2082 - accuracy: 0.0000e+00\n",
      "Epoch 01805: saving model to training_0_0/cp-1805.ckpt\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2269 - accuracy: 0.0000e+00 - val_loss: 1.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1806/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2265 - accuracy: 0.0000e+00 - val_loss: 1.4112 - val_accuracy: 0.0000e+00\n",
      "Epoch 1807/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2258 - accuracy: 0.0000e+00 - val_loss: 1.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 1808/2000\n",
      "250/250 [==============================] - 0s 797us/step - loss: 1.2244 - accuracy: 0.0000e+00 - val_loss: 1.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1809/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2248 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1810/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2068 - accuracy: 0.0000e+00\n",
      "Epoch 01810: saving model to training_0_0/cp-1810.ckpt\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2249 - accuracy: 0.0000e+00 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 1811/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.2257 - accuracy: 0.0000e+00 - val_loss: 1.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 1812/2000\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2260 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1813/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2266 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1814/2000\n",
      "250/250 [==============================] - 0s 850us/step - loss: 1.2252 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1815/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2181 - accuracy: 0.0000e+00\n",
      "Epoch 01815: saving model to training_0_0/cp-1815.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2258 - accuracy: 0.0000e+00 - val_loss: 1.4393 - val_accuracy: 0.0000e+00\n",
      "Epoch 1816/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.2256 - accuracy: 0.0000e+00 - val_loss: 1.4248 - val_accuracy: 0.0000e+00\n",
      "Epoch 1817/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2255 - accuracy: 0.0000e+00 - val_loss: 1.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 1818/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.2255 - accuracy: 0.0000e+00 - val_loss: 1.4215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1819/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2253 - accuracy: 0.0000e+00 - val_loss: 1.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 1820/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.2344 - accuracy: 0.0000e+00\n",
      "Epoch 01820: saving model to training_0_0/cp-1820.ckpt\n",
      "250/250 [==============================] - 0s 847us/step - loss: 1.2246 - accuracy: 0.0000e+00 - val_loss: 1.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1821/2000\n",
      "250/250 [==============================] - 0s 786us/step - loss: 1.2243 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1822/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.2252 - accuracy: 0.0000e+00 - val_loss: 1.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 1823/2000\n",
      "250/250 [==============================] - 0s 779us/step - loss: 1.2245 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1824/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2237 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1825/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2177 - accuracy: 0.0000e+00\n",
      "Epoch 01825: saving model to training_0_0/cp-1825.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 829us/step - loss: 1.2250 - accuracy: 0.0000e+00 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 1826/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.2247 - accuracy: 0.0000e+00 - val_loss: 1.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1827/2000\n",
      "250/250 [==============================] - 0s 781us/step - loss: 1.2238 - accuracy: 0.0000e+00 - val_loss: 1.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 1828/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2246 - accuracy: 0.0000e+00 - val_loss: 1.4111 - val_accuracy: 0.0000e+00\n",
      "Epoch 1829/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.2239 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1830/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.2052 - accuracy: 0.0000e+00\n",
      "Epoch 01830: saving model to training_0_0/cp-1830.ckpt\n",
      "250/250 [==============================] - 0s 878us/step - loss: 1.2238 - accuracy: 0.0000e+00 - val_loss: 1.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1831/2000\n",
      "250/250 [==============================] - 0s 780us/step - loss: 1.2241 - accuracy: 0.0000e+00 - val_loss: 1.4119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1832/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2226 - accuracy: 0.0000e+00 - val_loss: 1.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 1833/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.2224 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1834/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2225 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1835/2000\n",
      "212/250 [========================>.....] - ETA: 0s - loss: 1.2023 - accuracy: 0.0000e+00\n",
      "Epoch 01835: saving model to training_0_0/cp-1835.ckpt\n",
      "250/250 [==============================] - 0s 877us/step - loss: 1.2231 - accuracy: 0.0000e+00 - val_loss: 1.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 1836/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2229 - accuracy: 0.0000e+00 - val_loss: 1.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 1837/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2217 - accuracy: 0.0000e+00 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1838/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2232 - accuracy: 0.0000e+00 - val_loss: 1.4197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1839/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2231 - accuracy: 0.0000e+00 - val_loss: 1.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 1840/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.2150 - accuracy: 0.0000e+00\n",
      "Epoch 01840: saving model to training_0_0/cp-1840.ckpt\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2222 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1841/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2227 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1842/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2221 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1843/2000\n",
      "250/250 [==============================] - 0s 796us/step - loss: 1.2226 - accuracy: 0.0000e+00 - val_loss: 1.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 1844/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2220 - accuracy: 0.0000e+00 - val_loss: 1.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 1845/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2320 - accuracy: 0.0000e+00\n",
      "Epoch 01845: saving model to training_0_0/cp-1845.ckpt\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2213 - accuracy: 0.0000e+00 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 1846/2000\n",
      "250/250 [==============================] - 0s 788us/step - loss: 1.2226 - accuracy: 0.0000e+00 - val_loss: 1.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1847/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.2223 - accuracy: 0.0000e+00 - val_loss: 1.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1848/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2220 - accuracy: 0.0000e+00 - val_loss: 1.4107 - val_accuracy: 0.0000e+00\n",
      "Epoch 1849/2000\n",
      "250/250 [==============================] - 0s 793us/step - loss: 1.2218 - accuracy: 0.0000e+00 - val_loss: 1.4136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1850/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.1858 - accuracy: 0.0000e+00\n",
      "Epoch 01850: saving model to training_0_0/cp-1850.ckpt\n",
      "250/250 [==============================] - 0s 882us/step - loss: 1.2217 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1851/2000\n",
      "250/250 [==============================] - 0s 770us/step - loss: 1.2223 - accuracy: 0.0000e+00 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1852/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2221 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1853/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2215 - accuracy: 0.0000e+00 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 1854/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2208 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1855/2000\n",
      "223/250 [=========================>....] - ETA: 0s - loss: 1.2103 - accuracy: 0.0000e+00\n",
      "Epoch 01855: saving model to training_0_0/cp-1855.ckpt\n",
      "250/250 [==============================] - 0s 861us/step - loss: 1.2215 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1856/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2203 - accuracy: 0.0000e+00 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 1857/2000\n",
      "250/250 [==============================] - 0s 810us/step - loss: 1.2213 - accuracy: 0.0000e+00 - val_loss: 1.4143 - val_accuracy: 0.0000e+00\n",
      "Epoch 1858/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2189 - accuracy: 0.0000e+00 - val_loss: 1.4529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1859/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2204 - accuracy: 0.0000e+00 - val_loss: 1.4147 - val_accuracy: 0.0000e+00\n",
      "Epoch 1860/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2087 - accuracy: 0.0000e+00\n",
      "Epoch 01860: saving model to training_0_0/cp-1860.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2197 - accuracy: 0.0000e+00 - val_loss: 1.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1861/2000\n",
      "250/250 [==============================] - 0s 837us/step - loss: 1.2208 - accuracy: 0.0000e+00 - val_loss: 1.4213 - val_accuracy: 0.0000e+00\n",
      "Epoch 1862/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2199 - accuracy: 0.0000e+00 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 1863/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2198 - accuracy: 0.0000e+00 - val_loss: 1.4124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1864/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2197 - accuracy: 0.0000e+00 - val_loss: 1.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1865/2000\n",
      "229/250 [==========================>...] - ETA: 0s - loss: 1.2015 - accuracy: 0.0000e+00\n",
      "Epoch 01865: saving model to training_0_0/cp-1865.ckpt\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2203 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1866/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2195 - accuracy: 0.0000e+00 - val_loss: 1.4275 - val_accuracy: 0.0000e+00\n",
      "Epoch 1867/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2198 - accuracy: 0.0000e+00 - val_loss: 1.4435 - val_accuracy: 0.0000e+00\n",
      "Epoch 1868/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2186 - accuracy: 0.0000e+00 - val_loss: 1.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 1869/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2186 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1870/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.2083 - accuracy: 0.0000e+00\n",
      "Epoch 01870: saving model to training_0_0/cp-1870.ckpt\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2189 - accuracy: 0.0000e+00 - val_loss: 1.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1871/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2198 - accuracy: 0.0000e+00 - val_loss: 1.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 1872/2000\n",
      "250/250 [==============================] - 0s 760us/step - loss: 1.2195 - accuracy: 0.0000e+00 - val_loss: 1.4259 - val_accuracy: 0.0000e+00\n",
      "Epoch 1873/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2187 - accuracy: 0.0000e+00 - val_loss: 1.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1874/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2193 - accuracy: 0.0000e+00 - val_loss: 1.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 1875/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.2192 - accuracy: 0.0000e+00\n",
      "Epoch 01875: saving model to training_0_0/cp-1875.ckpt\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2191 - accuracy: 0.0000e+00 - val_loss: 1.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 1876/2000\n",
      "250/250 [==============================] - 0s 777us/step - loss: 1.2188 - accuracy: 0.0000e+00 - val_loss: 1.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 1877/2000\n",
      "250/250 [==============================] - 0s 800us/step - loss: 1.2185 - accuracy: 0.0000e+00 - val_loss: 1.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 1878/2000\n",
      "250/250 [==============================] - 0s 789us/step - loss: 1.2179 - accuracy: 0.0000e+00 - val_loss: 1.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 1879/2000\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2182 - accuracy: 0.0000e+00 - val_loss: 1.4176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1880/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.2394 - accuracy: 0.0000e+00\n",
      "Epoch 01880: saving model to training_0_0/cp-1880.ckpt\n",
      "250/250 [==============================] - 0s 853us/step - loss: 1.2153 - accuracy: 0.0000e+00 - val_loss: 1.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 1881/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2184 - accuracy: 0.0000e+00 - val_loss: 1.4145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1882/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2170 - accuracy: 0.0000e+00 - val_loss: 1.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1883/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2184 - accuracy: 0.0000e+00 - val_loss: 1.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1884/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2183 - accuracy: 0.0000e+00 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 1885/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2265 - accuracy: 0.0000e+00\n",
      "Epoch 01885: saving model to training_0_0/cp-1885.ckpt\n",
      "250/250 [==============================] - 0s 866us/step - loss: 1.2164 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1886/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2176 - accuracy: 0.0000e+00 - val_loss: 1.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 1887/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2173 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1888/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2163 - accuracy: 0.0000e+00 - val_loss: 1.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 1889/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2169 - accuracy: 0.0000e+00 - val_loss: 1.4231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1890/2000\n",
      "231/250 [==========================>...] - ETA: 0s - loss: 1.2058 - accuracy: 0.0000e+00\n",
      "Epoch 01890: saving model to training_0_0/cp-1890.ckpt\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2169 - accuracy: 0.0000e+00 - val_loss: 1.4150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1891/2000\n",
      "250/250 [==============================] - 0s 798us/step - loss: 1.2165 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1892/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2172 - accuracy: 0.0000e+00 - val_loss: 1.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1893/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2151 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1894/2000\n",
      "250/250 [==============================] - 0s 825us/step - loss: 1.2163 - accuracy: 0.0000e+00 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 1895/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2199 - accuracy: 0.0000e+00\n",
      "Epoch 01895: saving model to training_0_0/cp-1895.ckpt\n",
      "250/250 [==============================] - 0s 860us/step - loss: 1.2154 - accuracy: 0.0000e+00 - val_loss: 1.4161 - val_accuracy: 0.0000e+00\n",
      "Epoch 1896/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2159 - accuracy: 0.0000e+00 - val_loss: 1.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 1897/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2166 - accuracy: 0.0000e+00 - val_loss: 1.4206 - val_accuracy: 0.0000e+00\n",
      "Epoch 1898/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2157 - accuracy: 0.0000e+00 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 1899/2000\n",
      "250/250 [==============================] - 0s 864us/step - loss: 1.2163 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1900/2000\n",
      "234/250 [===========================>..] - ETA: 0s - loss: 1.2295 - accuracy: 0.0000e+00\n",
      "Epoch 01900: saving model to training_0_0/cp-1900.ckpt\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2164 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1901/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2158 - accuracy: 0.0000e+00 - val_loss: 1.4142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1902/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2150 - accuracy: 0.0000e+00 - val_loss: 1.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 1903/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2140 - accuracy: 0.0000e+00 - val_loss: 1.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1904/2000\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2143 - accuracy: 0.0000e+00 - val_loss: 1.4112 - val_accuracy: 0.0000e+00\n",
      "Epoch 1905/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2136 - accuracy: 0.0000e+00\n",
      "Epoch 01905: saving model to training_0_0/cp-1905.ckpt\n",
      "250/250 [==============================] - 0s 870us/step - loss: 1.2155 - accuracy: 0.0000e+00 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 1906/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2144 - accuracy: 0.0000e+00 - val_loss: 1.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 1907/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.2139 - accuracy: 0.0000e+00 - val_loss: 1.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 1908/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2128 - accuracy: 0.0000e+00 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1909/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2151 - accuracy: 0.0000e+00 - val_loss: 1.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1910/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.1955 - accuracy: 0.0000e+00\n",
      "Epoch 01910: saving model to training_0_0/cp-1910.ckpt\n",
      "250/250 [==============================] - 0s 860us/step - loss: 1.2143 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1911/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2140 - accuracy: 0.0000e+00 - val_loss: 1.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 1912/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2143 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1913/2000\n",
      "250/250 [==============================] - 0s 795us/step - loss: 1.2135 - accuracy: 0.0000e+00 - val_loss: 1.4233 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1914/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2138 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 1915/2000\n",
      "230/250 [==========================>...] - ETA: 0s - loss: 1.2142 - accuracy: 0.0000e+00\n",
      "Epoch 01915: saving model to training_0_0/cp-1915.ckpt\n",
      "250/250 [==============================] - 0s 828us/step - loss: 1.2129 - accuracy: 0.0000e+00 - val_loss: 1.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 1916/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2132 - accuracy: 0.0000e+00 - val_loss: 1.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1917/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2134 - accuracy: 0.0000e+00 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1918/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2127 - accuracy: 0.0000e+00 - val_loss: 1.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1919/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2133 - accuracy: 0.0000e+00 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 1920/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2397 - accuracy: 0.0000e+00\n",
      "Epoch 01920: saving model to training_0_0/cp-1920.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2134 - accuracy: 0.0000e+00 - val_loss: 1.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 1921/2000\n",
      "250/250 [==============================] - 0s 820us/step - loss: 1.2130 - accuracy: 0.0000e+00 - val_loss: 1.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 1922/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2126 - accuracy: 0.0000e+00 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1923/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2132 - accuracy: 0.0000e+00 - val_loss: 1.4283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1924/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2126 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1925/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2087 - accuracy: 0.0000e+00\n",
      "Epoch 01925: saving model to training_0_0/cp-1925.ckpt\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2126 - accuracy: 0.0000e+00 - val_loss: 1.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 1926/2000\n",
      "250/250 [==============================] - 0s 804us/step - loss: 1.2116 - accuracy: 0.0000e+00 - val_loss: 1.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 1927/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2120 - accuracy: 0.0000e+00 - val_loss: 1.4265 - val_accuracy: 0.0000e+00\n",
      "Epoch 1928/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2116 - accuracy: 0.0000e+00 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 1929/2000\n",
      "250/250 [==============================] - 0s 829us/step - loss: 1.2116 - accuracy: 0.0000e+00 - val_loss: 1.4163 - val_accuracy: 0.0000e+00\n",
      "Epoch 1930/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2034 - accuracy: 0.0000e+00\n",
      "Epoch 01930: saving model to training_0_0/cp-1930.ckpt\n",
      "250/250 [==============================] - 0s 835us/step - loss: 1.2114 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1931/2000\n",
      "250/250 [==============================] - 0s 855us/step - loss: 1.2108 - accuracy: 0.0000e+00 - val_loss: 1.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1932/2000\n",
      "250/250 [==============================] - 0s 819us/step - loss: 1.2109 - accuracy: 0.0000e+00 - val_loss: 1.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 1933/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2125 - accuracy: 0.0000e+00 - val_loss: 1.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 1934/2000\n",
      "250/250 [==============================] - 0s 836us/step - loss: 1.2105 - accuracy: 0.0000e+00 - val_loss: 1.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 1935/2000\n",
      "221/250 [=========================>....] - ETA: 0s - loss: 1.1959 - accuracy: 0.0000e+00\n",
      "Epoch 01935: saving model to training_0_0/cp-1935.ckpt\n",
      "250/250 [==============================] - 0s 856us/step - loss: 1.2090 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1936/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2103 - accuracy: 0.0000e+00 - val_loss: 1.4184 - val_accuracy: 0.0000e+00\n",
      "Epoch 1937/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2113 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 1938/2000\n",
      "250/250 [==============================] - 0s 812us/step - loss: 1.2119 - accuracy: 0.0000e+00 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1939/2000\n",
      "250/250 [==============================] - 0s 799us/step - loss: 1.2105 - accuracy: 0.0000e+00 - val_loss: 1.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1940/2000\n",
      "220/250 [=========================>....] - ETA: 0s - loss: 1.2252 - accuracy: 0.0000e+00\n",
      "Epoch 01940: saving model to training_0_0/cp-1940.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2103 - accuracy: 0.0000e+00 - val_loss: 1.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1941/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2106 - accuracy: 0.0000e+00 - val_loss: 1.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 1942/2000\n",
      "250/250 [==============================] - 0s 824us/step - loss: 1.2117 - accuracy: 0.0000e+00 - val_loss: 1.4153 - val_accuracy: 0.0000e+00\n",
      "Epoch 1943/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2094 - accuracy: 0.0000e+00 - val_loss: 1.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1944/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2094 - accuracy: 0.0000e+00 - val_loss: 1.4144 - val_accuracy: 0.0000e+00\n",
      "Epoch 1945/2000\n",
      "226/250 [==========================>...] - ETA: 0s - loss: 1.2251 - accuracy: 0.0000e+00\n",
      "Epoch 01945: saving model to training_0_0/cp-1945.ckpt\n",
      "250/250 [==============================] - 0s 863us/step - loss: 1.2097 - accuracy: 0.0000e+00 - val_loss: 1.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 1946/2000\n",
      "250/250 [==============================] - 0s 762us/step - loss: 1.2109 - accuracy: 0.0000e+00 - val_loss: 1.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 1947/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2094 - accuracy: 0.0000e+00 - val_loss: 1.4358 - val_accuracy: 0.0000e+00\n",
      "Epoch 1948/2000\n",
      "250/250 [==============================] - 0s 827us/step - loss: 1.2093 - accuracy: 0.0000e+00 - val_loss: 1.4124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1949/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2095 - accuracy: 0.0000e+00 - val_loss: 1.4132 - val_accuracy: 0.0000e+00\n",
      "Epoch 1950/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2138 - accuracy: 0.0000e+00\n",
      "Epoch 01950: saving model to training_0_0/cp-1950.ckpt\n",
      "250/250 [==============================] - 0s 844us/step - loss: 1.2091 - accuracy: 0.0000e+00 - val_loss: 1.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 1951/2000\n",
      "250/250 [==============================] - 0s 783us/step - loss: 1.2094 - accuracy: 0.0000e+00 - val_loss: 1.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 1952/2000\n",
      "250/250 [==============================] - 0s 790us/step - loss: 1.2086 - accuracy: 0.0000e+00 - val_loss: 1.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1953/2000\n",
      "250/250 [==============================] - 0s 794us/step - loss: 1.2093 - accuracy: 0.0000e+00 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 1954/2000\n",
      "250/250 [==============================] - 0s 792us/step - loss: 1.2095 - accuracy: 0.0000e+00 - val_loss: 1.4214 - val_accuracy: 0.0000e+00\n",
      "Epoch 1955/2000\n",
      "216/250 [========================>.....] - ETA: 0s - loss: 1.2149 - accuracy: 0.0000e+00\n",
      "Epoch 01955: saving model to training_0_0/cp-1955.ckpt\n",
      "250/250 [==============================] - 0s 886us/step - loss: 1.2084 - accuracy: 0.0000e+00 - val_loss: 1.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 1956/2000\n",
      "250/250 [==============================] - 0s 815us/step - loss: 1.2086 - accuracy: 0.0000e+00 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1957/2000\n",
      "250/250 [==============================] - 0s 805us/step - loss: 1.2089 - accuracy: 0.0000e+00 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1958/2000\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2080 - accuracy: 0.0000e+00 - val_loss: 1.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 1959/2000\n",
      "250/250 [==============================] - 0s 787us/step - loss: 1.2080 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1960/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.2287 - accuracy: 0.0000e+00\n",
      "Epoch 01960: saving model to training_0_0/cp-1960.ckpt\n",
      "250/250 [==============================] - 0s 852us/step - loss: 1.2079 - accuracy: 0.0000e+00 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1961/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2073 - accuracy: 0.0000e+00 - val_loss: 1.4148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1962/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2080 - accuracy: 0.0000e+00 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1963/2000\n",
      "250/250 [==============================] - 0s 818us/step - loss: 1.2083 - accuracy: 0.0000e+00 - val_loss: 1.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1964/2000\n",
      "250/250 [==============================] - 0s 821us/step - loss: 1.2080 - accuracy: 0.0000e+00 - val_loss: 1.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 1965/2000\n",
      "227/250 [==========================>...] - ETA: 0s - loss: 1.2130 - accuracy: 0.0000e+00\n",
      "Epoch 01965: saving model to training_0_0/cp-1965.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2083 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1966/2000\n",
      "250/250 [==============================] - 0s 809us/step - loss: 1.2072 - accuracy: 0.0000e+00 - val_loss: 1.4194 - val_accuracy: 0.0000e+00\n",
      "Epoch 1967/2000\n",
      "250/250 [==============================] - 0s 808us/step - loss: 1.2079 - accuracy: 0.0000e+00 - val_loss: 1.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 1968/2000\n",
      "250/250 [==============================] - 0s 803us/step - loss: 1.2070 - accuracy: 0.0000e+00 - val_loss: 1.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 1969/2000\n",
      "250/250 [==============================] - 0s 801us/step - loss: 1.2053 - accuracy: 0.0000e+00 - val_loss: 1.4246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1970/2000\n",
      "232/250 [==========================>...] - ETA: 0s - loss: 1.2073 - accuracy: 0.0000e+00\n",
      "Epoch 01970: saving model to training_0_0/cp-1970.ckpt\n",
      "250/250 [==============================] - 0s 846us/step - loss: 1.2058 - accuracy: 0.0000e+00 - val_loss: 1.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 1971/2000\n",
      "250/250 [==============================] - 0s 791us/step - loss: 1.2064 - accuracy: 0.0000e+00 - val_loss: 1.4216 - val_accuracy: 0.0000e+00\n",
      "Epoch 1972/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2056 - accuracy: 0.0000e+00 - val_loss: 1.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 1973/2000\n",
      "250/250 [==============================] - 0s 838us/step - loss: 1.2062 - accuracy: 0.0000e+00 - val_loss: 1.4155 - val_accuracy: 0.0000e+00\n",
      "Epoch 1974/2000\n",
      "250/250 [==============================] - 0s 826us/step - loss: 1.2050 - accuracy: 0.0000e+00 - val_loss: 1.4127 - val_accuracy: 0.0000e+00\n",
      "Epoch 1975/2000\n",
      "240/250 [===========================>..] - ETA: 0s - loss: 1.2076 - accuracy: 0.0000e+00\n",
      "Epoch 01975: saving model to training_0_0/cp-1975.ckpt\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2052 - accuracy: 0.0000e+00 - val_loss: 1.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1976/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2070 - accuracy: 0.0000e+00 - val_loss: 1.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 1977/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2061 - accuracy: 0.0000e+00 - val_loss: 1.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 1978/2000\n",
      "250/250 [==============================] - 0s 778us/step - loss: 1.2055 - accuracy: 0.0000e+00 - val_loss: 1.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 1979/2000\n",
      "250/250 [==============================] - 0s 775us/step - loss: 1.2066 - accuracy: 0.0000e+00 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1980/2000\n",
      "218/250 [=========================>....] - ETA: 0s - loss: 1.1999 - accuracy: 0.0000e+00\n",
      "Epoch 01980: saving model to training_0_0/cp-1980.ckpt\n",
      "250/250 [==============================] - 0s 895us/step - loss: 1.2061 - accuracy: 0.0000e+00 - val_loss: 1.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1981/2000\n",
      "250/250 [==============================] - 0s 823us/step - loss: 1.2058 - accuracy: 0.0000e+00 - val_loss: 1.4196 - val_accuracy: 0.0000e+00\n",
      "Epoch 1982/2000\n",
      "250/250 [==============================] - 0s 887us/step - loss: 1.2051 - accuracy: 0.0000e+00 - val_loss: 1.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 1983/2000\n",
      "250/250 [==============================] - 0s 802us/step - loss: 1.2056 - accuracy: 0.0000e+00 - val_loss: 1.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 1984/2000\n",
      "250/250 [==============================] - 0s 817us/step - loss: 1.2041 - accuracy: 0.0000e+00 - val_loss: 1.4113 - val_accuracy: 0.0000e+00\n",
      "Epoch 1985/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.2055 - accuracy: 0.0000e+00\n",
      "Epoch 01985: saving model to training_0_0/cp-1985.ckpt\n",
      "250/250 [==============================] - 0s 854us/step - loss: 1.2039 - accuracy: 0.0000e+00 - val_loss: 1.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 1986/2000\n",
      "250/250 [==============================] - 0s 806us/step - loss: 1.2044 - accuracy: 0.0000e+00 - val_loss: 1.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1987/2000\n",
      "250/250 [==============================] - 0s 807us/step - loss: 1.2048 - accuracy: 0.0000e+00 - val_loss: 1.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 1988/2000\n",
      "250/250 [==============================] - 0s 784us/step - loss: 1.2056 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 1989/2000\n",
      "250/250 [==============================] - 0s 816us/step - loss: 1.2047 - accuracy: 0.0000e+00 - val_loss: 1.4138 - val_accuracy: 0.0000e+00\n",
      "Epoch 1990/2000\n",
      "222/250 [=========================>....] - ETA: 0s - loss: 1.2301 - accuracy: 0.0000e+00\n",
      "Epoch 01990: saving model to training_0_0/cp-1990.ckpt\n",
      "250/250 [==============================] - 0s 841us/step - loss: 1.2047 - accuracy: 0.0000e+00 - val_loss: 1.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 1991/2000\n",
      "250/250 [==============================] - 0s 830us/step - loss: 1.2037 - accuracy: 0.0000e+00 - val_loss: 1.4312 - val_accuracy: 0.0000e+00\n",
      "Epoch 1992/2000\n",
      "250/250 [==============================] - 0s 832us/step - loss: 1.2048 - accuracy: 0.0000e+00 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 1993/2000\n",
      "250/250 [==============================] - 0s 831us/step - loss: 1.2037 - accuracy: 0.0000e+00 - val_loss: 1.4241 - val_accuracy: 0.0000e+00\n",
      "Epoch 1994/2000\n",
      "250/250 [==============================] - 0s 811us/step - loss: 1.2041 - accuracy: 0.0000e+00 - val_loss: 1.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1995/2000\n",
      "224/250 [=========================>....] - ETA: 0s - loss: 1.1920 - accuracy: 0.0000e+00\n",
      "Epoch 01995: saving model to training_0_0/cp-1995.ckpt\n",
      "250/250 [==============================] - 0s 869us/step - loss: 1.2040 - accuracy: 0.0000e+00 - val_loss: 1.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 1996/2000\n",
      "250/250 [==============================] - 0s 842us/step - loss: 1.2023 - accuracy: 0.0000e+00 - val_loss: 1.4232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1997/2000\n",
      "250/250 [==============================] - 0s 813us/step - loss: 1.2032 - accuracy: 0.0000e+00 - val_loss: 1.4245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1998/2000\n",
      "250/250 [==============================] - 0s 840us/step - loss: 1.2046 - accuracy: 0.0000e+00 - val_loss: 1.4221 - val_accuracy: 0.0000e+00\n",
      "Epoch 1999/2000\n",
      "250/250 [==============================] - 0s 814us/step - loss: 1.2041 - accuracy: 0.0000e+00 - val_loss: 1.4202 - val_accuracy: 0.0000e+00\n",
      "Epoch 2000/2000\n",
      "217/250 [=========================>....] - ETA: 0s - loss: 1.2187 - accuracy: 0.0000e+00\n",
      "Epoch 02000: saving model to training_0_0/cp-2000.ckpt\n",
      "250/250 [==============================] - 0s 868us/step - loss: 1.2027 - accuracy: 0.0000e+00 - val_loss: 1.4135 - val_accuracy: 0.0000e+00\n",
      "63/63 - 0s - loss: 1.4135 - accuracy: 0.0000e+00\n",
      "Restored model, accuracy:  0.00%\n",
      "r2 =0.7361537930796631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "list_model = [0]\n",
    "\n",
    "for i in range(1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train_scaled, y_r_train_ls, test_size=0.2)\n",
    "\n",
    "    mean = X_train.values.mean(axis=0)\n",
    "    std = X_train.values.std(axis=0)\n",
    "    train_data = (X_train.values - mean) / std\n",
    "    test_data = (X_test.values - mean) / std\n",
    "\n",
    "    train_labels = y_train.values.T / 40000\n",
    "    test_labels = y_test.values.T / 40000\n",
    "    \n",
    "    # Добавим эпоху в имя файла (uses `str.format`)\n",
    "    checkpoint_path = \"training_0_0/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Создадим коллбек сохраняющий веса модели каждые 5 эпох\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_path, \n",
    "        verbose=1, \n",
    "        save_weights_only=True,\n",
    "        period=5)    \n",
    "\n",
    "    # Сохраним веса используя формат `checkpoint_path` format\n",
    "    model_nn.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "    # Отобразим прогресс тренировки \n",
    "    # печатая по одной точке на каждую завершенную эпоху \n",
    "    class PrintDot(keras.callbacks.Callback):\n",
    "          def on_epoch_end(self, epoch, logs):\n",
    "                print('.', end='')\n",
    "\n",
    "    EPOCHS = 2000\n",
    "\n",
    "    # Сохраним тренировочную статистику\n",
    "    history = model_nn.fit(train_data, train_labels, epochs=EPOCHS,\n",
    "                            validation_data=(test_data, test_labels), callbacks=[cp_callback])\n",
    "\n",
    "    #clear_output()\n",
    "\n",
    "    \n",
    "    def plot_history(history):\n",
    "        plt.figure()\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Abs Error [1000$]')\n",
    "        plt.plot(history.epoch, \n",
    "               np.array(history.history['mae']),\n",
    "               label='Train Loss')\n",
    "        plt.plot(history.epoch, \n",
    "               np.array(history.history['val_mae']),\n",
    "               label = 'Val loss')\n",
    "        plt.legend()\n",
    "        plt.ylim([0, 3])\n",
    "    \n",
    "    #print('epoch'+str(i * EPOCHS))\n",
    "    \n",
    "    #plot_history(history)\n",
    "    \n",
    "    loss,acc = model_nn.evaluate(test_data, test_labels, verbose=2)\n",
    "    print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    \n",
    "    y_nn_pred = model_nn.predict(test_data)\n",
    "    \n",
    "    print('r2 =' + str(r2_score(test_labels, y_nn_pred)))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 - 0s - loss: 1.4135 - accuracy: 0.0000e+00\n",
      "Restored model, accuracy:  0.00%\n",
      "r2 =0.7361537930796631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest\n",
    "\n",
    "loss,acc = model_nn.evaluate(test_data, test_labels, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))\n",
    "    \n",
    "y_nn_pred = model_nn.predict(test_data)\n",
    "    \n",
    "print('r2 =' + str(r2_score(test_labels, y_nn_pred)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(X_test_ls)\n",
    "X_tarin_l = X_test_ls.copy(deep=True)\n",
    "X_tarin_l['Id'] = test['Id']\n",
    "X_tarin_l['Id'].values\n",
    "\n",
    "d = dict(zip(X_tarin_l['Id'].values, y))\n",
    "X_tarin_l['Price'] = test['Id'].map(d)\n",
    "X_tarin_l[['Id', 'Price']].to_csv(\"KuznetsovVV_predictions_nn.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361537930796631\n",
      "Testing set Mean Abs Error: $   0.00\n"
     ]
    }
   ],
   "source": [
    "[loss, mae] = model_nn.evaluate(test_data, test_labels, verbose=0)\n",
    "\n",
    "y_nn_pred = model_nn.predict(test_data)\n",
    "print(r2_score(test_labels, y_nn_pred))\n",
    "print(\"Testing set Mean Abs Error: ${:7.2f}\".format(mae * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model_nn.predict(test_data).flatten()\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')\n",
    "plt.xlim(plt.xlim())\n",
    "plt.ylim(plt.ylim())\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins = 50)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
